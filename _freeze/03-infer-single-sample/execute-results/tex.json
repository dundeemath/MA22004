{
  "hash": "9d1e16c21850b1574f0d00ca1ea6e4ee",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n\n\n# Inferences based on a single sample {#inference-single-sample}\n\nIn a few situations, we can derive the sampling distribution for the statistic of interest and use this as the basis for constructing confidence intervals and hypothesis tests. Presently we estimate population means $\\mu$ in Section \\@ref(estimating-means), population proportions $p$ in Section \\@ref(estimating-proportions), and population variances $\\sigma^2$ in Section \\@ref(estimating-variances) in some special cases.  \n\n## Estimating means {#estimating-means}\n\nIf the parameter of interest is the population mean $\\theta = \\mu$, then what can be said about the distribution of the sample mean estimator $\\widehat{\\theta} = \\overline{X}$ in \\@ref(eq:sample-mean)? We will consider three cases,\n\n1. [normal population with known $\\sigma^2$](#mean-normal-var-known),\n2. [any population with unknown $\\sigma^2$, when the sample size $m$ is large](#mean-large-sample), and\n3. [normal population with unknown $\\sigma^2$, when the sample size $m$ is small](#mean-normal-var-unknown).  \n\nIn each, the form of the confidence interval and hypothesis test statistic for $\\mu$ can be derived using the approximate normality of the sample mean.\n\nIn general, the confidence intervals for the mean based on normality theory will have the form:\n\\begin{equation}\n \\text{point estimate}\\; \\mu \\pm (\\text{critical value of reference dist.}) \\cdot (\\text{precision of point estimate})\\,, \n (\\#eq:ci-gen-form)\n\\end{equation}\nwhere the reference distribution will be the standard normal (for 1. and 2.) and the Student's $\\mathsf{t}$ distribution (for 3.). The critical value corresponds to the value under the reference distribution that yields the two-sided (symmetric) tail areas summing to $1-\\alpha$.  \n\n### Mean of a normal population with known variance {#mean-normal-var-known}\n\nWhen sampling from a normal population with a known mean and variance, the estimator for the sample mean is also normal with mean $\\mu$ and variance $\\sigma^2/m$ where $m$ is the sample size. Standardising, \n\\begin{equation}\n \\frac{\\overline{X} - \\mu}{ \\sigma / \\sqrt{m}} \\quad \\sim \\mathsf{N}(0, 1)\n (\\#eq:standardized-sample-mean)\n\\end{equation}\nwe see that \n\\begin{equation*}\nP\\left(-z_{\\alpha/2} <  \\frac{\\overline{X} - \\mu}{ \\sigma / \\sqrt{m}} < z_{\\alpha/2}\\right) = 1 - \\alpha\\,.\n\\end{equation*}\nBased on knowing the estimator's sampling distribution, we state the following CI. \n\n\n\n::: {.cell}\n\n```{.definition .cell-code}\nA **$100(1-\\alpha)\\%$ confidence interval** for the mean $\\mu$ of a normal population when the value of $\\sigma^2$ is known is given by \n\\begin{equation} \n \\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{m}}\\,, \n        \\overline{x} + z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{m}} \\right)\\,,  (\\#eq:ci-norm-known-var)\n\\end{equation}\nor $\\overline{x} \\pm z_{\\alpha/2} \\cdot \\sigma / \\sqrt{m}$, where $m$ is the sample size.\n```\n:::\n\n\n\nThe CI for the mean \\@ref(eq:ci-norm-known-var) can be expressed (cf. \\@ref(eq:ci-gen-form)) as \n\\begin{equation*}\n \\text{point estimate}\\; \\mu \\pm \n (z \\;\\text{critical value}) \\cdot (\\text{standard error of mean})\\,.\n\\end{equation*}\nThe $z$ critical value is related to the tail areas under the standard normal curve; we need to find the $z$-score having a cumulative probability equal to $1-\\alpha$ according to Definition \\@ref(def:confidence-interval-gen). \n\n\n\n::: {.cell}\n\n```{.example .cell-code}\nConsider $400$ samples from a normal population with a known standard deviation $\\sigma = 17000$ with mean $\\overline{x} = 20992$ (as depicted in \\@ref(fig:ci-norm-known-var-code)). How do we construct a $95\\%$ confidence interval for $\\mu$?\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![$400$ samples from a normal population with known variance $\\sigma = 17000$ together with the corresponding (normal) sampling distribution for the observed mean.](03-infer-single-sample_files/figure-pdf/ci-norm-known-var-code-1.pdf)\n:::\n:::\n\n\n\nFor $\\alpha = 0.05$, the critical value $z_{0.025} = 1.96$; this value can be found by looking in a table of critical $z$ values or using the `r` code `qnorm(1-.05/2)`. From Definition \\@ref(def:ci-norm-known-var),\n\\begin{equation*}\n\\begin{aligned}\n\\left(\\overline{x} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{m}}\\,, \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{m}} \\right) \n&= \\left(20992 - 1.96 \\frac{17000}{\\sqrt{400}}\\,, 20992 + 1.96 \\frac{17000}{\\sqrt{400}} \\right) \\\\\n&= \\left(19326 \\,, 22658\\right)\\,.\n\\end{aligned}\n\\end{equation*}\n\nThe data above was generated with a true population parameter $\\mu = 21500$, and the CI contains the parameter value (incidentally). $\\lozenge$   \n\nAs noted in \\@ref(eq:ci-gen-form) and \\@ref(eq:ci-norm-known-var), the width of a CI is related to the estimator's precision. The confidence level (or reliability) is inversely related to this precision. When the population is normal and the variance is known, determining the sample size necessary to achieve a desired confidence level and precision is an appealing strategy. A general formula for the sample size $m^*$ necessary to achieve an interval width $w$ is obtained at confidence level  $\\alpha$ by equating $w$ to $2z_{\\alpha/2} \\cdot \\sigma /\\sqrt{m^*}$ and then solving for $m^*$. \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nThe sample size $m$ required to achieve a CI for $\\mu$ with width $w$ at level $\\alpha$ is given by,\n\\begin{equation*}\nm^* = \\left( 2 z_{\\alpha/2} \\cdot \\frac{\\sigma}{w} \\right)^2 \\,.\n\\end{equation*}\n```\n:::\n\n\n\nFrom Proposition \\@ref(prp:ci-select-n-fixed-w-alpha), we see that the smaller the desired $w$, the larger $m^*$ must be (and subsequently, the more effort that must be allocated to data collection).\n\n\n\n::: {.cell}\n\n```{.example .cell-code}\nIn Example \\@ref(exm:exm-ci-norm-known-var) we identified a $95\\%$ confidence interval for a normal population with known variance. The range (width) of that interval was $22658 - 19326 = 3332$. How much would $m$ need to increase to halve the interval width?\n```\n:::\n\n\n\nUsing Proposition \\@ref(prp:ci-select-n-fixed-w-alpha), \n\\begin{equation*}\nm = \\left( 2 \\cdot 1.96 \\cdot \\frac{17000}{1666} \\right)^2 = (40)^2 = 1600\\,.\n\\end{equation*}\nThus, we find that for the same level $\\alpha = 0.05$, we would need to quadruple our original sample size to halve the interval. It is expensive to remove uncertainty! $\\lozenge$   \n\nSuppose now that we would like to consider a hypothesis test for the population mean, such as $H_0 : \\mu = \\mu_0$. Starting from \\@ref(eq:standardized-sample-mean) and assuming that the null hypothesis is true, we find \n\\begin{equation*}\nZ = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{m}}\\,.\n\\end{equation*}\nThe statistic $Z$ measures the distance (measured in units of $\\sd[\\overline{X}]$) between $\\overline{X}$ and its expected value under the null hypothesis. We will use the statistic $Z$ to determine if there is substantial evidence against $H_0$, i.e. if the distance is too far in a direction consistent with $H_a$. \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nAssume that we sample $X_1, \\dots, X_m$ from a normal population with mean $\\mu$ and known variance $\\sigma^2$. \n\nConsider $H_0 : \\mu = \\mu_0$. The test statistic is\n\\begin{equation}\n Z = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{m}}\\,.\n (\\#eq:htest-norm-known-var-T)\n\\end{equation}\n\nFor a hypothesis test at level $\\alpha$, we use the following procedure:\n\nIf $H_a : \\mu > \\mu_0$, then $P = 1 - \\Phi(z)$, i.e., upper-tail $R = \\{z > z_{\\alpha}\\}$.\n\nIf $H_a : \\mu < \\mu_0$, then $P = \\Phi(z)$, i.e., lower-tail $R = \\{z < - z_{\\alpha}\\}$. \n\nIf $H_a : \\mu \\neq \\mu_0$, then $P = 2(1-\\Phi(|z|))$, i.e., two-tailed $R = \\{|z| > z_{\\alpha/2}\\}$.\n```\n:::\n\n\n\nWe recall that $\\Phi(z)$ is the area in the lower tail of the standard normal density, i.e., to the *left* of the calculated value of $z$. Thus $1 - \\Phi(z)$ is the area in the upper-tail, and $2(1 - \\Phi(|z|))$ is twice the area captured in the upper-tail by $|z|$, i.e. the sum of the area in the tails corresponding to $\\pm z$. If $P < \\alpha$, then we reject $H_0$ at level $\\alpha$ as the data provides sufficient evidence at the $\\alpha$ level against the null hypothesis.\n\n\n\n::: {.cell}\n\n```{.example .cell-code}\nLet's return to the data in Example \\@ref(exm:exm-ci-norm-known-var), where we sample from a normal population with a known standard deviation $\\sigma = 17000$. Suppose that someone claims the true mean is $\\mu_0 = 20000$. Does our sample mean $\\overline{x} = 20992$ based on $m = 400$ samples provide evidence to contradict this claim at the $\\alpha = 0.05$ level?\n```\n:::\n\n\n\nThe first thing to record is our parameter of interest: $\\mu$, the true population mean. The null hypothesis, which we assume to be true, is a statement about the value of $\\mu$,\n\\begin{equation*}\n H_0 : \\mu = 20000\\,,\n\\end{equation*}\nand the alternative hypothesis is\n\\begin{equation*}\n H_a : \\mu \\neq 20000\\,,\n\\end{equation*}\nsince we are concerned with a deviation in either direction from $\\mu_0 = 20000$. \n\nSince the population is normal with known variance, we compute the test statistic:\n\\begin{equation*}\n z = \\frac{\\overline{x} - \\mu_0}{\\sigma / \\sqrt{m}} = \\frac{20992 - 20000}{17000 / \\sqrt{400}} = 1.167\\,.\n\\end{equation*}\nThat is, the observed sample mean $\\overline{x}$ is slightly more than $1$ standard deviation than what we expect under $H_0$. Consulting \\@ref(prp:htest-norm-known-var), we see that a two-tailed test is indicated for this particular $H_a$ (i.e., containing \"$\\neq$\"). The $P$-value is the area,^[Note $\\Phi(z) = P(Z \\leq z)$ is found by calling `pnorm(z)` in `r` or by looking up the value in a $Z$ table.]\n\\begin{equation*}\nP = 2(1 - \\Phi(1.167)) = 2 (0.1216052) = 0.2432.\n\\end{equation*}\nThus, since $P = 0.2432 > 0.05 = \\alpha$, we fail to reject $H_0$ at the level $0.05$. The data does not support the claim that the true population mean differs from the value $20000$ at the $0.05$ level. $\\lozenge$   \n\n### Mean of a population with unknown variance (large-sample) {#mean-large-sample}\n\nConsider samples $X_1, \\dots, X_m$ from a population with mean $\\mu$ and variance $\\sigma^2$. Provided that $m$ is large enough, the Central Limit Theorem implies that the estimator for the sample mean $\\overline{X}$ in \\@ref(eq:sample-mean) has *approximately* a normal distribution. Then \n\\begin{equation}\nP \\left( - z_{\\alpha/2} < \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{m}} < z_{\\alpha/2} \\right) \\approx 1 - \\alpha\\,,\n\\end{equation}\nsince the transformed variable has approximately a standard normal distribution. Thus, computing a point estimate based on a large $m$ of samples yields a CI for the population parameter $\\mu$ at an *approximate* confidence level $\\alpha$. However, it is often the case that the variance is unknown. When $m$ is large, replacing the population variance $\\sigma^2$ by the sample variance $S^2$ in \\@ref(eq:sample-var) will not typically introduce too much additional variability.\n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nFor a large sample size $m$, an approximate $100(1-\\alpha)\\%$ confidence interval for the mean $\\mu$ of any population when the variance is unknown is given by \n\\begin{equation} \n \\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{m}} \\,, \n        \\overline{x} + z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{m}} \\right)\\,,  \n (\\#eq:ci-large-sample)\n\\end{equation}\nor $\\overline{x} \\pm z_{\\alpha/2} \\cdot s / \\sqrt{m}$. \n```\n:::\n\n\n\nThe CI for the mean \\@ref(eq:ci-large-sample) applies regardless of the shape of the population distribution so long as the number of samples is large. A rule of thumb is that $m > 40$ is sufficient.^[For $m > 20$, the interval estimate \\[\\text{point estimate } \\pm 2\\sd\\] has $95\\%$ coverage and is surprisingly robust, i.e. applies to a wide variety of population distributions including the normal. However, this rule of thumb won't apply if you want to consider some different level, say $80\\%$ [@vanBelle:2008rt, ยง1].] In words, the CI \\@ref(eq:ci-large-sample) can be expressed (cf. \\@ref(eq:ci-gen-form)) as\n\\begin{equation*}\n \\text{point estimate}\\; \\mu \\pm \n (z \\;\\text{critical value}) \\cdot (\\text{estimated standard error of mean})\\,.\n\\end{equation*}\nTypically, a large-sample CI for a general parameter $\\theta$ holds that is similar to \\@ref(eq:ci-large-sample) for any estimator $\\widehat{\\theta}$ that satisfies: (1) approximately normal in distribution, (2) approximately unbiased, and (3) an expression for the standard error is available.\n\nTo conduct a large-sample hypothesis test regarding the population mean $\\mu$, we consider the test statistic\n\\begin{equation*}\n Z = \\frac{\\overline{X} - \\mu_0}{S / \\sqrt{m}}\n\\end{equation*}\nunder the null hypothesis, i.e., we replace the population standard deviation $\\sigma$ with the sample standard deviation $S$. When the number of samples $m$ is large (say $m > 40$), then $Z$ will be approximately normal. Substituting this test statistic $Z$ for \\@ref(eq:htest-norm-known-var-T), we follow Proposition \\@ref(prp:htest-norm-known-var) to determine how to calculate the $P$-value.  \n\n\n\n\n::: {.cell}\n\n```{.example .cell-code}\nConsider the **Iris Data** from \\@ref(point-estimation) and use the `infer` package to make inferences. In particular, consider whether the true mean petal length of Iris flowers exceeds 3.5 cm at the 0.05 level. \n```\n:::\n\n\n\nRecall that the **Iris Data** contains $m= 150$ measurements of petal length across three species of Iris flowers and that the true variance is unknown. \nWe are interested in testing the null hypothesis $H_0 : \\mu \\leq 3.5$ against the alternative $H_a : \\mu > 3.5$ (i.e., a one-sided test).\n\nWe first compute the observed statistic (sample mean) $\\widehat{\\mu}$. We use the `infer` package to construct a null distribution *computationally* for the response variable (petal length). We specify that the hypothesis test is for the parameter based on a point estimate and that we are testing for equality with the value $\\mu_0 = 3.5$. The null distribution is generated by computing 1000 bootstrap replications of the sample mean, i.e., the sample mean is generated 1000 times by drawing 150 values at random with replacement from the original corpus of $m=150$ samples. (Note that we obtain the null distribution computationally, so we do not need to standardise to $Z$.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_hat <- mean(iris$Petal.Length) \n\nnull_dist <- iris |>\n specify(response = Petal.Length) |>\n hypothesise(null = \"point\", mu = 3.5) |>\n generate(reps = 1000, type = \"bootstrap\") |>\n calculate(stat = \"mean\")\n\nnull_dist |>\n visualise() +\n shade_p_value(obs_stat = mu_hat, direction = \"greater\")\n```\n\n::: {.cell-output-display}\n![](03-infer-single-sample_files/figure-pdf/exm-mean-large-sample-infer-htest-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\np_val <- null_dist |>\n get_p_value(obs_stat = mu_hat, direction = \"greater\")\np_val\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1   0.044\n```\n\n\n:::\n:::\n\n\n\nThe bootstrapped null distribution is plotted using the `visualise` command, and the regions of the null distribution that are as extreme (or more extreme) than the observed statistic $\\widehat{\\mu}$ can be highlighted using the `shade_p_value` command. $P = 0.044$ is found which is quite small; if $\\mu \\leq 3.5$, then the probability of obtaining the sample mean value  $\\widehat{\\mu} = 3.758$ is only 0.044! Thus, the data provide sufficient evidence at the 0.05 level against the hypothesis that the true mean petal length is at most 3.5 cm.  $\\lozenge$\n\n### Mean of a normal population with unknown variance {#mean-normal-var-unknown}\n\nIn Section \\@ref(mean-normal-var-known), we considered samples $X_1, \\dots, X_m$ from a normal population with a known $\\mu$ and $\\sigma^2$. In contrast, here, we consider samples from a normal population and assume the population parameters $\\mu$ and $\\sigma^2$ are unknown. If the number of samples is large, the discussion in Section \\@ref(mean-large-sample) indicates that the rv $Z = (\\overline{X} - \\mu) \\sqrt{m} / S$ has approximately a standard normal distribution. However, if $m$ is not sufficiently large^[Recall that we would consider $m > 40$ to be large.] then the transformed variable will be more spread out than a standard normal distribution. \n\n\n\n::: {.cell}\n\n```{.theorem .cell-code}\nFor the sample mean $\\overline{X}$ based on $m$ samples from a normal distribution with mean $\\mu$, the rv\n\\begin{equation}\n T = \\frac{\\overline{X} - \\mu}{S/\\sqrt{m}}  \\quad \\sim \\mathsf{t}(m-1)\\,, (\\#eq:t-statistic-mean)\n\\end{equation}\nthat is, $T$ has Student's $\\mathsf{t}$ distribution with $\\nu = m-1$ df. \n```\n:::\n\n\n\nThis leads us to consider a CI for the population parameter $\\mu$ based on critical values of the $\\mathsf{t}$ distribution. \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nA **$100(1-\\alpha)\\%$ confidence interval** for the mean $\\mu$ of a normal population, when $\\sigma^2$ is unknown, is given by \n\\begin{equation} \n \\left(\\overline{x} - t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}}\\,, \n        \\overline{x} + t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}} \\right)\\,,  (\\#eq:ci-norm-unknown-var)\n\\end{equation}\nor $\\overline{x} \\pm t_{\\alpha/2, m-1} \\cdot s/ \\sqrt{m}$. Here $\\overline{x}$ and $s$ are the sample mean and sample standard deviation, respectively.\n```\n:::\n\n::: {.cell}\n\n```{.example .cell-code}\nLet us return to the height of $31$ felled black cherry trees from the **Cherry Tree Data** in Table \\@ref(tab:cherry-data). Give a $99\\%$ CI for the population mean $\\mu$.\n```\n:::\n\n\n\nFor $m = 31$, the critical value of the reference distribution is $t_{0.005, 30} \\approx 2.7499$, which can looked up in a table of critical values for $\\mathsf{t}(\\nu = m-1)$ or found using the `r` command `qt(1-0.01/2, df = 31-1)`. The sample mean $\\overline{x} = 76$ (computed in Example \\@ref(exm:eg-estimators)) is combined with the sample standard deviation, \n\\begin{equation*}\n\\begin{aligned}\n s &= \\sqrt{\\frac{1}{m-1} \\sum_{i=1}^m (x_i - \\overline{x})^2}\\\\ \n   &= \\sqrt{\\frac{1}{30} \\left((63-76)^2 + \\cdots + (87 - 76)^2\\right)}\\\\\n   &= 6.372\\,,\n \\end{aligned}\n\\end{equation*}\nto form the interval estimate\n\\begin{equation*}\n\\begin{aligned}\n& \\left(\\overline{x} - t_{\\alpha/2, m-1}  \\cdot \\frac{s}{\\sqrt{m}}\\,, \n        \\overline{x} + t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}} \\right) \\\\\n        &\\qquad = \\left(76 - 2.750 \\cdot \\frac{6.372}{\\sqrt{31}} \\,, 76 + 2.750 \\cdot \\frac{6.372}{\\sqrt{31}} \\right)\\\\\n        &\\qquad = \\left(72.85\\,, 79.15\\right)\\,.\n\\end{aligned}\n\\end{equation*}\nFor comparison, the critical value $t_{.01/2, \\nu}$ for $\\nu = 13, \\dots, 30$ \n\n\n::: {.cell}\n\n```{.r .cell-code}\nqt(1-0.01/2, df = seq(12:39))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 63.656741  9.924843  5.840909  4.604095  4.032143  3.707428  3.499483  3.355387\n [9]  3.249836  3.169273  3.105807  3.054540  3.012276  2.976843  2.946713  2.920782\n[17]  2.898231  2.878440  2.860935  2.845340  2.831360  2.818756  2.807336  2.796940\n[25]  2.787436  2.778715  2.770683  2.763262\n```\n\n\n:::\n:::\n\n\ncan deviate significantly from the corresponding $z_{0.01/2} = 2.575829$. In particular, if we had erroneously used the large sample estimate \\@ref(eq:ci-large-sample), then we would have obtained $99\\%$ CI $(73.05\\,, 78.95)$ which might give us a false sense of security as it is narrower. $\\lozenge$    \n\nIn contrast to Proposition \\@ref(prp:ci-select-n-fixed-w-alpha), it is difficult to select the sample size $m$ to control the width of the $\\mathsf{t}$-based CI as the width involves the unknown (before the sample is acquired) $s$ and because $m$ also enters through $t_{\\alpha/2, m-1}$.  A one-sample $\\mathsf{t}$ test based on \\@ref(eq:t-statistic-mean) can be used to test a hypothesis about the population mean when the population is normal and $\\sigma^2$ is unknown.   \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nAssume that we sample $X_1, \\dots, X_m$ from a normal population with mean $\\mu$ and unknown variance $\\sigma^2$. \n\nConsider $H_0 : \\mu = \\mu_0$. The test statistic is\n\\begin{equation*}\n T = \\frac{\\overline{X} - \\mu_0}{S / \\sqrt{m}} \\,.\n\\end{equation*}\n\nFor a hypothesis test at level $\\alpha$, we use the following procedure: \n        \nIf $H_a : \\mu > \\mu_0$, then $P$-value is the area under $\\mathsf{t}(m-1)$ to the right of $t$.\n\nIf $H_a : \\mu < \\mu_0$, then $P$-value is the area under $\\mathsf{t}(m-1)$ to the left of $t$.\n\nIf $H_a : \\mu \\neq \\mu_0$, then $P$-value is twice the area under $\\mathsf{t}(m-1)$ to the right of $|t|$.\n```\n:::\n\n::: {.cell}\n\n```{.example .cell-code}\nFrom the **Cherry Tree Data**, let's look at the average timber volume given in Table \\@ref(tab:cherry-data-vol). The distribution for this data is approximately normal.^[After looking at the normal quantile-quantile plot, I decided to test a hypothesis. For level $0.01$, I ran a Kolmogorov--Smirnov test for the null hypothesis that the data is consistent with $\\mathsf{N}(\\overline{x}, s^2)$ vs the alternative that the data is not consistent with the specified reference distribution. The $P$-value attained was $P = 0.2532 > 0.10$, and therefore I fail to reject the null hypothesis. The data is consistent with being drawn from a normal population.] We might ask if the data provide compelling evidence, say at level 0.05, for concluding that the true average timber volume exceeds 21.3 cubic feet.^[How much wood is that? About a sixth of a cord. A full cord of chopped firewood in the US is $124$ cu ft; about enough to keep you warm through a New England winter (according to my mother-in-law).]\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\n\\caption{\\label{tab:cherry-data-vol}Observations of $m = 31$ felled black cherry trees.}\n\\centering\n\\begin{tabular}[t]{>{\\raggedright\\arraybackslash}p{150mm}}\n\\toprule\nVolume [cu ft]\\\\\n\\midrule\n\\cellcolor{gray!10}{10.2, 10.3, 10.3, 15.6, 16.4, 18.2, 18.8, 19.1, 19.7, 19.9, 21.0, 21.3, 21.4, 22.2, 22.6, 24.2, 24.9, 25.7, 27.4, 31.7, 33.8, 34.5, 36.3, 38.3, 42.6, 51.0, 51.5, 55.4, 55.7, 58.3, 77.0}\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\n\n:::\n:::\n\n\n\nLet's carry out a significance test for the true average volume of timber $\\mu$ at level $\\alpha = 0.05$. We assume the null hypothesis\n\\begin{equation*}\n H_0 : \\mu = 21.3\\,.\n\\end{equation*}\nAn appropriate null hypothesis is \n\\begin{equation*}\n H_a : \\mu > 21.3\\,,\n\\end{equation*}\nthat is, we will adopt the stance that the true average exceeds $\\mu_0 = 21.3$ only if the null is rejected. \n\nFrom our $m = 31$ samples, we find that $\\overline{x} = 30.17$ and that $s = 16.44$. The computed value of the one-sample $\\mathsf{t}$-statistic is given by \n\\begin{equation}\n\\begin{aligned}\n t &= \\frac{\\overline{x} - \\mu_0}{s / \\sqrt{m}}\\\\\n &= \\frac{30.17 - 21.3}{16.44 / \\sqrt{31}}\\\\\n & = 3\\,.\n \\end{aligned}\n\\end{equation}\nThe test is based on $\\nu = 31-1$ df, and $P = 0.002663$. This is the upper-tail area, i.e. the area to the right of $t$ (see Figure \\@ref(fig:exm-htest-ttest-plot)). \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![For this test, the $P$-value is the upper-tail area, i.e., to the right of the computed statistic t.](03-infer-single-sample_files/figure-pdf/exm-htest-ttest-plot-1.pdf)\n:::\n:::\n\n\n\nSince $P \\ll \\alpha$, we reject the null hypothesis that the population mean is $21.3$. The data provide sufficient evidence that the population mean differs from $21.3$. $\\lozenge$    \n\n## Estimating proportions {#estimating-proportions}\n\nConsider a population of size $M$ in which each member either satisfies a given property or does not (i.e. a binary classification). The proportion $p \\in (0,1)$ of the population satisfying the given property is a parameter characterising the population we might be interested in estimating. A sample of classified observations, $X_1, \\dots, X_m \\sim \\mathsf{Bernoulli}(p)$, from the population contains a proportion,\n\\begin{equation}\n \\widehat{p} = \\frac{1}{m} \\sum_{i=1}^m X_i\\,,\n (\\#eq:proportion-estimator)\n\\end{equation}\nsatisfying the given property. The estimator $\\widehat{p}$ varies with the sample, and for large $m$, its sampling distribution has the following properties:\n\\begin{equation*}\n\\mu_{\\widehat{p}} = \\E[X_i] = p \n (\\#eq:proportion-mean)\n\\end{equation*}\nand \n\\begin{equation}\n \\sigma_{\\widehat{p}}^2 = \\frac{\\Var[X_i]}{m} = \\frac{p(1-p)}{m}\\,,\n (\\#eq:proportion-var)\n\\end{equation}\nprovided that $m$ is small relative to $M$ (a rule of thumb is $m \\leq 0.05 M$).^[Note that if $m$ is large relative to $M$ ($m > 0.05 M$) then the variance \\@ref(eq:proportion-var) must be adjusted by a factor (related to the hypergeometric distribution):\n\\begin{equation*}\n \\sigma_{\\widehat{p}}^2 = \\frac{p(1-p)}{m} \\frac{M-m}{M-1}\\,,\n\\end{equation*}\nwhere for fixed $m$ the factor converges to $1$ as $M\\to \\infty$.] Moreover, by invoking the Central Limit Theorem, we have the distribution of $\\widehat{p}$ is approximately normal for sufficiently large $m$ as \\@ref(eq:proportion-estimator) is a sample mean. Indeed, this normal approximation works well for moderately large $m$ as long as $p$ is not too close to zero or one; a rule of thumb is that $mp > 5$ and $m(1-p) > 5$.\n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nFor large samples $n$, a $100(1-\\alpha)\\%$ confidence interval for the parameter $p$ is given by\n\\begin{equation}\n \\widehat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{m}}\\,.\n (\\#eq:proportion-mean-ci)\n\\end{equation}\n```\n:::\n\n\n\nThis follows from Proposition \\@ref(prp:ci-large-sample) by observing that \\@ref(eq:proportion-estimator) is a sample mean and replacing the standard error $\\sigma_{\\widehat{p}}$ from \\@ref(eq:proportion-var) by the estimated standard error,\n\\begin{equation*}\n \\widehat{\\se}(\\widehat{p}) = \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{m}}\\,;\n\\end{equation*}\nrecall the $s$ in \\@ref(eq:ci-large-sample) is the sample variance for the *population* and $s / \\sqrt{m} = \\se$ is the standard error of the point estimator.   \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nLet $X$ be the count of members with a given property based on a sample of size $m$ from a population where a proportion $p$ shares the property.\nThen $\\widehat{p} = X / m$ is an estimator of $p$. Assume $m p_0 \\geq 10$ and $m (1-p_0) \\geq 10$. \n \nConsider $H_0 : p = p_0$. The test statistic is\n\\begin{equation*}\n Z = \\frac{\\widehat{p} - p_0}{\\sqrt{p_0 (1-p_0) / m}} \\,.\n\\end{equation*}\n\nFor a hypothesis test at level $\\alpha$, we use the following procedure: \n        \nIf $H_a : p > p_0$, then $P$-value is the area under $\\mathsf{N}(0,1)$ to the right of $z$.\n\nIf $H_a : p < p_0$, then $P$-value is the area under $\\mathsf{N}(0,1)$ to the left of $z$.\n\nIf $H_a : p \\neq p_0$, then $P$-value is twice the area under $\\mathsf{N}(0,1)$ to the right of $|z|$.   \n```\n:::\n\n::: {.cell}\n\n```{.example .cell-code}\nLet us revisit Example \\@ref(exm:htest-setup), where we considered Churchill's claim that he would receive half the votes for the House of Commons seat for the constituency of Dundee. We are sceptical that he is as popular as he says. Suppose 116 out of 263 Dundonians polled claimed they intended to vote for Churchill. Can it be concluded at a significance level of $0.10$ that more than half of all eligible Dundonains will vote for Churchill?\n```\n:::\n\n\n\nThe parameter of interest is $p$, the proportion of votes for Churchill. The null hypothesis is $H_0 : p = 0.5$. The alternative hypothesis is $H_a : p < 0.5$, since we . Since $263(0.5) = 131.5 > 10$, we satisfy the assumptions stated in Proposition \\@ref(prp:htest-proportion).\n\nBased on the sample, $\\widehat{p} = 116 / 263 = 0.4411$. The test statistic value is \n\\begin{equation*}\n\\begin{aligned}\n z &= \\frac{\\widehat{p} - p_0}{\\sqrt{p_0 (1-p_0) / m}} \\\\\n &= \\frac{0.4411 - 0.5}{\\sqrt{0.5 (1-0.5) / 263}}\\\\\n &= -1.91  \\,.\n\\end{aligned}\n\\end{equation*}\nThe $P$-value for this lower-tailed $z$ test is  $P = \\Phi(-1.91) = 0.028$. Since $P < 0.10 = \\alpha$, we reject the null hypothesis at the $0.1$ level. The evidence for concluding that the true proportion is different from $p_0 = 0.5$ at the $0.10$ level is compelling.^[Churchill took ca. $44\\%$ of the vote in the 1908 by-election to become MP for Dundee [[https://www.wikiwand.com/en/1908_Dundee_by-election](https://www.wikiwand.com/en/1908_Dundee_by-election)].] $\\lozenge$   \n\n\n## Estimating variances {#estimating-variances}\n\nNext, we consider estimates of the population variance (and standard deviation) when the population is assumed to have a normal distribution. In this case, the sample variance $S^2$ in \\@ref(eq:sample-var) provides the basis for inferences. Consider iid samples $X_1, \\dots, X_m \\sim \\mathsf{N}(\\mu, \\sigma^2)$. We provide the following theorem without proof.\n\n\n\n::: {.cell}\n\n```{.theorem .cell-code}\nFor the sample variance $S^2$ based on $m$ samples from a normal distribution with variance $\\sigma^2$, the rv\n\\begin{equation*}\nV = \\frac{(m-1)S^2}{\\sigma^2} = \\frac{\\sum_i(X_i - \\overline{X})^2}{\\sigma^2} \\qquad \\sim \\chi^2_{m-1}\\,,\n\\end{equation*}\nthat is, $V$ has a $\\chi^2$ distribution with $\\nu = m-1$ df. \n```\n:::\n\n\n\nBased on Theorem \\@ref(thm:samp-var-chisq), \n\\begin{equation*}\nP\\left(\\chi^2_{1-\\alpha/2, m-1} < \\frac{(m-1)S^2}{\\sigma^2} < \\chi^2_{\\alpha/2, m-1} \\right) = 1 - \\alpha \\,,\n\\end{equation*}\ni.e., the area captured between the right and left tail critical $\\chi^2$ values is $1-\\alpha$. The expression above can be further manipulated to obtain an interval for the unknown parameter $\\sigma^2$:\n\\begin{equation*}\nP\\left(\\frac{(m-1) s^2}{\\chi^2_{\\alpha/2, m-1}} < \\sigma^2 < \\frac{(m-1) s^2}{\\chi^2_{1-\\alpha/2, m-1}} \\right) = 1 - \\alpha \\,,\n\\end{equation*}\nwhere we substitute the computed value of the point estimate $s^2$ for the estimator into the limits to give a CI for $\\sigma^2$. If we take square roots in the inequality above, we obtain a CI for the population standard deviation $\\sigma$. \n\n\n\n::: {.cell}\n\n```{.proposition .cell-code}\nA $100(1-\\alpha)\\%$ confidence interval for the variance of a normal population is\n\\begin{equation*}\n \\left( (m-1)s^2 / \\chi^2_{\\alpha/2, m-1} \\,,  (m-1)s^2 / \\chi^2_{1-\\alpha/2, m-1} \\right) \\,.\n (\\#eq:ci-variance)\n\\end{equation*}\nA $100(1-\\alpha)\\%$ confidence interval for the standard deviation $\\sigma$ of a normal population is given by taking the square roots of the lower and upper limits in \\@ref(eq:ci-variance).\n```\n:::\n\n::: {.cell}\n\n```{.example .cell-code}\nFor the **Cherry Tree Data** in Table \\@ref(tab:cherry-data-vol) concerning the timber volume of $31$ felled black cherry trees, give a $95%$ CI for the variance.\n```\n:::\n\n\n\n\nWe are interested in estimating the true variance $\\sigma^2$ of the timber volume based on $m=31$ samples. Recall that the mean of our data is $\\overline{x} = 30.17$ cu ft and that the sample variance is $s^2 = 270.2$ using the estimator \\@ref(eq:sample-var). The critical values for the $\\chi^2_{.975, 30} = 16.7908$ and $\\chi^2{.025, 30} = 46.9792$ can be found by checking a table of critical values of the $\\chi^2(\\nu=30)$ distribution or by using the `r` code `qchisq(1-0.05/2, df=30, lower.tail = FALSE)` and `qchisq(0.05/2, df=df, lower.tail = FALSE)`, respectively (see \\@ref(fig:exm-htest-chisq-plot)).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![As the $\\chi^2$ distribution is not symmetric, the upper and lower critical values will not be the same (the shaded areas are equal).](03-infer-single-sample_files/figure-pdf/exm-htest-chisq-plot-1.pdf)\n:::\n:::\n\n\n\nPulling everything together, a $95\\%$ CI for the population variance is given by \n\\begin{equation*}\n\\begin{aligned}\n & \\left( (m-1)s^2 / \\chi^2_{\\alpha/2, m-1} \\,,  (m-1)s^2 / \\chi^2_{1-\\alpha/2, m-1} \\right) \\\\\n &\\qquad = \\left( (30) 270.2 / 46.9792 \\,, (30) 270.2 / 16.7908  \\right) \\\\\n &\\qquad = \\left(172.5\\,, 482.8\\right)\\,.\n \\end{aligned}\n\\end{equation*}\nNote the position of the critical values---don't swap them around. $\\lozenge$   \n\n\n\n\n::: {.cell}\n\n```{.example .cell-code}\nRevisit Example \\@ref(exm:eg-ci-variance) and use the `infer` package to construct a $95\\%$ confidence interval for the true standard deviation of the timber volume of black cherry trees based on the available measurements in the **Cherry Tree Data**,  Table \\@ref(tab:cherry-data-vol).\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- sd(trees$Volume)\n\nnull_dist <- trees |>\n specify(response = Volume) |>\n generate(reps = 1000, type = \"bootstrap\") |>\n calculate(stat = \"sd\")\n\nci <- null_dist |>\n get_confidence_interval(point_estimate = s, level = 0.95, type = \"se\")\n\nnull_dist |> \n visualise() + shade_ci(ci)\n```\n\n::: {.cell-output-display}\n![](03-infer-single-sample_files/figure-pdf/eg-ci-variance-infer-code-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nWe plot the 95\\% confidence interval for the standard deviation based on the computational null distribution obtained using 1000 bootstrap replications; note the interval estimate \n\n\n::: {.cell}\n\n```{.r .cell-code}\nci^2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lower_ci upper_ci\n1 142.8015 437.8864\n```\n\n\n:::\n:::\n\n\nis in good agreement with the values obtained Example \\@ref(exm:eg-ci-variance). Due to the computational nature, the bootstrapped interval estimate is not precisely the same as the theoretical interval estimate and rerunning the code will yield a slightly different interval. $\\lozenge$",
    "supporting": [
      "03-infer-single-sample_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}