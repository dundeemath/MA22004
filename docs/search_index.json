[
["index.html", "MA22004 - Statistics and Probability II Welcome", " MA22004 - Statistics and Probability II Dr Eric Hall Last updated: 2020-09-11 Welcome Welcome to MA22004. "],
["cg.html", "Course Guide Organisation Timetable Pre-requisites Syllabus Recommended Books Assessment Your Commitment Approved Calculators Study Support Disability Academic Honesty End of Module Questionaire", " Course Guide Organisation This module runs for 11 teaching weeks and is worth 20 SCQF credits (equivalently, 10 ECTS points). All organisation and teaching will be carried out by: Dr Eric Hall ehall001@dundee.ac.uk Mathematics Division Room TBA, Fulton Building 01382 TBA This course uses Blackboard Ultra (look for course MA22004_SEM0000_2021) for communicating all announcements/deadlines and also for running online meetings. This course also uses Gradescope for submission of some of the continuous assessment items and Perusall for collaborative engagement with reading materials. If you have a problem regarding the course, then you should make an appointment to see Dr Hall. You may also bring matters of concern about the course to the attention of the Mathematics Division Staff/Student Committee, which meets once each semester. A volunteer from Level 2 Mathematics will act as class representative to sit on the Staff/Student Committee (see Ultra for contact details). Timetable ⚠️ Due to COVID19, these plans may be subject to change. The delivery of this module consists of a blend of synchronous and asynchronous content delivered both in-person and online. On an average week, there will be seven planned teaching and learning activities. Activity Timetabled Group Hours Delivery Reading asynchronous individually &amp; in groups 6 online Investigation asynchronous individually 1 online Seminar synchronous whole class 1 online Computer Lab asynchronous individually 6 online Workshop Preparation asynchronous individually or in groups 2 online Workshop synchronous in groups 1 face-to-face Office Hours synchronous in groups 1 online The anticipated student effort is 200 hours over the length of the module. You are expected to be “present” for all synchronous timetabled activities except for the online office hours, which are optional. You may engage with the asynchronous material at your own pace, keeping in mind to meet any deadlines for engagement and/or attainment that will be posted to Ultra and discussed. Pre-requisites To take this course, you must have passed module MA12003 or equivalent. Syllabus Sampling Distributions Mean and standard deviation of samples, sampling from a single population, sampling from two populations, shape of sampling distributions. Normal distribution, \\(\\chi^2\\)-square distribution, F-distribution. Hypothesis tests Null and Alternate hypotheses, inferences, confidence intervals, estimating means, proportions and standard deviations. Linear Regression Least squares, assessing usefulness of a model, using a model. Industrial Quality Control Control Charts, acceptance sampling. R software package Appropriate use of computational software to carry out statistical and probabilistic calculations. Recommended Books In addition to the course notes, here are some textbooks you may wish to consult. ⚠️ You do not need to purchase these books. Devore, Probability and Statistics for Engineering and the Sciences, Cengage learning, 2011. (Devore 2016, secs. 6–10, 12, 14, 16) DeGroot and Schervish, Probability and Statistics, Addison-Wesley, 2001. (DeGroot and Schervish 2001, secs. 7–10) Rice, Mathematical statistics and data analysis, Cengage Learning, 2006. (Rice 2006, secs. 6–12) Wasserman, All of Statistics, Springer-Verlag, 2004. (Wasserman 2004, Concise general reference) Assessment The module will be continuously assessed using coursework and examinations. Deadlines, as well as test dates, will be posted on Ultra and announcements made in the class hours. The module assessment weighting is as follows. Assessment Weight Assignments 20% Midterm Exam 1 20% Midterm Exam 2 20% Final Exam 40% Coursework Assessed coursework includes: six hand-in laboratory reports and weekly engagement with the reading material using Perusall. There will also be alternative means of demonstrating your mastery of course material through: one (group) lab presentation and short seminar quizzes (announced in advance). Examinations The Midterm Exams will be computer-assessed and will be one (1) hour in scope. These will likely be in weeks 4 and 8. The Final Exam will be a two (2) hour hand-written exam that will be submitted using Gradescope. This process will be thoroughly discussed and trialled with a dummy exam in advance of the real submission. The Final Exam will be in week 11 (i.e., during the last week of the term). To pass this module, you must: obtain an overall grade of at least D3 in the overall assessment and obtain a grade of at least M1 for the exam and obtain a grade of at least M1 for the coursework. For those who fail the module, there may be an opportunity to take a two-hour resit examination paper at the next available exam diet. ⚠️ Resit marks are based on the resit exam only. Unless you have mitigating circumstances, if you fail to achieve a module grade of CF or above at first attempt, then you may not be permitted to resit the exam. Also, unless you have mitigating circumstances, any pass after a resit will be capped at a grade of D3 regardless of the weighted average mark obtained. Your Commitment You should attend all synchronous timetabled sessions except on medical grounds or with the special permission of Dr Hall. If you are unable to attend the degree examination or complete elements of the coursework on time, then you should inform Dr Hall and submit a medical certificate. Medical certificates should be submitted to your School Office as soon as possible after the absence. ⚠️ You must also submit a Mitigating Circumstances form to explain which aspects of assessment have been affected by your absence. A Medical Certificate will only be taken into account if accompanied by a completed Mitigating Circumstances form that refers to the medical certificate. Approved Calculators The Casio FX83 and the Casio FX85 are the only calculators approved for use in assessments in the School of Engineering, Physics and Mathematics. Study Support If you are having difficulty with the course, you are encouraged to seek help at an early stage by making an appointment with Dr Hall. You may also obtain additional help from the Maths Base (see Ultra for details). Disability The University of Dundee is committed to making reasonable, effective and appropriate accommodations to meet the needs of students with disabilities and to create an inclusive and barrier-free campus. If you require accommodation for a documented disability, then you are advised to register with Disability Services. Please communicate any needs you may have directly with Dr Hall and as soon as possible to ensure timely management of any accommodations. Academic Honesty Honesty in scholarship and research is integral to the integrity of the academic enterprise of any higher education institution. Therefore, all students at the University of Dundee must practice academic honesty. Academic dishonesty includes cheating, fabrication, plagiarism, and facilitating dishonesty. Cases of academic dishonesty will be subject to appropriate sanctions and ignorance of such standards is not sufficient evidence of lack of intent. Please see the Code of Practice on Academic Misconduct by Students for more information about what constitutes academic dishonesty. End of Module Questionaire You will have the opportunity to complete a confidential questionnaire regarding the content and presentation of the module periodically. These questionaires form an important element in the University’s Academic Standards procedures. Thank you in advance for your cooperation. References "],
["preliminaries.html", "Preliminaries Notation Abbreviations", " Preliminaries Notation Uppercase roman letters, e.g., \\(X\\), will typically denote random variables (rvs); lower case letters, e.g., \\(x\\), will denote a particular value (observation) of a rv. Rvs have probability distributions. Distributions are typically characterized by parameters which are fixed real numbers. Parameters describe population characteristics that are often unknown and must be estimated from data. Statistical inference is a tool that will help us to do this. ⚠️ Statistical models comprise both rvs and parameters. Be careful not to confuse them! Abbreviations Abbreviation Expanded pdf probability density function cdf cumulative distribution function rv random variable iid independent and identically distributed obs observations CI confidence interval df degrees of freedom "],
["special-distributions.html", "1 Special distributions 1.1 Normal distribution 1.2 \\(\\mathsf{t}\\) distribution 1.3 \\(\\chi^2\\) distribution 1.4 \\(\\mathsf{F}\\) distribution", " 1 Special distributions 1.1 Normal distribution Normal distributions play an important role in probability and statistics as they describes many natural phenomenon. For instance, the Central Limit Theorem tells us that sums of rvs are approximately normal in distribution. Definition 1.1 A continuous rv \\(X\\) has a normal distribution with parameters \\(\\mu\\) and \\(\\sigma^2\\), where \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(\\sigma &gt; 0\\), if \\(X\\) has pdf \\[\\begin{equation*} f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma}e^{-(x-\\mu)^2/(2\\sigma^2)}\\,, \\quad -\\infty &lt; x &lt; \\infty \\,. \\end{equation*}\\] We write \\(X \\sim \\mathsf{N}(\\mu, \\sigma^2)\\). For \\(X\\sim \\mathsf{N}(\\mu,\\sigma^2)\\), it can be shown that \\(\\operatorname{E}(X) = \\mu\\) and \\(\\operatorname{Var}(X) = \\sigma^2\\), that is, \\(\\mu\\) is the mean and \\(\\sigma^2\\) is the variance of \\(X\\). The pdf takes the form of a bell-shaped curve that is symmetric about \\(\\mu\\). The value \\(\\sigma\\) (standard deviation) is the distance from \\(\\mu\\) to the inflection points of the curve. Thus, the position (location) and spread of the distribution depends on \\(\\mu\\) and \\(\\sigma\\). Figure 1.1: The pdfs of two normal rvs with different means and the same standard deviations. Figure 1.2: The pdfs of two normal rvs with the same means and different standard deviations. Definition 1.2 We say that \\(X\\) has a standard normal distribution if \\(\\mu=0\\) and \\(\\sigma = 1\\) and we will usually denote standard Normal rvs by \\(Z\\) (why? tradition!). 1.1.1 Some useful facts about Normals Here are some useful facts about how to manipulate Normal rvs. If \\(X \\sim \\mathsf{N}(\\mu, \\sigma^2),\\) then \\(Z = (X - \\mu) / \\sigma \\quad \\sim \\mathsf{N}(0,1).\\) If \\(Z \\sim \\mathsf{N}(0, 1),\\) then \\(X = \\mu + \\sigma Z \\quad \\sim \\mathsf{N}(\\mu, \\sigma^2).\\) If \\(X_i \\sim \\mathsf{N}(\\mu_i, \\sigma_i^2)\\) for \\(i = 1, \\dots, n\\) are independent rvs, then \\[\\sum_{i=1}^{n} X_i \\sim \\mathsf{N} \\left( \\sum_{i=1}^{n} \\mu_i, \\sum_{i=1}^{n} \\sigma_i^2 \\right) \\,.\\] In particular, we note that for differences of independent rvs \\(X_1 \\sim \\mathsf{N}(\\mu_1, \\sigma_1^2)\\) and \\(X_2 \\sim \\mathsf{N}(\\mu_2, \\sigma_2^2)\\) then the variances also add: \\[ X_1 - X_2 \\sim \\mathsf{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2) \\,.\\] Probabilities \\(P(a \\leq X \\leq b)\\) are found by converting the problem in \\(X \\sim \\mathsf{N}(\\mu, \\sigma^2)\\) to the standard normal distribution \\(Z \\sim \\mathsf{N}(0, 1)\\) whose probability values \\(\\Phi(z) = P(Z\\leq z)\\) can then be looked up in a table. From (1.) above, \\[\\begin{aligned} P(a &lt; X &lt; b) &amp;= P\\left( \\frac{a-\\mu}{\\sigma} &lt; Z &lt; \\frac{b-\\mu}{\\sigma} \\right) \\\\ &amp;= \\Phi \\left( \\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right) \\,. \\end{aligned}\\] This process is often referred to as standardizing (the normal rv). Example 1.1 Let \\(X \\sim \\mathsf{N}(5, 9)\\) and find \\(P(X \\geq 5.5)\\). \\[\\begin{aligned} P(X \\geq 5.5) &amp;= P\\left(Z \\geq \\frac{5.5 - 5}{3}\\right) \\\\ &amp;= P(Z \\geq 0.1667) \\\\ &amp;= 1 - P(Z \\leq 0.1667) \\\\ &amp;= 1 - \\Phi(0.1667) \\\\ &amp;= 1 - 0.5662 \\\\ &amp;= 0.4338\\,, \\end{aligned}\\] where we look up the value of \\(\\Phi(z) = P(Z\\leq z)\\) in a table of standard normal curve areas. Alternatively, we can use the r code: pnorm(5.5, mean = 5, sd = 3, lower.tail = FALSE) [1] 0.4338162 TODO: plot of area under normal curve (right tail) \\(\\lozenge\\) Example 1.2 Let \\(X \\sim \\mathsf{N}(5, 9)\\) and find \\(P(4 \\leq X \\leq 5.25)\\). \\[\\begin{aligned} P(4 \\leq X \\leq 5.25) &amp;= P\\left(\\frac{4-5}{3} \\leq Z \\leq \\frac{5.25-5}{3}\\right) \\\\ &amp;= P(-0.3333 \\leq Z \\leq 0.0833) \\\\ &amp;= \\Phi(0.0833) - \\Phi(-0.3333) \\\\ &amp;= 0.5332 - 0.3694 \\\\ &amp;= 0.1638\\,. \\end{aligned}\\] where we look up the value of \\(\\Phi(z) = P(Z\\leq z)\\) in a table of standard normal curve areas. Alternatively, we can use the r code: pnorm(5.25, mean = 5, sd = 3) - pnorm(4, mean = 5, sd = 3) [1] 0.1637654 TODO: plot area under normal curve (interior) \\(\\lozenge\\) 1.1.2 Critical \\(z\\) values Below we provide a table containing commonly used normal critical values (note: indexed by \\(\\alpha/2\\)). \\(\\alpha/2 =\\) single tail area central area \\(= 1 – \\alpha\\) \\(z_{\\alpha/2}\\) \\(0.10\\) \\(0.80\\) \\(z_{.10} = 1.28\\) \\(0.05\\) \\(0.90\\) \\(z_{.05} = 1.645\\) \\(0.025\\) \\(0.95\\) \\(z_{.025} = 1.96\\) \\(0.01\\) \\(0.98\\) \\(z_{.01} = 2.33\\) \\(0.005\\) \\(0.99\\) \\(z_{.005} = 2.58\\) 1.2 \\(\\mathsf{t}\\) distribution Student’s \\(\\mathsf{t}\\) distribution gets its peculiar name as it was first published under the pseudonym “Student”. This bit of obfuscation was to protect the identity of his employer, and thereby vital trade secrets, in a highly competitive and lucrative industry. Definition 1.3 A continuous rv \\(X\\) has a \\(\\mathsf{t}\\) distribution with parameter \\(\\nu &gt; 0\\), if \\(X\\) has pdf \\[\\begin{equation*} f(x; \\nu) = \\frac{\\Gamma\\left(\\tfrac{\\nu+1}{2}\\right)}{\\sqrt{\\nu \\pi} \\Gamma \\left(\\tfrac{\\nu}{2}\\right)} \\left( 1 + \\tfrac{x^2}{\\nu} \\right)^{- \\frac{\\nu+1}{2}} \\,, \\quad -\\infty &lt; x &lt; \\infty\\,. \\end{equation*}\\] We write \\(X \\sim \\mathsf{t}(\\nu)\\). 1.2.1 Properties of \\(\\mathsf{t}\\) distributions The density for \\(\\mathsf{t}(\\nu)\\) is a bell-shaped curve centered at \\(0\\). The density for \\(\\mathsf{t}(\\nu)\\) is more spread out than the standard normal density (i.e., it has “fatter tails” than the normal). As \\(\\nu \\to \\infty\\), the spread of the corresponding \\(\\mathsf{t}(\\nu)\\) density converges to the standard normal density (i.e., the spread of the \\(\\mathsf{t}(\\nu)\\) density decreases relative to the standard normal). If \\(X \\sim \\mathsf{t}(\\nu)\\), then \\(\\operatorname{E}[X] = 0\\) for \\(\\nu &gt; 1\\) (otherwise the mean is undefined). 1.3 \\(\\chi^2\\) distribution The \\(\\chi^2\\) distribution arises as the distribution of a sum of the squares of \\(\\nu\\) independent standard normal rvs. Definition 1.4 A continuous rv \\(X\\) has a \\(\\chi^2\\) distribution with parameter \\(\\nu \\in \\mathbf{N}_{&gt;}\\), if \\(X\\) has pdf \\[\\begin{equation*} f(x; \\nu) = \\frac{1}{2^{\\nu/2} \\Gamma(\\nu/2)} x^{(\\nu/2)-1} e^{-x/2} \\,, \\end{equation*}\\] with support \\(x \\in (0, \\infty)\\) if \\(\\nu=1\\), otherwise \\(x \\in [0, \\infty)\\). We write \\(X \\sim \\chi^2(\\nu)\\). The pdf \\(f(x; \\nu)\\) of the \\(\\chi^2(\\nu)\\) distribution depends on a positive integer \\(\\nu\\) referred to as the df. The density \\(f(x;\\nu)\\) is positively skewed, i.e., the right tail is longer and hence the mass is concentrated to the left of the figure. The distribution becomes more symmetric as \\(\\nu\\) increases. We denote critical values of the \\(\\chi^2(\\nu)\\) distribution by \\(\\chi^2_{\\alpha, \\nu}\\). ⚠️ Unlike the normal and \\(t\\) distributions, the \\(\\mathsf{\\chi}^2\\) distribution is not symmetric. This means that the critical values e.g. \\(\\chi^2_{.99, \\nu}\\) and \\(\\chi^2_{0.01,\\nu}\\) are not equal. Hence, it will be necessary to look up both values for CIs based on \\(\\chi^2\\) critical values. If \\(X \\sim \\chi^2(\\nu)\\), then \\(\\operatorname{E}[X] = \\nu\\) and \\(\\operatorname{Var}[X] = 2\\nu\\). 1.4 \\(\\mathsf{F}\\) distribution The \\(\\mathsf{F}\\) distribution arises as a test statistic when comparing population variances and in ANOVA. Definition 1.5 A continuous rv \\(X\\) has an \\(\\mathsf{F}\\) distribution with df parameters \\(\\nu_1\\) and \\(\\nu_2\\), if \\(X\\) has pdf \\[\\begin{equation*} f(x; \\nu_1, \\nu_2) = \\frac{\\Gamma\\left(\\frac{n+m}{2}\\right) n^{n/2} m^{m/2}} {\\Gamma\\left(\\frac{n}{2}\\right) \\Gamma\\left(\\frac{m}{2}\\right)} \\frac{x^{n/2 - 1}}{(m+nx)^{(n+m)/2}} \\,. \\end{equation*}\\] Theorem 1.1 If \\(X_1 \\sim \\chi^2(\\nu_1)\\) and \\(X_2 \\sim \\chi^2(\\nu_2)\\) are independent rvs, then the rv \\[\\begin{equation*} F = \\frac{X_1 / \\nu_1}{X_2 / \\nu_2} \\quad \\sim \\mathsf{F}(\\nu_1,\\nu_2)\\,, \\end{equation*}\\] that comprises the ratio of two \\(\\chi^2\\) rvs divided by their respective df has an \\(\\mathsf{F}(\\nu_1, \\nu_2)\\) distribution. "],
["statistical-inference.html", "2 Inferences based on a single sample 2.1 Point estimation 2.2 Confidence intervals 2.3 Hypothesis testing 2.4 Estimating means 2.5 Estimating proportions 2.6 Estimating variances", " 2 Inferences based on a single sample We discuss the basics of point estimation, confidence intervals, and hypothesis testing for making inferences about a population based on a single sample in Sections 2.1, 2.2, and 2.3, respectively. In particular, we provide details about estimating population means (\\(\\mu\\)) in Section 2.4, population proportions (\\(p\\)) in Section 2.5, and population variances (\\(\\sigma^2\\)) in Section 2.6. 2.1 Point estimation A statistic is a quantity that can be calculated from sample data. Prior to obtaining data, a statistic is an unknown quantity and is therefore a rv. We refer to the probability distribution for a statistic as a sampling distribution to emphasize how the distribution will vary across all possible sample data. Statistical inference seeks to draw conclusions about the characteristics of a population from data. For example, suppose we are botanists interested in taxonomic classification of iris flowers. Let \\(\\mu\\) denote the true average petal length (in cm) of the Iris setosa (AKA the bristle-pointed iris). The parameter \\(\\mu\\) is a characteristic of the whole population of the setosa species. Before we collect data, the petal lengths of \\(n\\) independent setosa flowers are denoted by rvs \\(X_1, X_2, \\dots, X_n\\). Any function of the \\(X_i\\)’s, such as the sample mean, \\[\\begin{equation} \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\\,, \\tag{2.1} \\end{equation}\\] or the sample variance, \\[\\begin{equation*} S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2 \\,, \\tag{2.2} \\end{equation*}\\] is also a rv. Suppose we actually find and measure the petal length of \\(50\\) independent setosa flowers resulting in observations \\(x_1, x_2, \\dots, x_{50}\\); the distribution (counts) of \\(50\\) such petal length measurements are displayed in Figure 2.1. The sample mean \\(\\overline{x}\\) for petal length can then be used to draw a conclusion about the (true) value of the population mean \\(\\mu\\). Based on the data in Figure 2.1 and using (2.1), the value of the sample mean is \\(\\overline{x} = 1.462\\). The value \\(\\overline{x}\\) provides a “best guess” or point estimate for the true value of \\(\\mu\\) based on the \\(n=50\\) samples. Figure 2.1: The distribution (counts) of \\(50\\) setosa petal length measurments. The botonist Edgar Anderson’s Iris Data contains 50 obs. of four features (sepal length [cm], sepal width [cm], petal length [cm], and petal width [cm]) for each of three plant species (setosa, virginica, versicolor) for 150 obs. total. This data set can be accessed in r by loading library(datasets) and then calling data(iris). Definition 2.1 A point estimate of a parameter \\(\\theta\\) (recall: a fixed, unknown quantity) is a single number that we regard as a sensible value for \\(\\theta\\). Let \\(X_1, X_2, \\dots, X_n\\) be iid samples from a (general) distribution \\(F(\\theta)\\). A point estimator \\(\\widehat{\\theta}_n\\) of a parameter \\(\\theta\\) is obtained by selecting a suitable statistic \\(g\\), \\[\\begin{equation*} \\widehat{\\theta}_n = g(X_1, \\dots, X_n) \\,. \\end{equation*}\\] A point estimate \\(\\widehat{\\theta}_n\\) can then be computed from the estimator using sample data. ⚠️ The symbol \\(\\widehat{\\theta}_n\\) (or simply \\(\\widehat{\\theta}\\) when the sample size \\(n\\) is clear from context) is typically used to denote both the estimator and the point estimate resulting from a given sample. Note that writing, e.g., \\(\\widehat{\\theta} = 42\\) does not indicate how the point estimate was obtained. Therefore, it is essential to report both the estimator and the resulting point estimate. Note that Definition 2.1 does not say how to select the appropriate statistic. For the setosa example, the sample mean \\(\\overline{X}\\) is suggested as a good estimator of the population mean \\(\\mu\\). That is, \\(\\widehat{\\mu} = \\overline{X}\\) or “the point estimator of \\(\\mu\\) is the sample mean \\(\\overline{X}\\)”. Here, while \\(\\mu\\) and \\(\\sigma^2\\) are fixed quantities representing characteristics of the population, \\(\\overline{X}\\) and \\(S^2\\) are rvs with sampling distributions. If the population is normally distributed or if the sample is large then the sampling distribution for \\(\\overline{X}\\) has a known form: \\(\\overline{X}\\) is normal with mean \\(\\mu_{\\overline{X}} = \\mu\\) and variance \\(\\sigma_{\\overline{X}}^2 = \\sigma^{2} / n\\), i.e., \\[\\begin{equation*} \\overline{X} \\sim \\mathsf{N}(\\mu, \\sigma^{2} / n) \\,, \\end{equation*}\\] where \\(n\\) is the sample size and \\(\\mu\\) and \\(\\sigma\\) are the (typically unknown) population parameters. Example 2.1 Let us consider the heights (measured in inches) of \\(31\\) black cherry trees (sorted, for your enjoyment) in Table 2.1. Table 2.1: Observations of 31 felled black cherry trees. Height [in] 63, 64, 65, 66, 69, 70, 71, 72, 72, 74, 74, 75, 75, 75, 76, 76, 77, 78, 79, 80, 80, 80, 80, 80, 81, 81, 82, 83, 85, 86, 87 The Cherry Tree Data contains 31 obs. of three features (diameter, height, and volume) and can be accessed in r by loading library(datasets) and then calling data(trees). The quantile-quantile plot1 comparing the quantiles of this data to the quantiles of a normal distribution, is fairly straight. Therefore, we assume that the distribution of black cherry tree heights is (at least approximately) normal with a mean value \\(\\mu\\); i.e., that the population of heights is distributed \\(\\mathsf{N}(\\mu, \\sigma^2)\\) where \\(\\mu\\) is a parameter to be estimated and \\(\\sigma^2\\) is unknown. The observations \\(X_1, \\dots, X_{31}\\) are then assumed to be a random sample from this normal distribution (iid). Consider the following three different stimators and the resulting point estimates for \\(\\mu\\) based on the \\(31\\) samples. Estimator (sample mean) \\(\\overline{X}\\) as in (2.1) and estimate \\(\\overline{x} = \\sum x_i / n = 2356 / 31 = 76\\). Estimator (average of extreme heights) \\(\\widetilde{X} = [\\min(X_i) + \\max(X_i)]/2\\) and estimate \\(\\widetilde{x} = (63 + 87)/2 = 75\\). Estimator (\\(10\\%\\) trimmed mean – i.e., in this instance exclude the smallest and largest three values) \\(\\overline{X}_{\\text{tr}(10)}\\) and estimate \\(\\overline{x}_{\\text{tr}(10)} = (2356 - 63 - 64 - 65 - 87 - 86 - 85) / 25 = 76.24\\). Each estimator above uses a different notion of center for the sample data. An interesting question to think about is: which estimator will tend to produce estimates closest to the true parameter value? Will the estimators work universally well for all distributions? \\(\\lozenge\\) In addition to reporting a point estimate (together with its estimator), some indication of its precision should be given. One measure of the precision of an estimate is its standard error. Definition 2.2 The standard error of an estimator \\(\\widehat{\\theta}\\) is the standard deviation \\(\\sigma_{\\widehat{\\theta}} = \\sqrt{\\operatorname{Var}(\\widehat{\\theta})}\\) (sometimes denoted \\(\\mathsf{se}= \\mathsf{se}(\\widehat{\\theta})\\)). Often, the standard error depends on unknown parameters and must also be estimated. The estimated standard error is denoted by \\(\\widehat{\\sigma}_{\\widehat{\\theta}}\\) or \\(s_{\\widehat{\\theta}}\\) or \\(\\widehat{\\mathsf{se}}\\). 2.2 Confidence intervals An alternative to reporting a point estimate for a parameter is to report an interval estimate suggesting an entire range of plausible values for the parameter of interest. A confidence interval is an interval estimate that makes a probability statement about the degree of reliability, or the confidence level, of the interval. The first step in computing a confidence interval is to select the confidence level. A popular choice is a \\(95\\%\\) confidence interval which corresponds to level \\(\\alpha = 0.05\\). Definition 2.3 A \\(100(1-\\alpha)\\%\\) confidence interval for a parameter \\(\\theta\\) is a random interval \\(C_n = (L_n , U_n)\\) where \\(L_n = \\ell(X_1, \\dots, X_n)\\) and \\(U_n = u(X_1, \\dots, X_n)\\) are functions of the data such that \\[\\begin{equation} P_{\\theta}(L_n &lt; \\theta &lt; U_n ) = 1 - \\alpha\\,, \\end{equation}\\] for all \\(\\theta \\in \\Theta\\). My favorite interpretation of a confidence interval is due to (Wasserman 2004, p 92): On day 1, you collect data and construct a 95 percent confidence interval for a parameter \\(\\theta_1\\). On day 2, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\(\\theta_2\\). On day 3, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\(\\theta_3\\). You continue this way constructing confidence intervals for a sequence of unrelated parameters \\(\\theta_1\\), \\(\\theta_2\\), \\(\\dots\\) Then 95 percent of your intervals will trap the true parameter value. There is no need to introduce the idea of repeating the same experiment over and over. This interpretation makes clear that a confidence interval is not a probability statement about the parameter \\(\\theta\\). In Definition 2.3, note that \\(\\theta\\) is fixed (\\(\\theta\\) is not a rv) and the interval \\(C_n\\) is random. After data has been collected and a point estimator has been calculated, the resulting CIs either contain the true parameter value or they do not (see). Figure 2.2: Fifty \\(95\\%\\) CIs for a population mean \\(\\mu\\). After a sample is taken, the computed interval estimate either contains \\(\\mu\\) or it does not (asteriks identify intervals that do not include \\(\\mu\\)). When drawing such a large number of \\(95\\%\\) CIs, we would anticipate that approximately \\(5\\%\\) (ca. 2.5) would fail to cover the true parameter \\(\\mu\\). TODO: fix above plot EG devore fig 7.3 that illustrates ca. 50 \\(95\\%\\) CIs (with asterisks identifying intervals that do not include \\(\\mu\\)). 2.3 Hypothesis testing In Sections 2.1 and 2.2 we reviewed how to estimate a parameter by a single number (point estimate) or range of plausible values (confidence-interval), respectively. Next we discuss methods for determining which of two contradictory claims, or hypotheses, about a parameter is correct. Definition 2.4 The null hypothesis, denoted by \\(H_0\\), is a claim that we intially assume to be true by dafault. The alternative hypothesis, denoted by \\(H_a\\), is an assertion that is contradictory to \\(H_0\\). For a statistical hypothesis regarding the equality of a parameter \\(\\theta\\) with a fixed quantity \\(\\theta_0\\), the null and alternative hypotheses will take one of the following forms. Null hypothesis Alternative hypothesis \\(H_0 : \\theta \\leq \\theta_0\\) \\(H_a : \\theta &gt; \\theta_0\\) \\(H_0 : \\theta \\geq \\theta_0\\) \\(H_a : \\theta &lt; \\theta_0\\) \\(H_0 : \\theta = \\theta_0\\) \\(H_a : \\theta \\neq \\theta_0\\) The value \\(\\theta_0\\), called the null value, separates the alternative from the null. Definition 2.5 A hypothesis test asks if the available data provides sufficient evidence to reject \\(H_0\\). If the observations disagree with \\(H_0\\), then we reject the null hypothesis. If the sample evidence does not strongly contradict \\(H_0\\), then we continue to believe \\(H_0\\). The two possible conclustions of a hypothesis test are: reject \\(H_0\\) or fail to reject \\(H_0\\).2 A procedure for carrying out a hypothesis test is based on specifying two additional items: a test statistic and a corresponding rejection region. A test statistic is a function of the sample data (like an estimator). The statistical decision to reject or fail to reject the null hypothesis will involve computing the test statistic. The rejection region are the values of the test statistic for which the null hypothesis is to be rejected in favor of the alternative. That is, we compute the test statistic based on a given sample; the test statistic either falls in the rejection region—in which case we reject the null \\(H_0\\)—or it does not fall in the rejection region—in which case we fail to reject the null \\(H_0\\). Example 2.2 TODO: example hypothesis test \\(\\lozenge\\) When carrying out a hypothesis test, two types of errors can be made. The basis for choosing a rejection region typically involves considering these errors. Definition 2.6 A type I error occurs if \\(H_0\\) is rejected when \\(H_0\\) is actually true. A type II error is made if we fail to reject \\(H_0\\) when \\(H_0\\) is actually false. Example 2.3 TODO: example hypothesis error types \\(\\lozenge\\) To summarize, the elements of a statistical test are: Null hypothesis, \\(H_0\\) Alternative hypothesis, \\(H_a\\) Test statistic Rejection region 2.4 Estimating means If the parameter of interest is the population mean \\(\\theta = \\mu\\), then the sample mean estimator \\(\\widehat{\\theta} = \\overline{X}\\) in (2.1) has (at least approximately) a normal distribution for sufficiently large \\(n\\). We will consider three cases, normal population with known \\(\\sigma^2\\), any population with unknown \\(\\sigma^2\\), when the sample size \\(n\\) is large, normal population with unknown \\(\\sigma^2\\), when the sample size \\(n\\) is small, where the form of the confidence interval for \\(mu\\) can be derived using the approximate normality of the sample mean. In general, the confidence intervals for the mean based on normality theory will have the form: \\[\\begin{equation} \\text{point estimate}\\; \\mu \\pm (\\text{critical value of reference dist.}) \\cdot (\\text{precision of point estimate})\\,, \\tag{2.3} \\end{equation}\\] where the reference distribution will be the standard normal (for 1. and 2.) and the Student’s \\(\\mathsf{t}\\) distribution (for 3.). The critical value corresponds to the two-sided (symmetric) tail areas under the reference distribution. 2.4.1 Mean of a normal population with known variance Definition 2.7 A \\(100(1-\\alpha)\\%\\) confidence interval for the mean \\(\\mu\\) of a normal population when the value of \\(\\sigma^2\\) is known is given by \\[\\begin{equation} \\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\,, \\overline{x} + z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}} \\right)\\,, \\tag{2.4} \\end{equation}\\] or \\(\\overline{x} \\pm z_{\\alpha/2} \\cdot \\sigma / \\sqrt{n}\\). The CI for the mean (2.4) can be expressed as \\[\\begin{equation*} \\text{point estimate}\\; \\mu \\pm (z \\;\\text{critical value}) \\cdot (\\text{standard error of mean})\\,. \\end{equation*}\\] The \\(z\\) critical value is related to the tail areas under the standard normal curve; we need to find the \\(z\\)-score having a cumulative probability equal to \\(1-\\alpha\\) according to Definition 2.3. TODO: add example As noted in (2.3) and (2.4), the width of a CI is related to the estimator’s precision. The confidence level (or reliability) is inversely related to this precision. When the population is normal and the variance is known, then an appealing strategy is to determine the sample size necessary to achieve a desired confidence level and precision. A general formula for the sample size \\(n\\) necessary to achieve an interval width \\(w\\) is obtained at confidence level \\(\\alpha\\) is obtained by equating \\(w\\) to \\(2z_{\\alpha/2} \\cdot \\sigma /\\sqrt{n}\\) and then solving for \\(n\\). Proposition 2.1 The sample size \\(n\\) required to achieve a CI for \\(\\mu\\) with width \\(w\\) at level \\(\\alpha\\) is given by, \\[\\begin{equation} n = \\left( 2 z_{\\alpha/2} \\cdot \\frac{\\sigma}{w} \\right)^2 \\,. \\end{equation}\\] From Proposition 2.1, we see that the smaller the desired \\(w\\) then the larger \\(n\\) must be (and subsequently, the more effort that must be allocated to data collection). TODO: add example of sample size calculation 2.4.2 Mean of a population with unknown variance (large-sample) Consider samples \\(X_1, \\dots, X_n\\) from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Provided that \\(n\\) is large enough, the Central Limit Theorem implies that the estimator for the sample mean \\(\\overline{X}\\) in (2.1) has approximately a normal distribution. Then \\[\\begin{equation} P \\left( - z_{\\alpha/2} &lt; \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} &lt; z_{\\alpha/2} \\right) \\approx 1 - \\alpha\\,, \\end{equation}\\] since the transformed variable has approximately a standard normal distribution. Thus, computing a point estimate based on a large \\(n\\) of samples yields a CI for the population parameter \\(\\mu\\) at an approximate confidence level \\(\\alpha\\). However, it is often the case that the variance is unknown. When \\(n\\) is large, replacing the population variance \\(\\sigma^2\\) by the sample variance \\(S^2\\) in (2.2) will not typically introduce too much additional variability. Proposition 2.2 For large samples \\(n\\), an approximate \\(100(1-\\alpha)\\%\\) confidence interval for the mean \\(\\mu\\) of any population when the variance is uknown is given by \\[\\begin{equation} \\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}} \\,, \\overline{x} + z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}} \\right)\\,, \\tag{2.5} \\end{equation}\\] or \\(\\overline{x} \\pm z_{\\alpha/2} \\cdot s / \\sqrt{n}\\). The CI for the mean (2.5) applies regardless of the shape of the population distribution so long as the number of samples is large. A rule of thumb is that \\(n &gt; 40\\) is sufficient. In words, the CI (2.5) can be expressed as \\[\\begin{equation*} \\text{point estimate}\\; \\mu \\pm (z \\;\\text{critical value}) \\cdot (\\text{estimated standard error of mean})\\,. \\end{equation*}\\] Typically, a large-sample CI for a general parameter \\(\\theta\\) similar to (2.5) holds for any estimator \\(\\widehat{\\theta}\\) that satisfies: (1) approximately normal in distribution, (2) approximately unbiased, and (3) an expression for the standard error is available. TODO: add example 2.4.3 Mean of a normal population with unknown variance In Section 2.4.1, we considered samples \\(X_1, \\dots, X_n\\) from a normal population with a known \\(\\mu\\) and \\(\\sigma^2\\). In contrast, here we consider samples from a normal population and assume the population parameters \\(\\mu\\) and \\(\\sigma^2\\) are unknown. If the number of samples is large, the discussion in Section 2.4.2 indicates that the rv \\(Z = (\\overline{X} - \\mu) \\sqrt{n} / S\\) has approximately a standard normal distribution. However, if \\(n\\) is not sufficiently large then the transformed variable will be more spread out than a standard normal distribution. Theorem 2.1 For the sample mean \\(\\overline{X}\\) based on \\(n\\) samples from a normal distribution with mean \\(\\mu\\), the rv \\[\\begin{equation} T = \\frac{\\overline{X} - \\mu}{S} \\sqrt{n} \\quad \\sim \\mathsf{t}(n-1)\\,, \\end{equation}\\] that is, \\(T\\) has Student’s \\(\\mathsf{t}\\) distribution with \\(\\nu = n-1\\) degrees of freedom (df). This leads us to consider a CI for the population parameter \\(\\mu\\) that is based on critical values of the \\(\\mathsf{t}\\) distribution. Proposition 2.3 A \\(100(1-\\alpha)\\%\\) confidence interval for the mean \\(\\mu\\) of a normal population when the value of \\(\\sigma^2\\) is unknown is given by \\[\\begin{equation} \\left(\\overline{x} - t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}}\\,, \\overline{x} + t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\right)\\,, \\tag{2.4} \\end{equation}\\] or \\(\\overline{x} \\pm t_{\\alpha/2, n-1} \\cdot s/ \\sqrt{n}\\). Here \\(\\overline{x}\\) and \\(s\\) are the sample mean and sample standard deviation, respectively. In contrast to Proposition 2.1, it is difficult to select the sample size \\(n\\) to control the width of the \\(\\mathsf{t}\\)-based CI as the width involves the unknown (before the sample is acquired) \\(s\\) and because \\(n\\) also enters through \\(t_{\\alpha/2, n-1}\\). TODO: add example Proposition 2.4 TODO: rule of thumb normal CI TODO: add example using rule of thumb 2.5 Estimating proportions Consider a population of size \\(N\\) in which a proportion \\(p\\) of the population satisfies a given property. The \\(p \\in (0,1)\\) is a parameter characterizing the population, with distribution \\(F(p)\\),3 that we might be interested in estimating. A sample, \\(X_1, \\dots, X_n \\sim F(p)\\), of size \\(n\\) from the population contains a proportion, \\[\\begin{equation} \\widehat{p} = \\frac{1}{n} \\sum_{i=1}^n X_i\\,, \\tag{2.6} \\end{equation}\\] satisfying the given property. The estimator \\(\\widehat{p}\\) varies with the sample and for large \\(n\\) it’s sampling distribution has the following properties: \\[\\begin{equation*} \\mu_{\\widehat{p}} = \\operatorname{E}[X_i] = p \\tag{2.7} \\end{equation*}\\] and \\[\\begin{equation} \\sigma_{\\widehat{p}}^2 = \\frac{\\operatorname{Var}[X_i]}{n} = \\frac{p(1-p)}{n}\\,, \\tag{2.8} \\end{equation}\\] provided that \\(n\\) is small relative to \\(N\\) (a rule of thumb is \\(n \\leq 0.05 N\\)).4 Moreover, by invoking the Central Limit Theorem we have the distribution of \\(\\widehat{p}\\) is approximately normal for sufficiently large \\(n\\) as (2.6) is a sample mean. Indeed, this normal approximation works well for moderately large \\(n\\) as long as \\(p\\) is not too close to zero or one; a rule of thumb is that \\(np &gt; 5\\) and \\(n(1-p) &gt; 5\\). Proposition 2.5 For large samples \\(n\\), a \\(100(1-\\alpha)\\%\\) confidence interval for the parameter \\(p\\) is given by \\[\\begin{equation} \\widehat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{n}}\\,. \\tag{2.9} \\end{equation}\\] This follows from Proposition 2.2 by observing that (2.6) is a sample mean and replacing the standard error \\(\\sigma_{\\widehat{p}}\\) from (2.8) by the estimated standard error, \\[\\begin{equation*} \\widehat{\\mathsf{se}}(\\widehat{p}) = \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{n}}\\,; \\end{equation*}\\] recall the \\(s\\) in (2.5) is the sample variance for the population and \\(s / \\sqrt{n} = \\mathsf{se}\\) is the standard error of the point estimator. Example 2.4 TODO: Examples of sampling distribution for p \\(\\lozenge\\) Example 2.5 TODO: Example confidence interval for p \\(\\lozenge\\) Example 2.6 TODO: Example hypothesis test \\(\\lozenge\\) 2.6 Estimating variances Next we consider estimates of the population variance (and standard deviation) when the population is assumed to have a normal distribution. In this case, the sample variance \\(S^2\\) in (2.2) provides the basis for inferences. Consider iid samples \\(X_1, \\dots, X_n \\sim \\mathsf{N}(\\mu, \\sigma^2)\\). We provide the following theorem without proof. Theorem 2.2 For the sample variance \\(S^2\\) based on \\(n\\) samples from a normal distribution with variance \\(\\sigma\\), the rv \\[\\begin{equation*} V = \\frac{(n-1)S^2}{\\sigma^2} = \\frac{\\sum_i(X_i - \\overline{X})^2}{\\sigma^2} \\qquad \\sim \\chi^2_{n-1}\\,, \\end{equation*}\\] that is, \\(V\\) has a \\(\\chi^2\\) distribution with \\(\\nu = n-1\\) df. Based on Theorem 2.2, \\[\\begin{equation*} P\\left(\\chi^2_{1-\\alpha/2, n-1} &lt; \\frac{(n-1)S^2}{\\sigma^2} &lt; \\chi^2_{\\alpha/2, n-1} \\right) = 1 - \\alpha \\,, \\end{equation*}\\] i.e., the area captured between the right and left tail critical \\(\\chi^2\\) values is \\(1-\\alpha\\). The expression above can be further manipulated to obtain an interval for the unknown parameter \\(\\sigma^2\\): \\[\\begin{equation*} P\\left(\\frac{(n-1) s^2}{\\chi^2_{\\alpha/2, n-1}} &lt; \\sigma^2 &lt; \\frac{(n-1) s^2}{\\chi^2_{1-\\alpha/2, n-1}} \\right) = 1 - \\alpha \\,, \\end{equation*}\\] where we substitute the computed value of the point estimate \\(s^2\\) for the estimator into the limits to give a CI for \\(\\sigma^2\\). If we take square roots of the inequality above, we obtain a CI for the population standard deviation \\(\\sigma\\). Proposition 2.6 A \\(100(1-\\alpha)\\%\\) confidence interval for the variance of a normal population is \\[\\begin{equation*} \\left( (n-1)s^2 / \\chi^2_{\\alpha/2, n-1} \\,, (n-1)s^2 / \\chi^2_{1-\\alpha/2, n-1} \\right) \\,. \\tag{2.10} \\end{equation*}\\] A \\(100(1-\\alpha)\\%\\) confidence interval for the standard deviation \\(\\sigma\\) of a normal population is given by taking the square roots of the lower and upper limits in (2.10). Example 2.7 TODO: Example CI for variance (using the tree data?) \\(\\lozenge\\) References "],
["inference-two-samples.html", "3 Inferences based on two samples 3.1 Comparing means 3.2 Comparing paired samples 3.3 Comparing proportions 3.4 Comparing variances", " 3 Inferences based on two samples We consider inferences—estimators, confidence intervals, and hypothesis testing—for comparing means, proportions, and variances based on two independent samples from different populations, respectively, in Sections 3.1, 3.3, 3.4. We also consider inferences when the samples are not independent, so-called paired samples, in Section 3.2. 3.1 Comparing means Let us assume that we have two normal populations with iid samples \\[\\begin{equation*} X_1, \\dots, X_m \\sim \\mathsf{N}(\\mu_X, \\sigma_X^2) \\end{equation*}\\] and \\[\\begin{equation*} Y_1, \\dots, Y_n \\sim \\mathsf{N}(\\mu_Y, \\sigma_Y^2) \\end{equation*}\\] and, moreover, that the \\(X\\) and \\(Y\\) samples are independent of one another. When comparing the means of two populations, the quantity of interest is the difference: \\(\\mu_X - \\mu_Y\\). Proposition 3.1 If we consider the sample means \\(\\overline{X}\\) and \\(\\overline{Y}\\), then the mean of the variable \\(\\overline{X} - \\overline{Y}\\) is, \\[\\begin{equation*} \\mu_{\\overline{X} - \\overline{Y}} = \\operatorname{E}\\left[ \\overline{X} - \\overline{Y} \\right] = \\mu_X - \\mu_Y\\,, \\end{equation*}\\] and the variance is, \\[\\begin{equation*} \\sigma_{\\overline{X} - \\overline{Y}}^2 = \\operatorname{Var}\\left[ \\overline{X} - \\overline{Y} \\right] = \\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n} \\,. \\end{equation*}\\] Proposition 3.1 follows directly from the definition of the sample mean in (2.1) and properties of expectation and variance. If our parameter of interest is \\[\\begin{equation*} \\theta = \\mu_1 - \\mu_2\\,, \\end{equation*}\\] then its estimator, \\[\\begin{equation*} \\widehat{\\theta} = \\overline{X} - \\overline{Y}\\,, \\end{equation*}\\] is normally distributed with mean and variance given by Proposition 3.1. If the samples sizes \\(m\\) and \\(n\\) are large, then the estimator is approximately normally distributed by the Central Limit Theorem regardless of the population. We now discuss CIs and hypothesis tests for comparing population means \\(\\theta = \\mu_X - \\mu_Y\\). We consider three cases when comparing means: normal populations when the variances \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\) are known, any populations with unknown variances \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\), when the sample sizes \\(m\\) and \\(n\\) are large, normal populations when the variances \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\) are unknown, when the sample sizes \\(m\\) and \\(n\\) are small, noting that the development largely reflects that of Section 2.4. 3.1.1 Comparing means of normal populations when variances are known When \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\) are known, standardizing \\(\\overline{X} - \\overline{Y}\\) yields the standard normal variable: \\[\\begin{equation} Z = \\frac{\\overline{X} - \\overline{Y} - (\\mu_X - \\mu_Y)}{\\sqrt{\\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n}}}\\quad \\sim \\mathsf{N}(0,1)\\,. \\tag{3.1} \\end{equation}\\] Inferences proceed by treating the parameter of interest \\(\\theta\\) as a single sample using (3.1). Proposition 3.2 A \\(100(1-\\alpha)\\%\\) CI for the parameter \\(\\theta = \\mu_X - \\mu_Y\\) based on samples of size \\(m\\) from a normal population \\(\\mathsf{N}(\\mu_X, \\sigma_X^2)\\) and of size \\(n\\) from \\(\\mathsf{N}(\\mu_Y, \\sigma_Y^2)\\) with known variances, is given by \\[\\begin{equation*} (\\overline{x} + \\overline{y}) \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n}} \\,. \\end{equation*}\\] Proposition 3.3 For null hypothesis \\(H_0 : \\mu_X - \\mu_Y = \\theta_0\\), the test statistic to consider is: \\[\\begin{equation*} z = \\frac{\\overline{x} - \\overline{y} - \\theta_0}{\\sqrt{\\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n}}} \\end{equation*}\\] 3.1.2 Comparing means when the sample sizes are large When the samples are large, then the assumptions about normality of the populations and knowledge of the variances \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\) can be relaxed. For sufficiently large \\(m\\) and \\(n\\), the difference of the sample means, \\(\\overline{X} - \\overline{Y}\\), has approximately a normal distribution for any underlying population distributions by the Central Limit Theorem. Moreover, if \\(m\\) and \\(n\\) are large enough, then replacing the population variances with the sample variances \\(S_X^2\\) and \\(S_Y^2\\) will not increase the variability of the estimator or the test statistic too much. Proposition 3.4 For \\(m\\) and \\(n\\) sufficiently large, an approximate \\(100(1-\\alpha)\\%\\) CI for \\(\\mu_X - \\mu_Y\\) for two samples from populations with any underlying distribution is given by \\[\\begin{equation*} (\\overline{x} + \\overline{y}) \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{s_{X}^2}{m} + \\frac{s_{Y}^2}{n}} \\end{equation*}\\] Proposition 3.5 For null hypothesis \\(H_0 : \\mu_X - \\mu_Y = \\theta_0\\), the test statistic to consider is: \\[\\begin{equation*} z = \\frac{\\overline{x} - \\overline{y} - \\theta_0}{\\sqrt{\\frac{s_{X}^2}{m} + \\frac{s_{Y}^2}{n}}} \\end{equation*}\\] 3.1.3 Comparing means of normal populations when variances are unknown and the sample size is small If \\(\\sigma_X\\) and \\(\\sigma_Y\\) are unknown and either sample is small (e.g., \\(m &lt; 30\\) or \\(n &lt;30\\)), but both populations are normally distributed, then we can use Student’s \\(\\mathsf{t}\\) distribution to make inferences. We provide the following theorem without proof. Theorem 3.1 When both population distributions are normal, the standardized variable \\[\\begin{equation*} T = \\frac{\\overline{X}-\\overline{Y} - (\\mu_X - \\mu_Y)}{\\sqrt{\\frac{S_X^2}{m} + \\frac{S_Y^2}{n}}} \\quad \\sim \\mathsf{t}(\\nu) \\end{equation*}\\] where the df \\(\\nu\\) is estimated from the data. Namely, \\(\\nu\\) is given by (round \\(\\nu\\) down to the nearest integer): \\[\\begin{equation} \\nu = \\frac{ \\left( \\frac{s_X^2}{m} + \\frac{s_Y^2}{n} \\right)^2}{\\frac{(s_X^2 / m)^2}{m-1} + \\frac{(s_Y^2/n)^2}{n-1}} = \\frac{ \\left( s_{\\overline{X}}^2 + s_{\\overline{Y}}^2 \\right)^2}{\\frac{s_{\\overline{X}}^4}{m-1} + \\frac{s_{\\overline{Y}}^4}{n-1}} \\tag{3.2} \\end{equation}\\] where \\(s_X^2\\) and \\(s_Y^2\\) are point estimators of the sample variances; alternatively, we see that the formula (3.2) can also be written in terms of the standard error of the sample means: \\[\\begin{equation*} s_{\\overline{X}} = \\frac{s_X}{\\sqrt{m}} \\quad \\text{and} \\quad \\qquad s_{\\overline{Y}} = \\frac{s_Y}{\\sqrt{n}} \\,. \\end{equation*}\\] The formula (3.2) for the data-driven choice of \\(\\nu\\) calls for the computation of the standard error of the sample means. Proposition 3.6 A \\(100(1-\\alpha)\\%\\) CI for \\(\\mu_X - \\mu_Y\\) for two samples of size \\(m\\) and \\(n\\) from normal populations where the variances are unknown is given by \\[\\begin{equation*} (\\overline{x} - \\overline{y}) \\pm t_{\\alpha/2, \\nu} \\sqrt{ \\frac{s_X^2}{m} + \\frac{s_Y^2}{n}}\\,, \\end{equation*}\\] where we recall that \\(t_{\\alpha/2, \\nu}\\) is the \\(\\alpha/2\\) critical value of \\(\\mathsf{t}(\\nu)\\) with \\(\\nu\\) given by (3.2). Proposition 3.7 For the null hypothesis \\(H_0 = \\mu_X - \\mu_Y = \\theta_0\\), the test statistic to consider is: \\[\\begin{equation*} t = \\frac{(\\overline{x} - \\overline{y}) - \\theta_0}{\\sqrt{ \\frac{s_X^2}{m} + \\frac{s_Y^2}{n}}} \\end{equation*}\\] If the normal populations have the same variance (i.e., the populations differ only in location not in spread), then matters simplify. If the variances of the normal populations are unknown but are the same (i.e., \\(\\sigma_X^2 = \\sigma_Y^2\\)), then deriving CIs and test statistics for comparing the means can be simplified by considering a combined or pooled estimator for (the single parameter) \\(\\sigma^2\\). If we have two samples from populations with variance \\(\\sigma^2\\), then each sample provides an estimate for \\(\\sigma^2\\). That is, \\(S_X^2\\), based on the \\(m\\) observations of the first sample, is one estimator for \\(\\sigma^2\\) and another is given by \\(S_Y^2\\), based on \\(n\\) observations of the second sample. The correct way to combine these two estimators into a single estimator for the sample variance is to consider the pooled estimator of \\(\\sigma^2\\), \\[\\begin{equation} S_{\\mathsf{p}}^2 = \\frac{m-1}{m+n-2} S_X^2 + \\frac{n-1}{m+n-2} S_Y^2 \\,. \\tag{3.3} \\end{equation}\\] The pooled estimator is a weighted average that adjusts for differences between the sample sizes \\(m\\) and \\(n\\).5 Proposition 3.8 A \\(100(1-\\alpha)\\%\\) CI for \\(\\mu_X - \\mu_Y\\) for two samples of size \\(m\\) and \\(n\\) from normal populations where the variance \\(\\sigma^2\\) is unknown is given by \\[\\begin{equation*} (\\overline{x} - \\overline{y}) \\pm t_{\\alpha/2, m + n - 2} \\cdot \\sqrt{ s_{\\mathsf{p}}^2 \\left( \\frac{1}{m} + \\frac{1}{n} \\right)} \\,, \\end{equation*}\\] where we recall that \\(t_{\\alpha/2, m+n-2}\\) is the \\(\\alpha/2\\) critical value of the \\(\\mathsf{t}(\\nu)\\) with \\(\\nu = m + n - 2\\) df. Similarly, one can consider a pooled \\(\\mathsf{t}\\) test, i.e., a hypothesis test based on the pooled estimator for the variance as opposed to the two-sample \\(\\mathsf{t}\\) test in Proposition 3.7. If you have reasons to believe that \\(\\sigma_X^2 = \\sigma_Y^2\\), these pooled \\(\\mathsf{t}\\) procedures are appealing because \\(\\nu\\) is very easy to compute. ⚠️ Pooled \\(t\\) procedures are not robust if the assumption of equalized variance is violated. Theoretically, you could first carry out a statistical test \\(H_0 : \\sigma_X^2 = \\sigma_Y^2\\) on the equality of variances and then use a pooled \\(\\mathsf{t}\\) procedure if the null hypothesis is not rejected. However, there is no free lunch: the typical \\(\\mathsf{F}\\) test for equal variances (see Section 3.4) is sensitive to normality assumptions. The two sample \\(\\mathsf{t}\\) procedures, with the data-driven choice of \\(\\nu\\) in (3.2), are therefore recommended unless, of course, you have a very compelling reason to believe \\(\\sigma_X^2 = \\sigma_Y^2\\). 3.2 Comparing paired samples The preceding analysis for comparing population means was based on the assumption that a random sample \\(X_1, \\dots, X_m\\) is drawn from a distribution with mean \\(\\mu_X\\) and that a completely independent random sample \\(Y_1, \\dots, Y_n\\) is drawn from a distribution with mean \\(\\mu_Y\\). Some situations, e.g., comparing observations before and after a treatment or exposure, necessitate the consideration of paired values. Consider a random sample of iid pairs \\[\\begin{equation*} (X_1, Y_1), \\dots, (X_n, Y_n) \\end{equation*}\\] with \\(\\operatorname{E}[X_i] = \\mu_X\\) and \\(\\operatorname{E}[Y_i] = \\mu_Y\\). If we are interested in making inferences about the difference \\(\\mu_X - \\mu_Y\\) then the paired differences \\[\\begin{equation*} D_i = X_i - Y_i \\,,\\quad i=1, \\dots, n\\,, \\end{equation*}\\] constitute a sample with mean \\(\\mu_D = \\mu_X - \\mu_Y\\) that can be treated using single-sample CIs and tests, e.g., see Section 2.4.3. 3.3 Comparing proportions Consider a population containing a proportion \\(p_X\\) of individuals satisfying a given property. For a sample of size \\(m\\) from this population, we denote the sample proportion by \\(\\widehat{p}_X\\). Likewise, we consider a population containing a proportion \\(p_Y\\) of individuals satisfying the same given property. For a sample of size \\(n\\) from this population, we denote the sample proportion by \\(\\widehat{p}_Y\\). We assume the samples from the \\(X\\) and \\(Y\\) populations are independent. The natural estimator for the difference in population proportions \\(p_X - p_Y\\) is the difference in the sample proportions \\(\\widehat{p}_X - \\widehat{p}_Y\\). Provided the samples are much smaller than the population sizes (i.e., the populations are about \\(20\\) times larger than the samples), \\[\\begin{equation*} \\mu_{(\\widehat{p}_X - \\widehat{p}_Y)} = \\operatorname{E}[\\widehat{p}_X - \\widehat{p}_Y] = p_X - p_Y\\,, \\end{equation*}\\] and \\[\\begin{equation*} \\sigma_{(\\widehat{p}_X - \\widehat{p}_Y)}^2 = \\operatorname{Var}[\\widehat{p}_X - \\widehat{p}_Y] = \\frac{p_X(1-p_X)}{m} + \\frac{p_Y(1-p_Y)}{n}\\,, \\end{equation*}\\] by considering the fact that the count of individuals satisfying the given property in each population will be independent draws from \\(\\mathsf{Binom}(m, p_X)\\) and \\(\\mathsf{Binom}(n, p_Y)\\), respectively. Further, if \\(m\\) and \\(n\\) are large (e.g., \\(m \\geq 30\\) and \\(n \\geq 30\\)), then \\(\\widehat{p}_X\\) and \\(\\widehat{p}_Y\\) are (approximately) normally distributed. Standardizing \\(\\widehat{p}_X - \\widehat{p}_Y\\), \\[\\begin{equation*} Z = \\frac{\\widehat{p}_X - \\widehat{p}_Y - (p_X - p_Y)}{\\sqrt{\\frac{p_X(1-p_X)}{m} + \\frac{p_Y(1-p_Y)}{n}}} \\quad \\sim \\mathsf{N}(0,1)\\,. \\end{equation*}\\] A CI for \\(\\widehat{p}_X - \\widehat{p}_Y\\) then follows from the large-sample CI considered in Section 2.4.2. Proposition 3.9 An approximate \\(100(1-\\alpha)\\%\\) CI for \\(p_X - p_Y\\) is given by \\[\\begin{equation*} \\widehat{p}_X - \\widehat{p}_Y \\pm z_{\\alpha/2}\\sqrt{\\frac{\\widehat{p}_X (1 - \\widehat{p}_X)}{m} + \\frac{\\widehat{p}_Y (1 - \\widehat{p}_Y)}{n}}\\,, \\tag{3.4} \\end{equation*}\\] and, as a rule of thumb, can be reliably used if \\(m \\widehat{p}_X\\), \\(m (1 - \\widehat{p}_X)\\), \\(n \\widehat{p}_Y\\), and \\(n (1-\\widehat{p}_Y)\\) are greater than or equal to \\(10\\). Proposition 3.9 does not pool the estimators for the population proportions. However, if we are considering a hypothesis test concerning the equality of the population proportions with the null hypothesis \\[\\begin{equation*} H_0 : p_X - p_Y = 0 \\,, \\end{equation*}\\] then we are assuming that \\(p_X = p_Y\\) (unless the data suggests otherwise). Therefore as a matter of consistency we should replace the standard error in (3.4) with a pooled estimator for the standard error of the population proportion, \\[\\begin{equation*} \\widehat{p} = \\frac{m}{m + n} \\widehat{p}_X + \\frac{n}{m + n} \\widehat{p}_Y \\,. \\end{equation*}\\] Proposition 3.10 For the null hypothesis \\(H_0 : p_X - p_Y = 0\\), the test statistic to consider is: \\[\\begin{equation*} z = \\frac{\\widehat{p}_X - \\widehat{p}_Y}{\\sqrt{\\widehat{p} (1 - \\widehat{p}) \\left( \\frac{1}{m} + \\frac{1}{n} \\right)}} \\end{equation*}\\] 3.4 Comparing variances For a random sample \\[\\begin{equation*} X_1, \\dots, X_m \\sim \\mathsf{N}(\\mu_X, \\sigma_X^2) \\end{equation*}\\] and an independent random sample \\[\\begin{equation*} Y_1, \\dots, Y_n \\sim \\mathsf{N}(\\mu_Y, \\sigma_Y^2)\\,, \\end{equation*}\\] the rv \\[\\begin{equation} F = \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_Y^2} \\quad \\sim \\mathsf{F}(m-1, n-1)\\,, \\tag{3.5} \\end{equation}\\] that is, \\(F\\) has an \\(\\mathsf{F}\\) distribution with df \\(\\nu_1 = m-1\\) and \\(\\nu_2 = n-1\\). The statistic \\(F\\) in (3.5) comprises the ratio of variances \\(\\sigma_X^2 / \\sigma_Y^2\\) and not the difference; therefore, the plausibility of \\(\\sigma_X^2 = \\sigma_Y^2\\) will be based on how much the ratio differs from \\(1\\). Proposition 3.11 For the null hypothesis \\(H_0 : \\sigma_X^2 = \\sigma_Y^2\\), the test statistic to consider is: \\[\\begin{equation*} f = \\frac{s_X^2}{s_Y^2} \\end{equation*}\\] and the \\(P\\)-values are determined by the \\(\\mathsf{F}(m-1, n-1)\\) curve where \\(m\\) and \\(n\\) are the respective sample sizes. A \\(100(1-\\alpha)\\%\\) CI for the ratio \\(\\sigma_X^2 / \\sigma_Y^2\\) is based on forming the probability, \\[\\begin{equation*} P(F_{1-\\alpha/2, \\nu_1, \\nu_2} &lt; F &lt; F_{\\alpha/2, \\nu_1, \\nu_2}) = 1 - \\alpha\\,, \\end{equation*}\\] where \\(F_{\\alpha/2, \\nu_1, \\nu_2}\\) is the \\(\\alpha/2\\) critical value from the \\(\\mathsf{F}(\\nu_1 = m-1, \\nu_2 = n-1)\\) distribution. Substituting (3.5) with point estimates for \\(F\\) and manipulating the inequalities it is possible to isolate the ratio \\(\\sigma_X^2 / \\sigma_Y^2\\), \\[\\begin{equation*} P \\left( \\frac{1}{F_{\\alpha/2, \\nu_1, \\nu_2}} \\frac{s_X^2}{s_Y^2} &lt; \\frac{\\sigma_X^2}{\\sigma_Y^2} &lt; \\frac{1}{F_{1-\\alpha/2, \\nu_1, \\nu_2}} \\frac{s_X^2}{s_Y^2} \\right) = 1 - \\alpha \\,. \\end{equation*}\\] Proposition 3.12 A \\(100(1-\\alpha)\\%\\) CI for the ratio of population variances \\(\\sigma_X^2 / \\sigma_Y^2\\) is given by \\[\\begin{equation*} \\left(F_{\\alpha/2, m-1, n-1}^{-1} s_X^2 / s_Y^2 \\,, F_{1-\\alpha/2, m-1, n-1}^{-1} s_X^2 / s_Y^2 \\right)\\,. \\end{equation*}\\] If \\(m \\neq n\\), then the estimator with more samples will contain more information about the parameter \\(\\sigma^2\\). Thus, the simple average \\((S_X^2 + S_Y^2)/2\\) wouldn’t really be fair, would it?↩︎ "],
["categorical-data.html", "4 Categorical data 4.1 Multinomial experiments 4.2 Goodness-of-fit for a single factor 4.3 Test for independence of factors", " 4 Categorical data 4.1 Multinomial experiments Suppose we have a population that is divided into \\(k &gt; 2\\) distinct categories. We consider an experiment where we select \\(m\\) individuals (or objects) from the population and categorize each one. We denote the proportion of the population in the \\(i\\)th category by \\(p_i\\). If the sample size \\(m\\) is much smaller than the population size \\(M\\) (so that the \\(m\\) trials are independent), this experiment will be approximately multinomial with success probability \\(p_i\\) for each category, \\(i=1, \\dots, k\\). Before the experiment is performed, we denote the number (or count) of the trails resulting in category \\(i\\) by the rv \\(N_i\\). The expected number of trails that result in category \\(i\\) is given by \\[\\begin{equation} \\operatorname{E}[N_i] = m p_i\\,, \\quad i=1, \\dots, k\\,. \\tag{4.1} \\end{equation}\\] After the experiment is performed, we denote the corresponding observed value by \\(n_i\\). Since the trials result in distinct categories, \\[\\begin{equation*} \\sum_{i=1}^k N_i = \\sum_{i=1}^{k} n_i = m \\,, \\end{equation*}\\] which indicates that, for a given \\(m\\), we only need to observe \\(k-1\\) of the variables to be able to work out what the \\(k\\)th variable should be. 4.2 Goodness-of-fit for a single factor We are interested in making inferences about the proportion parameters \\(p_i\\). Specifically, we will consider the null hypothesis, \\[\\begin{equation} H_0 : p_1 = p_{10}\\,, p_2 = p_{20}\\,, \\cdots\\,, p_k = p_{k0}\\,, \\tag{4.2} \\end{equation}\\] that completely specifies a value \\(p_{i0}\\) for each \\(p_i\\).6 The alternative hypothesis \\(H_a\\) will state that \\(H_0\\) is not true, i.e., that at least one \\(p_i\\) is different from the value \\(p_{i0}\\) claimed under the null \\(H_0\\). Provided the null hypothesis in (4.2) is true, the expected values (4.1) can be written in terms of the expected frequencies, \\[\\begin{equation*} \\operatorname{E}[N_i] = m p_{i0}\\,, \\quad i=1,\\dots,k\\,. \\end{equation*}\\] Often the \\(n_i\\), referred to as the observed cell counts, and the corresponding \\(m p_{i0}\\), referred to as the expected cell counts, are tabulated, for example, as in Table 4.1. Table 4.1: Observed and expected cell counts. Category \\(i=1\\) \\(i=2\\) \\(\\cdots\\) \\(i=k\\) Row total Observed \\(n_1\\) \\(n_2\\) \\(\\cdots\\) \\(n_k\\) \\(m\\) Expected \\(mp_{10}\\) \\(mp_{20}\\) \\(\\cdots\\) \\(mp_{k0}\\) \\(m\\) The test procedure assesses the discrepancy between the value of the observed and expected cell counts. This discrepancy, or goodness of fit, is measured by the squared deviations divided by the expected count.7 Theorem 4.1 For \\(m p_i \\geq 5\\) for \\(i = 1, \\dots, k\\), the rv \\[\\begin{equation*} V = \\sum_{i=1}^k \\frac{(N_i - m p_i)^2}{m p_i} \\quad \\sim \\chi^2(k-1)\\,, \\end{equation*}\\] that is, \\(V\\) has approximately a \\(\\chi^2\\) distribution with \\(\\nu = k-1\\) df. Proposition 4.1 For the null hypothesis \\[\\begin{equation*} H_0 : p_1 = p_{10}, p_2 = p_{20}, \\cdots, p_k = p_{k0}\\,, \\end{equation*}\\] and alternative \\[\\begin{equation*} H_a : p_i \\neq p_{i0}\\; \\text{for at least one}\\; i\\,, \\end{equation*}\\] the test statistic to consider is: \\[\\begin{equation*} V = \\sum_{i=1}^k \\frac{(n_i - m p_{i0})^2}{m p_{i0}}\\,, \\end{equation*}\\] provided, as a rule of thumb, \\(m p_{i0} \\geq 5\\) for all \\(i = 1, \\dots, k\\). ⚠️ Things are much more complicated if the category probabilities are not completely specified. 4.3 Test for independence of factors In Section 4.2 we considered the categorization of a population into a single factor. We now consider a single population where each individual is categorized into two factors with \\(I\\) distinct categories for the first factor and \\(J\\) distinct categories for the second factor. That is, each individual from the population belongs to exactly one of the \\(I\\) categories of the first factor and exactly one of the \\(J\\) categories of the second factor. We want to determine whether or not there is any dependency between the two factors. For a sample of \\(m\\) individuals, we denote by \\(n_{ij}\\) the count of the \\(m\\) samples that fall both in category \\(i\\) of the first factor and category \\(j\\) of the second factor, for \\(i = 1, \\dots, I\\) and \\(j = 1, \\dots, J\\). A contingency (data) tables with \\(I\\) rows and \\(J\\) columns (i.e., \\(IJ\\) cells) will be used to record the \\(n_{ij}\\) counts (in the obvious way).8 Let \\(p_{ij}\\) be the proportion of individuals in the population who belong in category \\(i\\) of factor 1 and category \\(j\\) of factor \\(2\\). Then, the probability that a randomly selected individual falls in category \\(i\\) of factor 1 is found by summing over all \\(j\\): \\[\\begin{equation*} p_{i} = \\sum_{j=1}^J p_{ij}\\,, \\end{equation*}\\] and likewise, the probability that a randomly selected individual falls in category \\(j\\) of factor 2 is found by summing over all \\(i\\): \\[\\begin{equation*} p_{j} = \\sum_{i=1}^I p_{ij}\\,. \\end{equation*}\\] The null hypothesis that we will be interested in adopting is \\[\\begin{equation*} H_0 : p_{ij} = p_{i} \\cdot p_{j} \\; \\forall (i,j)\\,, \\tag{4.3} \\end{equation*}\\] that is, that an individual’s category in factor 1 is independent of the category in factor 2. Following the same program as for the single category goodness-of-fit test, we note that, assuming the null hypothesis (4.3) is true, then the expected count in cell \\(i,j\\) is \\[\\begin{equation*} \\operatorname{E}[N_{ij}] = n p_{ij} = m p_{i} p_{j}\\,; \\end{equation*}\\] and we estimate \\(p_i\\) and \\(p_j\\) by the appropriate sample proportion: \\[\\begin{equation*} \\widehat{p}_i = \\frac{n_i}{m}\\,, \\quad n_i = \\sum_{j} n_{ij} \\qquad \\text{(row total)}\\,, \\end{equation*}\\] and \\[\\begin{equation*} \\widehat{p}_j = \\frac{n_j}{m}\\,, \\quad n_j = \\sum_{i} n_{ij}\\qquad \\text{(col total)}\\,. \\end{equation*}\\] Thus, the expected cell count is given by \\[\\begin{equation*} \\widehat{e}_{ij} = m \\widehat{p}_i \\widehat{p}_j = \\frac{n_i n_j}{m}\\,, \\end{equation*}\\] and we assess the goodness of fit between the observed cell count \\(n_ij\\) and the expected cell count \\(\\widehat{e}_ij\\). Proposition 4.2 Null hypothesis \\(H_0 : p_{ij} = p_i p_j\\) for all \\(i=1, \\dots, I\\), \\(j=1, \\dots, J\\). Alternative hypothesis \\(H_a : H_0 \\;\\text{is not true}\\). Test statistic: \\[\\begin{equation*} V = \\sum_{i=1}^I \\sum_{j=1}^J \\frac{(n_{ij} - \\widehat{e}_{ij})^2}{\\widehat{e}_{ij}} \\end{equation*}\\] Rule of thumb, \\(\\widehat{e}_{ij} \\geq 5\\) for all \\(i,j\\), and when \\(H_0\\) is true then the test statistic has approximately \\(\\chi^2((I-1)(J-1))\\) distribution. Upper tail. Here for \\(i=1, \\dots, k\\) we use the notation \\(p_{i0}\\) to denote the value of \\(p_i\\) claimed under the null hypothesis.↩︎ The division by the expected cell counts is to account for possible differences in the relative magnitude of the observed/expected counts.↩︎ Contingency is another word for dependency in this context.↩︎ "],
["anova.html", "5 Analysis of variance (ANOVA) 5.1 Single factor ANOVA test 5.2 Confidence intervals", " 5 Analysis of variance (ANOVA) Analysis of variance, shortened as ANOVA, is a collection of statistical models and estimation procedures for analyzing the variation among different groups. In particular, a single-factor ANOVA provides a hypothesis test regarding the equality of two or more population means, thereby generalizing the one-sample and two-sample \\(\\mathsf{t}\\) tests considered in Sections 2.4.3 and 3.1.3. 5.1 Single factor ANOVA test Suppose that we have \\(k\\) normally distributed populations9 with different means \\(\\mu_1, \\dots, \\mu_k\\) and equal variances \\(\\sigma^2\\). We denote the rv for the \\(j\\)th measurement taken from the \\(i\\)th population by \\(X_{ij}\\) and the corresponding sample observation by \\(x_{ij}\\). For samples of size \\(m_1, \\dots, m_k\\), we denote the sample means \\[\\begin{equation*} \\overline{X}_i = \\frac{1}{m_i} \\sum_{j=1}^{m_i} X_{ij}\\,, \\end{equation*}\\] and sample variances \\[\\begin{equation*} S_i^2 = \\frac{1}{m_i - 1} \\sum_{j=1}^{m_i} (X_{ij} - \\overline{X}_{i})^2\\,, \\end{equation*}\\] for each \\(i = 1, \\dots, k\\); likewise, we denote the associated point estimates for the sample means \\(\\overline{x}_1, \\dots, \\overline{x}_k\\) and the sample variances \\(s_1^2, \\dots, s_k^2\\). The average over all observations \\(m = \\sum m_i\\), called the grand mean, is denoted by \\[\\begin{equation*} \\overline{X} = \\frac{1}{m} \\sum_{i=1}^k \\sum_{j=1}^{m_i} X_{ij}\\,. \\end{equation*}\\] The sample variances \\(s_i^2\\), and hence the sample standard deviations, will generally vary even when the \\(k\\) populations share the same variance; a rule of thumb is that the equality of variances is reasonable if the largest \\(s_i\\) is not much more than two times the smallest. We wish to test the equality of the population means, given by the null hypothesis, \\[\\begin{equation*} H_0 : \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\,, \\end{equation*}\\] versus the alternative hypothesis, \\[\\begin{equation*} H_a : \\text{at least two}\\; \\mu_i \\; \\text{differ}\\,. \\end{equation*}\\] Note that if \\(k=3\\) then \\(H_0\\) is true only if all three means are the same, i.e., \\(\\mu_1 = \\mu_1 = \\mu_3\\), but there are a number of ways which the alternative might hold: \\(\\mu_1 \\neq \\mu_2 = \\mu_3\\) or \\(\\mu_1 = \\mu_2 \\neq \\mu_3\\) or \\(\\mu_1 = \\mu_3 \\neq \\mu_2\\) or \\(\\mu_1 \\neq \\mu_2 \\neq \\mu_3\\). The test procedure is based on comparing a measure of difference in variation among the sample means, i.e., the variation between \\(x_i\\)’s, to a measure of variation within each sample. Definition 5.1 The mean square for treatments is \\[\\begin{equation*} \\mathsf{MSTr} = \\frac{1}{k-1} \\sum_{i=1}^k m_i (\\overline{X}_i - \\overline{X})^2\\,, \\end{equation*}\\] and the mean square error is \\[\\begin{equation*} \\mathsf{MSE} = \\frac{1}{m-k} \\sum_{i=1}^k (m_i - 1) S_i^2 \\,. \\end{equation*}\\] The \\(\\mathsf{MSTr}\\) and \\(\\mathsf{MSE}\\) are statistics that measure, respectively, the variation among sample means and the variation within samples. We will also use \\(\\mathsf{MSTr}\\) and \\(\\mathsf{MSE}\\) to denote calculated values of these statistics. Proposition 5.1 The test statistic \\[\\begin{equation*} F = \\frac{\\mathsf{MSTr}}{\\mathsf{MSE}} \\end{equation*}\\] is the appropriate test statistic for the single-factor ANOVA problem involving \\(k\\) populations (or treatments) with a random sample of size \\(m_1, \\dots, m_k\\) from each. When \\(H_0\\) is true, \\[\\begin{equation*} F \\sim \\mathsf{F}(\\nu_1 = k-1, \\nu_2 = m - k)\\,. \\end{equation*}\\] In the present context a large test statistic value is more constradictory to \\(H_0\\) than a smaller value, therefore the test is upper-tailed, i.e., consider the area \\(F_\\alpha\\) to the right of the critical value \\(F_{\\alpha, \\nu_1, \\nu_2}\\). We reject \\(H_0\\) if the value of the test statistic \\(F &gt; F_\\alpha\\). Example 5.1 Consider the average salary data from lcocal councils in Table 5.1. Is the expected average salary in each nation the same at the \\(5\\%\\) level? Table 5.1: Data and summary sample statistics for Figure 5.1. Nation Average salaries (’000 £) Size \\((m_i)\\) Sample Mean \\((\\overline{x}_i)\\) Sample SD \\((s_i)\\) England 17, 12, 18, 13, 15, 12 6 14.5 2.588 N Ireland 11, 7, 9, 13 4 10.0 2.582 Scotland 15, 10, 13, 14, 13 5 13.0 1.871 Wales 10, 12, 8, 7, 9 5 9.2 1.924 Table 5.1 presents the average salaries (in thousands of pounds) reported from 20 local councils classified by nation (England, N Ireland, Scotland, and Wales). The sample means together with the sample standard deviations are summarized in the table as well as presented using using box plots in Figure 5.1. Figure 5.1: Box plots of the average mean salary data in Table 5.1 indicate five summary statistics: the median, two hinges (first and third quartiles) and two whiskers (extending from the hinge to the most extreme data point within 1.5 * IQR). For \\(\\alpha = 0.05\\), we compute the upper-tail area \\(F_{0.05}\\) i.e. to the right of the critical value \\(F_{0.05, 3, 16}\\) by consulting a statistical table or by using r: qf(1-.05, df1 = 4-1, df2 = 20-4) # alt: qf(.05, df1 = 4-1, df2 = 20-4, lower.tail = FALSE) [1] 3.238872 to find \\(F_{0.05} = 3.2388715\\). The grand mean is \\[\\begin{equation*} \\overline{x} = \\frac{17 + 12 + 18 + \\cdots + 8 + 7 + 9}{20} = 11.9\\,, \\end{equation*}\\] and hence the variation among sample means is given by, \\[\\begin{equation*} \\begin{aligned} \\mathsf{MSTr} &amp;= \\frac{1}{4-1} \\left(m_1(\\overline{x}_1 - \\overline{x})^2 + \\cdots + m_4 (\\overline{x}_4 - \\overline{x})^2\\right) \\\\ &amp;= \\left(6 (14.5-11.9)^2 + 4(10.0 - 11.9)^2 + 5(13.0-11.9)^2 + 5 ( 9.2 - 11.9)^2\\right) / 3 \\\\ &amp;= 32.5 \\,. \\end{aligned} \\end{equation*}\\] The mean square error is \\[\\begin{equation*} \\begin{aligned} \\mathsf{MSE} &amp; = \\frac{1}{20-4} \\left((m_1 - 1)s_1^2 + \\cdots (m_4-1)s_4^2\\right)\\\\ &amp;= \\frac{5(2.588)^2 + 3(2.582)^2 + 4(1.871)^2 + 4(1.924)^2}{16} \\\\ &amp;= 5.14366 \\end{aligned} \\end{equation*}\\] yielding the test statistic value \\[\\begin{equation*} F = \\frac{\\mathsf{MSTr}}{\\mathsf{MSE}} = \\frac{32.5}{5.14366} = 6.3184581 \\,. \\end{equation*}\\] Since \\(F &gt; F_\\alpha\\) we reject \\(H_0\\). The data does not support they hypothesis that the mean salaries in each nation are identical at the \\(5\\%\\) level. 5.2 Confidence intervals In Section 3.1 we gave a CI for comparing population means that involved the difference \\(\\mu_X - \\mu_Y\\). In some settings, we would like to give CIs for more complicated functions of population means \\(\\mu_i\\). Let \\[\\begin{equation*} \\theta = \\sum_{i=1}^k c_i \\mu_i\\,, \\end{equation*}\\] for constants \\(c_i\\). As we assume the \\(X_ij\\) are normally distributed with \\(\\operatorname{E}[X_{ij}] = \\mu_i\\) and \\(\\operatorname{Var}[X_{ij}] = \\sigma^2\\), the estimator \\[\\begin{equation*} \\widehat{\\theta} = \\sum_{i=1}^k c_i \\overline{X}_{i}\\,, \\end{equation*}\\] is normally distributed with \\[\\begin{equation*} \\operatorname{Var}[\\widehat{\\theta}] - \\sum_{i=1}^k c_i^2 \\operatorname{Var}[\\overline{X}_i] = \\sigma^2 \\sum_{i=1}^{k} \\frac{c_i}{m_i}\\,. \\end{equation*}\\] Estimating \\(\\sigma^2\\) by the and forming \\(\\widehat{\\sigma}_{\\widehat{\\theta}}\\) results in a \\(\\mathsf{t}\\) variable \\[\\begin{equation*} \\frac{\\widehat{\\theta} - \\theta}{\\widehat{\\sigma}_{\\widehat{\\theta}}}\\,. \\end{equation*}\\] Proposition 5.2 A \\(100(1-\\alpha)\\%\\) CI for \\(\\sum c_i \\mu_i\\) is given by \\[\\begin{equation*} \\sum_{i=1}^k c_i \\overline{x}_i \\pm t_{\\alpha/2, m-k} \\sqrt{\\mathsf{MSE} \\sum_{i=1}^k \\frac{c_i}{m_i}}\\,. \\end{equation*}\\] Example 5.2 Determine a \\(90\\%\\) CI for the difference in mean average salary for councils in Scotland and England, based on the data available in Table 5.1 For \\(\\alpha = 0.10\\), the critical value \\(t_{0.05, 16} = 1.7458837\\) is found by looking in a table of \\(\\mathsf{t}\\) critical values or by using r: qt(1-0.1/2, df = 20 - 4) # alt: qt(0.1/2, 16, lower.tail = FALSE) [1] 1.745884 Then for the function \\(\\overline{x}_2 - \\overline{x_1}\\), \\[\\begin{equation*} \\begin{aligned} (\\overline{x}_{Eng} - \\overline{x}_{Sco}) \\pm&amp; t_{0.05, 16} \\sqrt{\\mathsf{MSE}} \\sqrt{\\frac{1}{m_{Eng}} + \\frac{1}{m_{Sco}}} \\\\ &amp; = (14.5 - 13.0) \\pm 1.7458837 \\sqrt{5.14366} \\sqrt{\\frac{1}{6} + \\frac{1}{5}} \\\\ &amp; = 1.5 \\pm 2.3976575\\,. \\end{aligned} \\end{equation*}\\] Thus a \\(90\\%\\) confidence interval for \\(\\mu_{Eng} - \\mu_{Sco}\\) is \\((-0.8976575\\,, 3.8976575)\\). How does this result compare to the method in Section 3.1.3? In the context of ANOVA, these \\(k\\) populations are often referred to as treatment distributions.↩︎ "],
["linear-models.html", "6 Linear regression 6.1 Simple linear regression models 6.2 Correlation", " 6 Linear regression 6.1 Simple linear regression models 6.2 Correlation "],
["quality-control.html", "7 Quality Control 7.1 Control Charts", " 7 Quality Control 7.1 Control Charts "],
["references.html", "References", " References DeGroot, M, and M Schervish. 2001. Probability and Statistics. 3rd ed. Addison-Wesley. Devore, Jay L. 2016. Probability and Statistics for Engineering and the Sciences. 9th ed. Cengage Learning. Rice, John A. 2006. Mathematical Statistics and Data Analysis. Cengage Learning. Wasserman, Larry. 2004. All of Statistics. Springer-Verlag, New York. https://doi.org/10.1007/978-0-387-21736-9. "]
]
