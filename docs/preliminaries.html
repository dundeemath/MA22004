<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Preliminaries | MA22004 - Statistics II</title>
  <meta name="description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Preliminaries | MA22004 - Statistics II" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://dundeemath.github.io/MA22004/assets/images/cover_small.jpg" />
  <meta property="og:description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="github-repo" content="dundeemath/MA22004" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Preliminaries | MA22004 - Statistics II" />
  
  <meta name="twitter:description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="twitter:image" content="https://dundeemath.github.io/MA22004/assets/images/cover_small.jpg" />

<meta name="author" content="Dr Eric Hall" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="writing.html"/>
<link rel="next" href="sampling-distributions.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MA22004</a></li>

<li class="divider"></li>
<li class="part"><span><b>Module Documents</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-your-instructor"><i class="fa fa-check"></i>About your instructor</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="labs.html"><a href="labs.html"><i class="fa fa-check"></i>Lab Guide</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html"><i class="fa fa-check"></i>Writing Lab Reports</a>
<ul>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-assess"><i class="fa fa-check"></i>Assessment Criteria</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-content"><i class="fa fa-check"></i>Content</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-present"><i class="fa fa-check"></i>Presentation</a>
<ul>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-plots"><i class="fa fa-check"></i>Plots</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-math"><i class="fa fa-check"></i>Mathematical formulas</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-eng"><i class="fa fa-check"></i>Writing</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-format"><i class="fa fa-check"></i>Formatting</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Lecture Notes</b></span></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i>Preliminaries</a>
<ul>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#notation"><i class="fa fa-check"></i>Notation</a></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#abbreviations"><i class="fa fa-check"></i>Abbreviations</a></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#sample-space-events-probabilities"><i class="fa fa-check"></i>Sample space, events, probabilities</a></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#random-variables"><i class="fa fa-check"></i>Random variables</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>1</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>1.1</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#facts-normals"><i class="fa fa-check"></i><b>1.1.1</b> Some useful facts about normal variates</a></li>
<li class="chapter" data-level="1.1.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#empirical-rule-68-95-99.7-rule"><i class="fa fa-check"></i><b>1.1.2</b> Empirical rule (<span class="math inline">\(68-95-99.7\)</span> rule)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#t-distribution"><i class="fa fa-check"></i><b>1.2</b> <span class="math inline">\(\mathsf{t}\)</span> distribution</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#facts-t"><i class="fa fa-check"></i><b>1.2.1</b> Properties of <span class="math inline">\(\mathsf{t}\)</span> distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#chisq-distribution"><i class="fa fa-check"></i><b>1.3</b> <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="1.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#F-distribution"><i class="fa fa-check"></i><b>1.4</b> <span class="math inline">\(\mathsf{F}\)</span> distribution</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>2</b> Basics of statistical inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#point-estimation"><i class="fa fa-check"></i><b>2.1</b> Point estimation</a></li>
<li class="chapter" data-level="2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>2.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="2.3" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>2.3</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inference-single-sample.html"><a href="inference-single-sample.html"><i class="fa fa-check"></i><b>3</b> Inferences based on a single sample</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-means"><i class="fa fa-check"></i><b>3.1</b> Estimating means</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-normal-var-known"><i class="fa fa-check"></i><b>3.1.1</b> Mean of a normal population with known variance</a></li>
<li class="chapter" data-level="3.1.2" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-large-sample"><i class="fa fa-check"></i><b>3.1.2</b> Mean of a population with unknown variance (large-sample)</a></li>
<li class="chapter" data-level="3.1.3" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-normal-var-unknown"><i class="fa fa-check"></i><b>3.1.3</b> Mean of a normal population with unknown variance</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-proportions"><i class="fa fa-check"></i><b>3.2</b> Estimating proportions</a></li>
<li class="chapter" data-level="3.3" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-variances"><i class="fa fa-check"></i><b>3.3</b> Estimating variances</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-two-samples.html"><a href="inference-two-samples.html"><i class="fa fa-check"></i><b>4</b> Inferences based on two samples</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means"><i class="fa fa-check"></i><b>4.1</b> Comparing means</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-normpops-vars-known"><i class="fa fa-check"></i><b>4.1.1</b> Comparing means of normal populations when variances are known</a></li>
<li class="chapter" data-level="4.1.2" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-large-samples"><i class="fa fa-check"></i><b>4.1.2</b> Comparing means when the sample sizes are large</a></li>
<li class="chapter" data-level="4.1.3" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-normpops-vars-unknown"><i class="fa fa-check"></i><b>4.1.3</b> Comparing means of normal populations when variances are unknown and the sample size is small</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-paired-samples"><i class="fa fa-check"></i><b>4.2</b> Comparing paired samples</a></li>
<li class="chapter" data-level="4.3" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-proportions"><i class="fa fa-check"></i><b>4.3</b> Comparing proportions</a></li>
<li class="chapter" data-level="4.4" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-variances"><i class="fa fa-check"></i><b>4.4</b> Comparing variances</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>5</b> Analysis of variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="anova.html"><a href="anova.html#anova-single-factor-test"><i class="fa fa-check"></i><b>5.1</b> Single factor ANOVA test</a></li>
<li class="chapter" data-level="5.2" data-path="anova.html"><a href="anova.html#anova-ci"><i class="fa fa-check"></i><b>5.2</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>6</b> Linear regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-models.html"><a href="linear-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Simple linear regression models</a></li>
<li class="chapter" data-level="6.2" data-path="linear-models.html"><a href="linear-models.html#ls-estimate-var"><i class="fa fa-check"></i><b>6.2</b> Estimating <span class="math inline">\(\sigma^2\)</span> for linear regressions</a></li>
<li class="chapter" data-level="6.3" data-path="linear-models.html"><a href="linear-models.html#inference-ls"><i class="fa fa-check"></i><b>6.3</b> Inferences for least-squares parameters</a></li>
<li class="chapter" data-level="6.4" data-path="linear-models.html"><a href="linear-models.html#correlation"><i class="fa fa-check"></i><b>6.4</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="categorical-data.html"><a href="categorical-data.html"><i class="fa fa-check"></i><b>7</b> Categorical data</a>
<ul>
<li class="chapter" data-level="7.1" data-path="categorical-data.html"><a href="categorical-data.html#multinomial-experiments"><i class="fa fa-check"></i><b>7.1</b> Multinomial experiments</a></li>
<li class="chapter" data-level="7.2" data-path="categorical-data.html"><a href="categorical-data.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>7.2</b> Goodness-of-fit for a single factor</a></li>
<li class="chapter" data-level="7.3" data-path="categorical-data.html"><a href="categorical-data.html#test-for-the-independence-of-factors"><i class="fa fa-check"></i><b>7.3</b> Test for the independence of factors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="quality-control.html"><a href="quality-control.html"><i class="fa fa-check"></i><b>8</b> Quality control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="quality-control.html"><a href="quality-control.html#control-charts"><i class="fa fa-check"></i><b>8.1</b> Control charts</a></li>
</ul></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html"><i class="fa fa-check"></i>Curated Content</a>
<ul>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-0"><i class="fa fa-check"></i>Investigation 0</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-1"><i class="fa fa-check"></i>Investigation 1</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-2"><i class="fa fa-check"></i>Investigation 2</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-3"><i class="fa fa-check"></i>Investigation 3</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-4"><i class="fa fa-check"></i>Investigation 4</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-5"><i class="fa fa-check"></i>Investigation 5</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-6"><i class="fa fa-check"></i>Investigation 6</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-7"><i class="fa fa-check"></i>Investigation 7</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-8"><i class="fa fa-check"></i>Investigation 8</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="http://uod.ac.uk/sig-home" rel="nofollow"><img width="73" height="73" src="https://www.dundee.ac.uk/media/dundeewebsite/themes/brandnewhope/img/university-of-dundee-email-favicon.png" alt="University of Dundee shield logo"> </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MA22004 - Statistics II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<span class="math inline">\(\DeclareMathOperator{\E}{\mathbf{E}}\)</span>
<span class="math inline">\(\DeclareMathOperator{\Var}{Var}\)</span>
<span class="math inline">\(\DeclareMathOperator{\Cov}{Cov}\)</span>
<span class="math inline">\(\DeclareMathOperator{\corr}{corr}\)</span>
<span class="math inline">\(\newcommand{\se}{\mathsf{se}}\)</span>
<span class="math inline">\(\DeclareMathOperator{\sd}{sd}\)</span>
<div id="preliminaries" class="section level1 unnumbered hasAnchor">
<h1>Preliminaries<a href="preliminaries.html#preliminaries" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This section contains a comment on notation, a list of abbreviations and a (very quick) review of probability.</p>
<div id="notation" class="section level2 unnumbered hasAnchor">
<h2>Notation<a href="preliminaries.html#notation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Uppercase roman letters, e.g., <span class="math inline">\(X\)</span>, will typically denote random variables (rvs); lower case letters, e.g., <span class="math inline">\(x\)</span>, will represent a particular value (observation) of a rv. Rvs have probability distributions. Distributions are typically characterised by <em>parameters</em> that describe population characteristics. In the present module, we will adopt the (frequentists) view that parameters are fixed real numbers that are often unknown and must be estimated from data. Statistical inference is a tool that will help us to do this.</p>
<div class="warningblock">
<p>Statistical models comprise both rvs and parameters. Be careful not to confuse them!</p>
</div>
<p>For a random variable <span class="math inline">\(X\)</span> that has a distribution <span class="math inline">\(F\)</span> depending on a parameter <span class="math inline">\(\theta\)</span>, we will write <span class="math inline">\(X \sim F(\theta)\)</span>.</p>
<div class="warningblock">
<p>We write <span class="math inline">\(X \sim F\)</span> to indicate <span class="math inline">\(X\)</span> has distribution <span class="math inline">\(F\)</span>, not “<span class="math inline">\(X\)</span> is approximately <span class="math inline">\(F\)</span>!</p>
</div>
</div>
<div id="abbreviations" class="section level2 unnumbered hasAnchor">
<h2>Abbreviations<a href="preliminaries.html#abbreviations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Abbreviation
</th>
<th style="text-align:left;">
Expanded
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
pdf
</td>
<td style="text-align:left;">
probability density function
</td>
</tr>
<tr>
<td style="text-align:left;">
cdf
</td>
<td style="text-align:left;">
cumulative distribution function
</td>
</tr>
<tr>
<td style="text-align:left;">
rv
</td>
<td style="text-align:left;">
random variable
</td>
</tr>
<tr>
<td style="text-align:left;">
iid
</td>
<td style="text-align:left;">
independent and identically distributed
</td>
</tr>
<tr>
<td style="text-align:left;">
obs
</td>
<td style="text-align:left;">
observations
</td>
</tr>
<tr>
<td style="text-align:left;">
CI
</td>
<td style="text-align:left;">
confidence interval
</td>
</tr>
<tr>
<td style="text-align:left;">
df
</td>
<td style="text-align:left;">
degrees of freedom
</td>
</tr>
</tbody>
</table>
<!-- ## Quick review of probability {.unnumbered} -->
</div>
<div id="sample-space-events-probabilities" class="section level2 unnumbered hasAnchor">
<h2>Sample space, events, probabilities<a href="preliminaries.html#sample-space-events-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>sample space</strong> <span class="math inline">\(\Omega\)</span> is a set of possible outcomes of an experiment. Points <span class="math inline">\(\omega \in \Omega\)</span> are <strong>sample outcomes</strong> or realizations. Subsets <span class="math inline">\(A \subset \Omega\)</span> are called <strong>events</strong>.</p>
<div class="example">
<p><span id="exm:sample-space" class="example"><strong>Example 0.1  </strong></span>Consider an experiment where we <em>measures the petal widths</em> from a randomly sampled cyclamen flowers. Before we observe the petal width, there is uncertainty that we can model using a sample space of events. The sample space is <span class="math inline">\(\Omega = (0, \infty)\)</span>, since measurements of length should be positive (practically, the lengths will have a finite size, too). Each <span class="math inline">\(\omega \in \Omega\)</span> is a measurement of petal width for a cyclamen flower. Consider an event <span class="math inline">\(A = (5, 12]\)</span>; this is the event that the petal width is larger than <span class="math inline">\(5\)</span> but less than or equal to <span class="math inline">\(12\)</span>. Remember, we use probability to model uncertainty <em>before</em> we observe the petal width — after we take a measurement, the petal width is no longer uncertain (we have collected a statistic).</p>
</div>
<p>As sample spaces and events are described using sets, we recall the following notations, definitions, and laws about set theory. Let <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(A_1, A_2, \dots\)</span> be events in a sample space <span class="math inline">\(\Omega\)</span>.</p>
<ul>
<li><p><strong>complement</strong>: <span class="math inline">\(A^c = \{ \omega \in \Omega: \omega \notin A\}\)</span>.</p></li>
<li><p><strong>null event</strong>: <span class="math inline">\(\emptyset = \Omega^c\)</span>.</p></li>
<li><p><strong>intersection</strong>: <span class="math inline">\(A \cap B = \{\omega \in \Omega : \omega \in A \text{ and } \omega \in B\}\)</span>. In particular, for <span class="math inline">\(A_1, A_2, \dots\)</span>, then <span class="math display">\[\bigcap_{i=1}^\infty A_i = \{\omega \in \Omega : \omega \in A_i \text{ for all } i \}\,.\]</span></p></li>
<li><p><strong>difference</strong>: <span class="math inline">\(A \setminus B = \{\omega \in \Omega : \omega \in A, \omega \notin B\}\)</span>.</p></li>
<li><p><strong>size</strong>: <span class="math inline">\(|A|\)</span> denotes the number of elements in <span class="math inline">\(A\)</span>.</p></li>
<li><p><strong>disjoint</strong>: <span class="math inline">\(A_i \cap A_j = \emptyset\)</span>, for <span class="math inline">\(i\neq j\)</span>.</p></li>
<li><p><strong>partition</strong>: disjoint <span class="math inline">\(A_1, A_2, \dots\)</span> such that <span class="math inline">\(\bigcup_{i=1}^\infty A_i = \Omega\)</span>.</p></li>
<li><p><strong>indicator</strong>: <span class="math inline">\(I_A(\omega) = I(\omega \in A) = \{1 \text{ if } \omega \in A; 0 \text{ if } \omega \notin A\}\)</span>.</p></li>
<li><p><strong>monotone increasing</strong>: <span class="math inline">\(A_1 \subset A_2 \subset \dots\)</span> and define limit <span class="math display">\[\lim_{n \to \infty}A_n = \bigcup_{i=1}^\infty A_i\,.\]</span></p></li>
<li><p><strong>monotone decreasing</strong>: <span class="math inline">\(A_1 \supset A_2 \supset \dots\)</span> and define limit <span class="math display">\[\lim_{n \to \infty} A_n = \bigcap_{i=1}^\infty A_i\,.\]</span></p></li>
<li><p><strong>distributive laws</strong>: <span class="math display">\[A\cap (B\cup C) = (A\cap B) \cup (A \cap C)\,,\]</span> <span class="math display">\[A\cup(B\cap C) = (A \cup B) \cap (A\cup C)\,.\]</span></p></li>
<li><p><strong>De Morgan’s laws</strong>: <span class="math display">\[(A \cap B)^c = A^c \cup B^c\,,\]</span> <span class="math display">\[(A\cup B)^c = A^c \cap B^c\,.\]</span></p></li>
</ul>
<p>We assign probabilities to events in our sample space.</p>
<div class="definition">
<p><span id="def:prob" class="definition"><strong>Definition 0.1  </strong></span>A <strong>probability distribution</strong> is a function <span class="math inline">\(P : \Omega \to \mathbf{R}\)</span> satisfying three axioms:
1. <span class="math inline">\(P(A) \geq 0\)</span> for every <span class="math inline">\(A \subset \Omega\)</span> (positivity),
2. <span class="math inline">\(P(\Omega) = 1\)</span> (totality),
3. if <span class="math inline">\(A_1, A_2, \dots\)</span> are disjoint subsets of <span class="math inline">\(\Omega\)</span>, then <span class="math display">\[P(\cup_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)\,.\]</span></p>
</div>
<div class="tipblock">
<p>We can interpret <span class="math inline">\(P(A)\)</span> as representing:</p>
<ul>
<li><strong>frequency</strong>, i.e., the long-run proportion of times <span class="math inline">\(A\)</span> is true (the <em>frequentist</em> perspective),</li>
<li><strong>degrees of belief</strong>, i.e, as a measure of the observer’s strength of belief that <span class="math inline">\(A\)</span> is true (the <em>Bayesian</em> perspective).</li>
</ul>
</div>
<div class="theorem">
<p><span id="thm:pie" class="theorem"><strong>Theorem 0.1  </strong></span>The principal of inclusion-exclusion (PIE),
<span class="math display">\[P(A\cup B) = P(A) + P(B) - P(A\cap B)\,.\]</span></p>
</div>
<p>PIE follows from the definition of a probability distributions and facts about set theory.</p>
<div class="definition">
<p><span id="def:prob-finite" class="definition"><strong>Definition 0.2  </strong></span>For events <span class="math inline">\(A\)</span> from finite sample spaces <span class="math inline">\(\Omega\)</span>, we <strong>assign probabilities</strong> according to:
<span class="math display">\[P(A) = \frac{|A|}{|\Omega|} \,.\]</span></p>
</div>
<p>For finite sample spaces, we assign probabilities according to their long-run frequency of occurring. For an event <span class="math inline">\(A\)</span>, this is the ratio of the size of <span class="math inline">\(A\)</span> (number of ways <span class="math inline">\(A\)</span> can happen) to the size of <span class="math inline">\(\Omega\)</span> (number of total outcomes).</p>
<div class="definition">
<p><span id="def:indep" class="definition"><strong>Definition 0.3  </strong></span>Events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong>, i.e., <span class="math inline">\(A \perp \!\!\! \perp B\)</span>, iff <span class="math inline">\(P(A\cap B) = P(A)P(B)\)</span>.</p>
</div>
<p>That is, <em>events</em> <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if the probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring is equal to the the probability <span class="math inline">\(A\)</span> occurring times the probability of <span class="math inline">\(B\)</span> occurring.</p>
<div class="definition">
<p><span id="def:cond-prob" class="definition"><strong>Definition 0.4  </strong></span>If <span class="math inline">\(P(B) &gt; 0\)</span>, then <span class="math display">\[P(A \mid B) = \frac{P(A \cap B)}{P(B)}\,.\]</span></p>
</div>
<p>Note that: - <span class="math inline">\(P(\cdot \mid B)\)</span> satisfies the axioms of probability, for fixed <span class="math inline">\(B\)</span>, - in general, <span class="math inline">\(P(A \mid \cdot)\)</span> is not a probability for fixed <span class="math inline">\(A\)</span>, and, - in general, <span class="math inline">\(P(A\mid B) \neq P(B \mid A)\)</span>.</p>
<div class="theorem">
<p><span id="thm:bayes" class="theorem"><strong>Theorem 0.2  </strong></span>(Bayes theorem) Let events <span class="math inline">\(A_1, \dots, A_k\)</span> parition <span class="math inline">\(\Omega\)</span>, with <span class="math inline">\(P(A_i) &gt; 0\)</span>.</p>
<p>If <span class="math inline">\(P(B) &gt; 0\)</span>, then
<span class="math display">\[P(A_i \mid B) = \frac{P(B\mid A_i) P(A_i)}{\sum_j P(B \mid A_j) P(A_j)}\,.\]</span></p>
</div>
<p>Generally, it is not feasible to assing probabilities to <em>all</em> subsets of <span class="math inline">\(\Omega\)</span> (e.g., if is infinite). In that case, we restrict to our attention to a <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\(\mathcal{A}\)</span> (also called, <span class="math inline">\(\sigma\)</span>-field), which is a collection of sets satisfying: 1. <span class="math inline">\(\emptyset \in \mathcal{A}\)</span>, 2. if <span class="math inline">\(A_1, A_2, \dots, \in \mathcal{A}\)</span> then <span class="math inline">\(\cup_{i = 1}^\infty A_i \in \mathcal{A}\)</span>, 3. <span class="math inline">\(A\in \mathcal{A} \implies A^c \in \mathcal{A}\)</span>.</p>
<p>Sets in <span class="math inline">\(\mathcal{A}\)</span> are said to be <strong>measurable</strong> and <span class="math inline">\((\Omega, \mathcal{A})\)</span> is a measure space. If <span class="math inline">\(P\)</span> is a probability defined on <span class="math inline">\(\mathcal{A}\)</span>, then <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> is called a <strong>probability space</strong>.</p>
<p>E.g., when <span class="math inline">\(\Omega \equiv \mathbf{R}\)</span>, we take <span class="math inline">\(\mathcal{A}\)</span> to be the smallest <span class="math inline">\(\sigma\)</span>-field containing all open subsets of <span class="math inline">\(\mathbf{R}\)</span>, which is called the Borel <span class="math inline">\(\sigma\)</span>-field. If you find these details interesting, take: MA42008 Mathematical Statistics and MA51007 Measure Theory!</p>
</div>
<div id="random-variables" class="section level2 unnumbered hasAnchor">
<h2>Random variables<a href="preliminaries.html#random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="tipblock">
<p>How do we link sample spaces and events to data?</p>
</div>
<p>We use random variables to link sample spaces and events to data.</p>
<div class="definition">
<p><span id="def:rv" class="definition"><strong>Definition 0.5  </strong></span>A <em>random variable</em> (rv) is a mapping <span class="math inline">\(X : \Omega \to \mathbf{R}\)</span> that maps <span class="math inline">\(\omega \in \Omega \mapsto X(\omega)\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:rv-1" class="example"><strong>Example 0.2  </strong></span>Consider a coin flipping experiment where you flip a fair coin eight times. Let <span class="math inline">\(X\)</span> be the number of heads in the sequence. If three heads occur, e.g., <span class="math inline">\(\omega = HTTTTTHH\)</span>, then <span class="math inline">\(X(\omega) = 3\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:rv-2" class="example"><strong>Example 0.3  </strong></span>Consider an experiment where you draw a point a random from the unit disk. Then <span class="math inline">\(\Omega = \{(x,y) : x^2 + y^2 \leq 1\}\)</span> and a typical outcome will be the pair <span class="math inline">\(\omega = (x,y)\)</span>. Some random variables to consider are <span class="math inline">\(X(\omega) = x\)</span>, <span class="math inline">\(Y(\omega) = y\)</span>, <span class="math inline">\(Z(\omega) = x+y\)</span>, and <span class="math inline">\(W(\omega) = \sqrt{x^2 + y^2}\)</span>.</p>
</div>
<div class="definition">
<p><span id="def:prob-rv" class="definition"><strong>Definition 0.6  </strong></span>Given <span class="math inline">\(X\)</span> and <span class="math inline">\(A \subset \mathbf{R}\)</span>, we define
<span class="math display">\[X^{-1}(A) = \{\omega \in \Omega : X(\omega) \in A\}\]</span>
and let <span class="math display">\[P(X \in A) = P(X^{-1}(A)) = P(\{\omega \in \Omega : X(\omega) \in A\})\,,\]</span>
e.g., <span class="math inline">\(P(X=x) = P(X^{-1}(x)) = P(\{\omega \in \Omega : X(\omega) = x\})\)</span>.</p>
</div>
<div class="warningblock">
<p><span class="math inline">\(X\)</span> denotes a rv and <span class="math inline">\(x\)</span> denotes a particular value of <span class="math inline">\(X\)</span>. You would never write <span class="math inline">\(P(X)\)</span>, would you!?</p>
</div>
<div class="example">
<p><span id="exm:rv-3" class="example"><strong>Example 0.4  </strong></span>Consider a coin flipping experiment where you flip a fair coin twice. Let <span class="math inline">\(X\)</span> be the number of heads. Then
<span class="math display">\[P(X=0) = P(\{TT\}) = \frac{1}{4}\,,\]</span>
<span class="math display">\[P(X=1) = P(\{HT\} \cup \{TH\}) = P(\{HT\}) + P(\{TH\}) = \frac{1}{2}\,,\]</span>
<span class="math display">\[P(X=2) = P(\{HH\}) = \frac{1}{4}\,.\]</span></p>
</div>
<div class="definition">
<p><span id="def:cdf" class="definition"><strong>Definition 0.7  </strong></span>The <em>cumulative distribution function</em> (cdf), <span class="math inline">\(F_X:\mathbf{R} \to [0,1]\)</span>, is defined by <span class="math inline">\(F_X(x) = P(X \leq x)\)</span>.</p>
</div>
<p>Note that a cdf completely determines the distribution of a random variable.</p>
<div class="theorem">
<p><span id="thm:cdf-determines-dist" class="theorem"><strong>Theorem 0.3  </strong></span>Let <span class="math inline">\(X\)</span> have cdf <span class="math inline">\(F\)</span> and <span class="math inline">\(Y\)</span> have cdf <span class="math inline">\(G\)</span>. If <span class="math inline">\(F(x) = G(x)\)</span> for all <span class="math inline">\(x\)</span>, then <span class="math inline">\(P(X \in A)= P(Y \in A) \forall A \in \mathbf{R}\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:cdf-properties" class="theorem"><strong>Theorem 0.4  </strong></span></p>
<span class="math inline">\(F : \mathbf{R} \to [0,1]\)</span> is a cdf for some <span class="math inline">\(P\)</span> iff,
</div>
<p>For a rv <span class="math inline">\(X\)</span> we say <span class="math inline">\(X\)</span> is <em>discrete</em> if it assumes at most a <em>countable</em> number of (discrete) values. For a discrete sample space, the collection of all probabilities of <span class="math inline">\(X(\omega)\)</span> gives us a probability distribution.</p>
<div class="definition">
<p><span id="def:pmf" class="definition"><strong>Definition 0.8  </strong></span>A <em>probability density function</em> (pdf) for a discrete rv <span class="math inline">\(X\)</span> is <span class="math inline">\(f_X(x) = P(X = x)\)</span>.</p>
</div>
<div class="warningblock">
<p>Since the probabilities for a discrete rv form “point masses,” the pdf is sometimes called a probability mass function.</p>
</div>
<p>Note, from the axioms of probability, that the pdf for a discrete random variable therefore satisfies <span class="math inline">\(f(x) \geq 0\)</span>, <span class="math inline">\(\forall x \in \mathbf{R}\)</span> and <span class="math inline">\(\sum_i f(x_i) = 1\)</span>.</p>
A rv <span class="math inline">\(X\)</span> is <em>continuous</em> if there exists a continuous function <span class="math inline">\(f_X\)</span> such that,
<div class="definition">
<p><span id="def:pdf" class="definition"><strong>Definition 0.9  </strong></span>A <span class="math inline">\(f_X\)</span> satisfying the three properties above is a <em>probability density function</em> for the continous rv <span class="math inline">\(X\)</span>.</p>
</div>
<div class="warningblock">
<p>If <span class="math inline">\(X\)</span> is continuous, then <span class="math inline">\(P(X = x) = 0\)</span> for every <span class="math inline">\(x\)</span>. That is, <span class="math display">\[P(a \leq X \leq b) = P(a &lt; X \leq b) = P(a \leq X &lt; b) = P(a &lt; X &lt; b)\,.\]</span></p>
</div>
<p>The cdf is related to the pdf by the derivative (difference). If <span class="math inline">\(X\)</span> is continuous:
<span class="math display">\[F_X(x) = P(X \leq x) =
int_{-\infty}^x f_X(t) dt\]</span> and <span class="math inline">\(f_X(x) = F_X\prime(x)\)</span> at all <span class="math inline">\(x\)</span> at which <span class="math inline">\(F_X\)</span> is differentiable.
(Likewise, if <span class="math inline">\(X\)</span> is discrete,
<span class="math inline">\(F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)\)</span>.)</p>
<div class="definition">
<p><span id="def:quantile" class="definition"><strong>Definition 0.10  </strong></span>Let <span class="math inline">\(X\)</span> be a rv with cdf <span class="math inline">\(F\)</span>. The inverse cdf, or <em>quantile function</em>, is defined by
<span class="math display">\[F^{-1}(q) = \inf \{x : F(x) &gt; q\}\]</span> for <span class="math inline">\(q \in [0,1]\)</span>. If <span class="math inline">\(F\)</span> is monotonic increasing and continuous then <span class="math inline">\(F^{-1}(q)\)</span> is the unique real number <span class="math inline">\(x\)</span> such that <span class="math inline">\(F(x) = q\)</span>.</p>
</div>
<p>Some quantiles get used more than others (and therefore get names). Important quantiles include, <span class="math inline">\(F^{-1}(\frac{1}{4})\)</span> is the first quantile, <span class="math inline">\(F^{-1}(\frac{1}{2})\)</span> is the median, and <span class="math inline">\(F^{-1}(\frac{3}{4})\)</span> is the third quantile.</p>
<div class="definition">
<p><span id="def:equal-dist" class="definition"><strong>Definition 0.11  </strong></span>We say <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <em>equal in distribution</em>, <span class="math inline">\(X \equiv Y\)</span>, if <span class="math inline">\(F_X(x) = F_Y(x)\)</span> for all <span class="math inline">\(x\)</span>.</p>
</div>
<div class="warningblock">
<p>Note that equality in distribution does not mean that the random variables are the same. Rather, probabilityu statements are the same.</p>
<p>Suppose <span class="math inline">\(P(X = 1) = P(X = -1) = \frac{1}{2}\)</span>. Let <span class="math inline">\(Y = -X\)</span>. Then <span class="math inline">\(P(Y = 1) = P(Y = -1) = \frac{1}{2}\)</span>. Thus, <span class="math inline">\(X \equiv Y\)</span>, but <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not equal; in fact, <span class="math inline">\(P(X = Y) = 0\)</span>.</p>
</div>
<p>We sometimes consider more than one random variable, taken to together. This leads to the concept of a joint and marginal densities.</p>
<div class="definition">
<p><span id="def:joint-pdf" class="definition"><strong>Definition 0.12  </strong></span></p>
A <em>joint pdf</em> for <span class="math inline">\((X,Y)\)</span> satisfies
</div>
<div class="definition">
<p><span id="def:joint-cdf" class="definition"><strong>Definition 0.13  </strong></span>A <em>joint cdf</em> is given by <span class="math inline">\(F(x,y) = P(X\leq x, Y\leq y)\)</span>.</p>
</div>
<div class="definition">
<p><span id="def:marginals" class="definition"><strong>Definition 0.14  </strong></span>For <span class="math inline">\(X,Y\)</span> with joint pdf <span class="math inline">\(f(x,y)\)</span>, we define the marginals for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as <span class="math inline">\(f_X(x) \int f(x,y) dy\)</span> and <span class="math inline">\(f_Y(y) = \int f(x,y) dx\)</span>, respectively.</p>
</div>
<p>We also have a notion of independence for rvs.</p>
<div class="definition">
<p><span id="def:indep-rv" class="definition"><strong>Definition 0.15  </strong></span>Rvs <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are *independent$ if <span class="math inline">\(P(X \in A, Y \in B) = P(X \in A) P(Y \in B)\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:pdf-indep-rv" class="theorem"><strong>Theorem 0.5  </strong></span>Let <span class="math inline">\(X,Y\)</span> have joint <span class="math inline">\(f_{XY}\)</span>. Then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent iff <span class="math inline">\(f_{XY} = f_X \cdot f_Y\)</span> for all <span class="math inline">\(x,y\)</span>.</p>
</div>
<p>If <span class="math inline">\(X_1, \dots X_n\)</span> are independent and each as the same marginal distribution with cdf <span class="math inline">\(F\)</span>, we say <span class="math inline">\(X_1, \dots, X_n\)</span> are iid and write <span class="math inline">\(X_1, \dots, X_n \sim F\)</span> iid. We also write <span class="math inline">\(X_1, \dots, X_n \sim f\)</span> if <span class="math inline">\(F\)</span> has corresponding density <span class="math inline">\(f\)</span>, when no confusion arises.</p>
<div class="definition">
<p><span id="def:sample" class="definition"><strong>Definition 0.16  </strong></span><span class="math inline">\(X_1, \dots, X_n \sim F\)</span> iid is a <em>random sample of size <span class="math inline">\(n\)</span> from <span class="math inline">\(F\)</span></em>.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="writing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sampling-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dundeemath/MA22004/edit/master/00-prelim.Rmd",
"text": "Suggest an edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ma22004.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true,
"highlight": "pygments",
"number_sections": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
