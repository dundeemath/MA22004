<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Inferences based on a single sample | MA22004 - Statistics II</title>
  <meta name="description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Inferences based on a single sample | MA22004 - Statistics II" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://dundeemath.github.io/MA22004/assets/images/cover_small.jpg" />
  <meta property="og:description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="github-repo" content="dundeemath/MA22004" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Inferences based on a single sample | MA22004 - Statistics II" />
  
  <meta name="twitter:description" content="Module notes. Mathematics Division, School of Science &amp; Engineering, University of Dundee." />
  <meta name="twitter:image" content="https://dundeemath.github.io/MA22004/assets/images/cover_small.jpg" />

<meta name="author" content="Dr Eric Hall" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistical-inference.html"/>
<link rel="next" href="inference-two-samples.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MA22004</a></li>

<li class="divider"></li>
<li class="part"><span><b>Module Documents</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-your-instructor"><i class="fa fa-check"></i>About your instructor</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html"><i class="fa fa-check"></i>Module Guide</a>
<ul>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-organization"><i class="fa fa-check"></i>Organisation</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-timetable"><i class="fa fa-check"></i>Timetable</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-prerecs"><i class="fa fa-check"></i>Pre-requisites</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-books"><i class="fa fa-check"></i>Recommended Books</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-assessment"><i class="fa fa-check"></i>Assessment</a>
<ul>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-assessment-coursework"><i class="fa fa-check"></i>Coursework</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-assessment-exams"><i class="fa fa-check"></i>Class Tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-commitment"><i class="fa fa-check"></i>Your Commitment</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-calcs"><i class="fa fa-check"></i>Approved Calculators</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-support"><i class="fa fa-check"></i>Study Support</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-disability"><i class="fa fa-check"></i>Disability</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-honesty"><i class="fa fa-check"></i>Academic Honesty</a></li>
<li class="chapter" data-level="" data-path="cg.html"><a href="cg.html#cg-questionaire"><i class="fa fa-check"></i>Module Questionaires</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="deadlines.html"><a href="deadlines.html"><i class="fa fa-check"></i>Deadlines</a></li>
<li class="chapter" data-level="" data-path="labs.html"><a href="labs.html"><i class="fa fa-check"></i>Lab Guide</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html"><i class="fa fa-check"></i>Writing Lab Reports</a>
<ul>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-assess"><i class="fa fa-check"></i>Assessment Criteria</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-content"><i class="fa fa-check"></i>Content</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-present"><i class="fa fa-check"></i>Presentation</a>
<ul>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-plots"><i class="fa fa-check"></i>Plots</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-math"><i class="fa fa-check"></i>Mathematical formulas</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-eng"><i class="fa fa-check"></i>Writing</a></li>
<li class="chapter" data-level="" data-path="writing.html"><a href="writing.html#w-format"><i class="fa fa-check"></i>Formatting</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Lecture Notes</b></span></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i>Preliminaries</a>
<ul>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#notation"><i class="fa fa-check"></i>Notation</a></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#abbreviations"><i class="fa fa-check"></i>Abbreviations</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>1</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>1.1</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#facts-normals"><i class="fa fa-check"></i><b>1.1.1</b> Some useful facts about normal variates</a></li>
<li class="chapter" data-level="1.1.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#empirical-rule-68-95-99.7-rule"><i class="fa fa-check"></i><b>1.1.2</b> Empirical rule (<span class="math inline">\(68-95-99.7\)</span> rule)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#t-distribution"><i class="fa fa-check"></i><b>1.2</b> <span class="math inline">\(\mathsf{t}\)</span> distribution</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#facts-t"><i class="fa fa-check"></i><b>1.2.1</b> Properties of <span class="math inline">\(\mathsf{t}\)</span> distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#chisq-distribution"><i class="fa fa-check"></i><b>1.3</b> <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="1.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#F-distribution"><i class="fa fa-check"></i><b>1.4</b> <span class="math inline">\(\mathsf{F}\)</span> distribution</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>2</b> Basics of statistical inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#point-estimation"><i class="fa fa-check"></i><b>2.1</b> Point estimation</a></li>
<li class="chapter" data-level="2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>2.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="2.3" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>2.3</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inference-single-sample.html"><a href="inference-single-sample.html"><i class="fa fa-check"></i><b>3</b> Inferences based on a single sample</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-means"><i class="fa fa-check"></i><b>3.1</b> Estimating means</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-normal-var-known"><i class="fa fa-check"></i><b>3.1.1</b> Mean of a normal population with known variance</a></li>
<li class="chapter" data-level="3.1.2" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-large-sample"><i class="fa fa-check"></i><b>3.1.2</b> Mean of a population with unknown variance (large-sample)</a></li>
<li class="chapter" data-level="3.1.3" data-path="inference-single-sample.html"><a href="inference-single-sample.html#mean-normal-var-unknown"><i class="fa fa-check"></i><b>3.1.3</b> Mean of a normal population with unknown variance</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-proportions"><i class="fa fa-check"></i><b>3.2</b> Estimating proportions</a></li>
<li class="chapter" data-level="3.3" data-path="inference-single-sample.html"><a href="inference-single-sample.html#estimating-variances"><i class="fa fa-check"></i><b>3.3</b> Estimating variances</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-two-samples.html"><a href="inference-two-samples.html"><i class="fa fa-check"></i><b>4</b> Inferences based on two samples</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means"><i class="fa fa-check"></i><b>4.1</b> Comparing means</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-normpops-vars-known"><i class="fa fa-check"></i><b>4.1.1</b> Comparing means of normal populations when variances are known</a></li>
<li class="chapter" data-level="4.1.2" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-large-samples"><i class="fa fa-check"></i><b>4.1.2</b> Comparing means when the sample sizes are large</a></li>
<li class="chapter" data-level="4.1.3" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-means-normpops-vars-unknown"><i class="fa fa-check"></i><b>4.1.3</b> Comparing means of normal populations when variances are unknown and the sample size is small</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-paired-samples"><i class="fa fa-check"></i><b>4.2</b> Comparing paired samples</a></li>
<li class="chapter" data-level="4.3" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-proportions"><i class="fa fa-check"></i><b>4.3</b> Comparing proportions</a></li>
<li class="chapter" data-level="4.4" data-path="inference-two-samples.html"><a href="inference-two-samples.html#compare-variances"><i class="fa fa-check"></i><b>4.4</b> Comparing variances</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>5</b> Analysis of variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="anova.html"><a href="anova.html#anova-single-factor-test"><i class="fa fa-check"></i><b>5.1</b> Single factor ANOVA test</a></li>
<li class="chapter" data-level="5.2" data-path="anova.html"><a href="anova.html#anova-ci"><i class="fa fa-check"></i><b>5.2</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>6</b> Linear regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-models.html"><a href="linear-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Simple linear regression models</a></li>
<li class="chapter" data-level="6.2" data-path="linear-models.html"><a href="linear-models.html#ls-estimate-var"><i class="fa fa-check"></i><b>6.2</b> Estimating <span class="math inline">\(\sigma^2\)</span> for linear regressions</a></li>
<li class="chapter" data-level="6.3" data-path="linear-models.html"><a href="linear-models.html#inference-ls"><i class="fa fa-check"></i><b>6.3</b> Inferences for least-squares parameters</a></li>
<li class="chapter" data-level="6.4" data-path="linear-models.html"><a href="linear-models.html#correlation"><i class="fa fa-check"></i><b>6.4</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="categorical-data.html"><a href="categorical-data.html"><i class="fa fa-check"></i><b>7</b> Categorical data</a>
<ul>
<li class="chapter" data-level="7.1" data-path="categorical-data.html"><a href="categorical-data.html#multinomial-experiments"><i class="fa fa-check"></i><b>7.1</b> Multinomial experiments</a></li>
<li class="chapter" data-level="7.2" data-path="categorical-data.html"><a href="categorical-data.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>7.2</b> Goodness-of-fit for a single factor</a></li>
<li class="chapter" data-level="7.3" data-path="categorical-data.html"><a href="categorical-data.html#test-for-the-independence-of-factors"><i class="fa fa-check"></i><b>7.3</b> Test for the independence of factors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="quality-control.html"><a href="quality-control.html"><i class="fa fa-check"></i><b>8</b> Quality control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="quality-control.html"><a href="quality-control.html#control-charts"><i class="fa fa-check"></i><b>8.1</b> Control charts</a></li>
</ul></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html"><i class="fa fa-check"></i>Curated Content</a>
<ul>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-0"><i class="fa fa-check"></i>Investigation 0</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-1"><i class="fa fa-check"></i>Investigation 1</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-2"><i class="fa fa-check"></i>Investigation 2</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-3"><i class="fa fa-check"></i>Investigation 3</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-4"><i class="fa fa-check"></i>Investigation 4</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-5"><i class="fa fa-check"></i>Investigation 5</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-6"><i class="fa fa-check"></i>Investigation 6</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-7"><i class="fa fa-check"></i>Investigation 7</a></li>
<li class="chapter" data-level="" data-path="curated-content.html"><a href="curated-content.html#investigation-8"><i class="fa fa-check"></i>Investigation 8</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="http://uod.ac.uk/sig-home" rel="nofollow"><img width="73" height="73" src="https://www.dundee.ac.uk/media/dundeewebsite/themes/brandnewhope/img/university-of-dundee-email-favicon.png" alt="University of Dundee shield logo"> </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MA22004 - Statistics II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<span class="math inline">\(\DeclareMathOperator{\E}{\mathbf{E}}\)</span>
<span class="math inline">\(\DeclareMathOperator{\Var}{Var}\)</span>
<span class="math inline">\(\DeclareMathOperator{\Cov}{Cov}\)</span>
<span class="math inline">\(\DeclareMathOperator{\corr}{corr}\)</span>
<span class="math inline">\(\newcommand{\se}{\mathsf{se}}\)</span>
<span class="math inline">\(\DeclareMathOperator{\sd}{sd}\)</span>
<div id="inference-single-sample" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Inferences based on a single sample<a href="inference-single-sample.html#inference-single-sample" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In a few situations, we can derive the sampling distribution for the statistic of interest and use this as the basis for constructing confidence intervals and hypothesis tests. Presently we estimate population means <span class="math inline">\(\mu\)</span> in Section <a href="inference-single-sample.html#estimating-means">3.1</a>, population proportions <span class="math inline">\(p\)</span> in Section <a href="inference-single-sample.html#estimating-proportions">3.2</a>, and population variances <span class="math inline">\(\sigma^2\)</span> in Section <a href="inference-single-sample.html#estimating-variances">3.3</a> in some special cases.</p>
<div id="estimating-means" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Estimating means<a href="inference-single-sample.html#estimating-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If the parameter of interest is the population mean <span class="math inline">\(\theta = \mu\)</span>, then what can be said about the distribution of the sample mean estimator <span class="math inline">\(\widehat{\theta} = \overline{X}\)</span> in <a href="statistical-inference.html#eq:sample-mean">(2.1)</a>? We will consider three cases,</p>
<ol style="list-style-type: decimal">
<li><a href="inference-single-sample.html#mean-normal-var-known">normal population with known <span class="math inline">\(\sigma^2\)</span></a>,</li>
<li><a href="inference-single-sample.html#mean-large-sample">any population with unknown <span class="math inline">\(\sigma^2\)</span>, when the sample size <span class="math inline">\(m\)</span> is large</a>, and</li>
<li><a href="inference-single-sample.html#mean-normal-var-unknown">normal population with unknown <span class="math inline">\(\sigma^2\)</span>, when the sample size <span class="math inline">\(m\)</span> is small</a>.</li>
</ol>
<p>In each, the form of the confidence interval and hypothesis test statistic for <span class="math inline">\(\mu\)</span> can be derived using the approximate normality of the sample mean.</p>
<p>In general, the confidence intervals for the mean based on normality theory will have the form:
<span class="math display" id="eq:ci-gen-form">\[\begin{equation}
\text{point estimate}\; \mu \pm (\text{critical value of reference dist.}) \cdot (\text{precision of point estimate})\,,
\tag{3.1}
\end{equation}\]</span>
where the reference distribution will be the standard normal (for 1. and 2.) and the Student’s <span class="math inline">\(\mathsf{t}\)</span> distribution (for 3.). The critical value corresponds to the value under the reference distribution that yields the two-sided (symmetric) tail areas summing to <span class="math inline">\(1-\alpha\)</span>.</p>
<div id="mean-normal-var-known" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Mean of a normal population with known variance<a href="inference-single-sample.html#mean-normal-var-known" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When sampling from a normal population with a known mean and variance, the estimator for the sample mean is also normal with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2/m\)</span> where <span class="math inline">\(m\)</span> is the sample size. Standardising,
<span class="math display" id="eq:standardized-sample-mean">\[\begin{equation}
\frac{\overline{X} - \mu}{ \sigma / \sqrt{m}} \quad \sim \mathsf{N}(0, 1)
\tag{3.2}
\end{equation}\]</span>
we see that
<span class="math display">\[\begin{equation*}
P\left(-z_{\alpha/2} &lt;  \frac{\overline{X} - \mu}{ \sigma / \sqrt{m}} &lt; z_{\alpha/2}\right) = 1 - \alpha\,.
\end{equation*}\]</span>
Based on knowing the estimator’s sampling distribution, we state the following CI.</p>
<div class="definition">
<p><span id="def:ci-norm-known-var" class="definition"><strong>Definition 3.1  </strong></span>A <strong><span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval</strong> for the mean <span class="math inline">\(\mu\)</span> of a normal population when the value of <span class="math inline">\(\sigma^2\)</span> is known is given by
<span class="math display" id="eq:ci-norm-known-var">\[\begin{equation}
\left(\overline{x} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}}\,,
        \overline{x} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{m}} \right)\,,  \tag{3.3}
\end{equation}\]</span>
or <span class="math inline">\(\overline{x} \pm z_{\alpha/2} \cdot \sigma / \sqrt{m}\)</span>, where <span class="math inline">\(m\)</span> is the sample size.</p>
</div>
<p>The CI for the mean <a href="inference-single-sample.html#eq:ci-norm-known-var">(3.3)</a> can be expressed (cf. <a href="inference-single-sample.html#eq:ci-gen-form">(3.1)</a>) as
<span class="math display">\[\begin{equation*}
\text{point estimate}\; \mu \pm
(z \;\text{critical value}) \cdot (\text{standard error of mean})\,.
\end{equation*}\]</span>
The <span class="math inline">\(z\)</span> critical value is related to the tail areas under the standard normal curve; we need to find the <span class="math inline">\(z\)</span>-score having a cumulative probability equal to <span class="math inline">\(1-\alpha\)</span> according to Definition <a href="statistical-inference.html#def:confidence-interval-gen">2.3</a>.</p>
<div class="example">
<p><span id="exm:exm-ci-norm-known-var" class="example"><strong>Example 3.1  </strong></span>Consider <span class="math inline">\(400\)</span> samples from a normal population with a known standard deviation <span class="math inline">\(\sigma = 17000\)</span> with mean <span class="math inline">\(\overline{x} = 20992\)</span> (as depicted in <a href="inference-single-sample.html#fig:ci-norm-known-var-code">3.1</a>). How do we construct a <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(\mu\)</span>?</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ci-norm-known-var-code"></span>
<img src="ma22004_files/figure-html/ci-norm-known-var-code-1.svg" alt="$400$ samples from a normal population with known variance $\sigma = 17000$ together with the corresponding (normal) sampling distribution for the observed mean." width="768" />
<p class="caption">
Figure 3.1: <span class="math inline">\(400\)</span> samples from a normal population with known variance <span class="math inline">\(\sigma = 17000\)</span> together with the corresponding (normal) sampling distribution for the observed mean.
</p>
</div>
<p>For <span class="math inline">\(\alpha = 0.05\)</span>, the critical value <span class="math inline">\(z_{0.025} = 1.96\)</span>; this value can be found by looking in a table of critical <span class="math inline">\(z\)</span> values or using the <code>r</code> code <code>qnorm(1-.05/2)</code>. From Definition <a href="inference-single-sample.html#def:ci-norm-known-var">3.1</a>,
<span class="math display">\[\begin{equation*}
\begin{aligned}
\left(\overline{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{m}}\,, \overline{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{m}} \right)
&amp;= \left(20992 - 1.96 \frac{17000}{\sqrt{400}}\,, 20992 + 1.96 \frac{17000}{\sqrt{400}} \right) \\
&amp;= \left(19326 \,, 22658\right)\,.
\end{aligned}
\end{equation*}\]</span></p>
<p>The data above was generated with a true population parameter <span class="math inline">\(\mu = 21500\)</span>, and the CI contains the parameter value (incidentally). <span class="math inline">\(\lozenge\)</span></p>
<p>As noted in <a href="inference-single-sample.html#eq:ci-gen-form">(3.1)</a> and <a href="inference-single-sample.html#eq:ci-norm-known-var">(3.3)</a>, the width of a CI is related to the estimator’s precision. The confidence level (or reliability) is inversely related to this precision. When the population is normal and the variance is known, determining the sample size necessary to achieve a desired confidence level and precision is an appealing strategy. A general formula for the sample size <span class="math inline">\(m^*\)</span> necessary to achieve an interval width <span class="math inline">\(w\)</span> is obtained at confidence level <span class="math inline">\(\alpha\)</span> by equating <span class="math inline">\(w\)</span> to <span class="math inline">\(2z_{\alpha/2} \cdot \sigma /\sqrt{m^*}\)</span> and then solving for <span class="math inline">\(m^*\)</span>.</p>
<div class="proposition">
<p><span id="prp:ci-select-n-fixed-w-alpha" class="proposition"><strong>Proposition 3.1  </strong></span>The sample size <span class="math inline">\(m\)</span> required to achieve a CI for <span class="math inline">\(\mu\)</span> with width <span class="math inline">\(w\)</span> at level <span class="math inline">\(\alpha\)</span> is given by,
<span class="math display">\[\begin{equation*}
m^* = \left( 2 z_{\alpha/2} \cdot \frac{\sigma}{w} \right)^2 \,.
\end{equation*}\]</span></p>
</div>
<p>From Proposition <a href="inference-single-sample.html#prp:ci-select-n-fixed-w-alpha">3.1</a>, we see that the smaller the desired <span class="math inline">\(w\)</span>, the larger <span class="math inline">\(m^*\)</span> must be (and subsequently, the more effort that must be allocated to data collection).</p>
<div class="example">
<p><span id="exm:exm-ci-norm-known-var-find-n" class="example"><strong>Example 3.2  </strong></span>In Example <a href="inference-single-sample.html#exm:exm-ci-norm-known-var">3.1</a> we identified a <span class="math inline">\(95\%\)</span> confidence interval for a normal population with known variance. The range (width) of that interval was <span class="math inline">\(22658 - 19326 = 3332\)</span>. How much would <span class="math inline">\(m\)</span> need to increase to halve the interval width?</p>
</div>
<p>Using Proposition <a href="inference-single-sample.html#prp:ci-select-n-fixed-w-alpha">3.1</a>,
<span class="math display">\[\begin{equation*}
m = \left( 2 \cdot 1.96 \cdot \frac{17000}{1666} \right)^2 = (40)^2 = 1600\,.
\end{equation*}\]</span>
Thus, we find that for the same level <span class="math inline">\(\alpha = 0.05\)</span>, we would need to quadruple our original sample size to halve the interval. It is expensive to remove uncertainty! <span class="math inline">\(\lozenge\)</span></p>
<p>Suppose now that we would like to consider a hypothesis test for the population mean, such as <span class="math inline">\(H_0 : \mu = \mu_0\)</span>. Starting from <a href="inference-single-sample.html#eq:standardized-sample-mean">(3.2)</a> and assuming that the null hypothesis is true, we find
<span class="math display">\[\begin{equation*}
Z = \frac{\overline{X} - \mu_0}{\sigma / \sqrt{m}}\,.
\end{equation*}\]</span>
The statistic <span class="math inline">\(Z\)</span> measures the distance (measured in units of <span class="math inline">\(\sd[\overline{X}]\)</span>) between <span class="math inline">\(\overline{X}\)</span> and its expected value under the null hypothesis. We will use the statistic <span class="math inline">\(Z\)</span> to determine if there is substantial evidence against <span class="math inline">\(H_0\)</span>, i.e. if the distance is too far in a direction consistent with <span class="math inline">\(H_a\)</span>.</p>
<div class="proposition">
<p><span id="prp:htest-norm-known-var" class="proposition"><strong>Proposition 3.2  </strong></span>Assume that we sample <span class="math inline">\(X_1, \dots, X_m\)</span> from a normal population with mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Consider <span class="math inline">\(H_0 : \mu = \mu_0\)</span>. The test statistic is
<span class="math display" id="eq:htest-norm-known-var-T">\[\begin{equation}
Z = \frac{\overline{X} - \mu_0}{\sigma / \sqrt{m}}\,.
\tag{3.4}
\end{equation}\]</span></p>
<p>For a hypothesis test at level <span class="math inline">\(\alpha\)</span>, we use the following procedure:</p>
<p>If <span class="math inline">\(H_a : \mu &gt; \mu_0\)</span>, then <span class="math inline">\(P = 1 - \Phi(z)\)</span>, i.e., upper-tail <span class="math inline">\(R = \{z &gt; z_{\alpha}\}\)</span>.</p>
<p>If <span class="math inline">\(H_a : \mu &lt; \mu_0\)</span>, then <span class="math inline">\(P = \Phi(z)\)</span>, i.e., lower-tail <span class="math inline">\(R = \{z &lt; - z_{\alpha}\}\)</span>.</p>
<p>If <span class="math inline">\(H_a : \mu \neq \mu_0\)</span>, then <span class="math inline">\(P = 2(1-\Phi(|z|))\)</span>, i.e., two-tailed <span class="math inline">\(R = \{|z| &gt; z_{\alpha/2}\}\)</span>.</p>
</div>
<p>We recall that <span class="math inline">\(\Phi(z)\)</span> is the area in the lower tail of the standard normal density, i.e., to the <em>left</em> of the calculated value of <span class="math inline">\(z\)</span>. Thus <span class="math inline">\(1 - \Phi(z)\)</span> is the area in the upper-tail, and <span class="math inline">\(2(1 - \Phi(|z|))\)</span> is twice the area captured in the upper-tail by <span class="math inline">\(|z|\)</span>, i.e. the sum of the area in the tails corresponding to <span class="math inline">\(\pm z\)</span>. If <span class="math inline">\(P &lt; \alpha\)</span>, then we reject <span class="math inline">\(H_0\)</span> at level <span class="math inline">\(\alpha\)</span> as the data provides sufficient evidence at the <span class="math inline">\(\alpha\)</span> level against the null hypothesis.</p>
<div class="example">
<p><span id="exm:htest-norm-known-var-two-tail" class="example"><strong>Example 3.3  </strong></span>Let’s return to the data in Example <a href="inference-single-sample.html#exm:exm-ci-norm-known-var">3.1</a>, where we sample from a normal population with a known standard deviation <span class="math inline">\(\sigma = 17000\)</span>. Suppose that someone claims the true mean is <span class="math inline">\(\mu_0 = 20000\)</span>. Does our sample mean <span class="math inline">\(\overline{x} = 20992\)</span> based on <span class="math inline">\(m = 400\)</span> samples provide evidence to contradict this claim at the <span class="math inline">\(\alpha = 0.05\)</span> level?</p>
</div>
<p>The first thing to record is our parameter of interest: <span class="math inline">\(\mu\)</span>, the true population mean. The null hypothesis, which we assume to be true, is a statement about the value of <span class="math inline">\(\mu\)</span>,
<span class="math display">\[\begin{equation*}
H_0 : \mu = 20000\,,
\end{equation*}\]</span>
and the alternative hypothesis is
<span class="math display">\[\begin{equation*}
H_a : \mu \neq 20000\,,
\end{equation*}\]</span>
since we are concerned with a deviation in either direction from <span class="math inline">\(\mu_0 = 20000\)</span>.</p>
<p>Since the population is normal with known variance, we compute the test statistic:
<span class="math display">\[\begin{equation*}
z = \frac{\overline{x} - \mu_0}{\sigma / \sqrt{m}} = \frac{20992 - 20000}{17000 / \sqrt{400}} = 1.167\,.
\end{equation*}\]</span>
That is, the observed sample mean <span class="math inline">\(\overline{x}\)</span> is slightly more than <span class="math inline">\(1\)</span> standard deviation than what we expect under <span class="math inline">\(H_0\)</span>. Consulting <a href="inference-single-sample.html#prp:htest-norm-known-var">3.2</a>, we see that a two-tailed test is indicated for this particular <span class="math inline">\(H_a\)</span> (i.e., containing “<span class="math inline">\(\neq\)</span>”). The <span class="math inline">\(P\)</span>-value is the area,<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>
<span class="math display">\[\begin{equation*}
P = 2(1 - \Phi(1.167)) = 2 (0.1216052) = 0.2432.
\end{equation*}\]</span>
Thus, since <span class="math inline">\(P = 0.2432 &gt; 0.05 = \alpha\)</span>, we fail to reject <span class="math inline">\(H_0\)</span> at the level <span class="math inline">\(0.05\)</span>. The data does not support the claim that the true population mean differs from the value <span class="math inline">\(20000\)</span> at the <span class="math inline">\(0.05\)</span> level. <span class="math inline">\(\lozenge\)</span></p>
</div>
<div id="mean-large-sample" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Mean of a population with unknown variance (large-sample)<a href="inference-single-sample.html#mean-large-sample" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider samples <span class="math inline">\(X_1, \dots, X_m\)</span> from a population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Provided that <span class="math inline">\(m\)</span> is large enough, the Central Limit Theorem implies that the estimator for the sample mean <span class="math inline">\(\overline{X}\)</span> in <a href="statistical-inference.html#eq:sample-mean">(2.1)</a> has <em>approximately</em> a normal distribution. Then
<span class="math display">\[\begin{equation}
P \left( - z_{\alpha/2} &lt; \frac{\overline{X} - \mu}{\sigma/\sqrt{m}} &lt; z_{\alpha/2} \right) \approx 1 - \alpha\,,
\end{equation}\]</span>
since the transformed variable has approximately a standard normal distribution. Thus, computing a point estimate based on a large <span class="math inline">\(m\)</span> of samples yields a CI for the population parameter <span class="math inline">\(\mu\)</span> at an <em>approximate</em> confidence level <span class="math inline">\(\alpha\)</span>. However, it is often the case that the variance is unknown. When <span class="math inline">\(m\)</span> is large, replacing the population variance <span class="math inline">\(\sigma^2\)</span> by the sample variance <span class="math inline">\(S^2\)</span> in <a href="statistical-inference.html#eq:sample-var">(2.2)</a> will not typically introduce too much additional variability.</p>
<div class="proposition">
<p><span id="prp:ci-large-sample" class="proposition"><strong>Proposition 3.3  </strong></span>For a large sample size <span class="math inline">\(m\)</span>, an approximate <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for the mean <span class="math inline">\(\mu\)</span> of any population when the variance is unknown is given by
<span class="math display" id="eq:ci-large-sample">\[\begin{equation}
\left(\overline{x} - z_{\alpha/2} \cdot \frac{s}{\sqrt{m}} \,,
        \overline{x} + z_{\alpha/2} \cdot \frac{s}{\sqrt{m}} \right)\,,  
\tag{3.5}
\end{equation}\]</span>
or <span class="math inline">\(\overline{x} \pm z_{\alpha/2} \cdot s / \sqrt{m}\)</span>.</p>
</div>
<p>The CI for the mean <a href="inference-single-sample.html#eq:ci-large-sample">(3.5)</a> applies regardless of the shape of the population distribution so long as the number of samples is large. A rule of thumb is that <span class="math inline">\(m &gt; 40\)</span> is sufficient.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> In words, the CI <a href="inference-single-sample.html#eq:ci-large-sample">(3.5)</a> can be expressed (cf. <a href="inference-single-sample.html#eq:ci-gen-form">(3.1)</a>) as
<span class="math display">\[\begin{equation*}
\text{point estimate}\; \mu \pm
(z \;\text{critical value}) \cdot (\text{estimated standard error of mean})\,.
\end{equation*}\]</span>
Typically, a large-sample CI for a general parameter <span class="math inline">\(\theta\)</span> holds that is similar to <a href="inference-single-sample.html#eq:ci-large-sample">(3.5)</a> for any estimator <span class="math inline">\(\widehat{\theta}\)</span> that satisfies: (1) approximately normal in distribution, (2) approximately unbiased, and (3) an expression for the standard error is available.</p>
<p>To conduct a large-sample hypothesis test regarding the population mean <span class="math inline">\(\mu\)</span>, we consider the test statistic
<span class="math display">\[\begin{equation*}
Z = \frac{\overline{X} - \mu_0}{S / \sqrt{m}}
\end{equation*}\]</span>
under the null hypothesis, i.e., we replace the population standard deviation <span class="math inline">\(\sigma\)</span> with the sample standard deviation <span class="math inline">\(S\)</span>. When the number of samples <span class="math inline">\(m\)</span> is large (say <span class="math inline">\(m &gt; 40\)</span>), then <span class="math inline">\(Z\)</span> will be approximately normal. Substituting this test statistic <span class="math inline">\(Z\)</span> for <a href="inference-single-sample.html#eq:htest-norm-known-var-T">(3.4)</a>, we follow Proposition <a href="inference-single-sample.html#prp:htest-norm-known-var">3.2</a> to determine how to calculate the <span class="math inline">\(P\)</span>-value.</p>
<div class="example">
<p><span id="exm:exm-mean-large-sample-infer" class="example"><strong>Example 3.4  </strong></span>Consider the <strong>Iris Data</strong> from <a href="statistical-inference.html#point-estimation">2.1</a> and use the <code>infer</code> package to make inferences. In particular, consider whether the true mean petal length of Iris flowers exceeds 3.5 cm at the 0.05 level.</p>
</div>
<p>Recall that the <strong>Iris Data</strong> contains <span class="math inline">\(m= 150\)</span> measurements of petal length across three species of Iris flowers and that the true variance is unknown.
We are interested in testing the null hypothesis <span class="math inline">\(H_0 : \mu \leq 3.5\)</span> against the alternative <span class="math inline">\(H_a : \mu &gt; 3.5\)</span> (i.e., a one-sided test).</p>
<p>We first compute the observed statistic (sample mean) <span class="math inline">\(\widehat{\mu}\)</span>. We use the <code>infer</code> package to construct a null distribution <em>computationally</em> for the response variable (petal length). We specify that the hypothesis test is for the parameter based on a point estimate and that we are testing for equality with the value <span class="math inline">\(\mu_0 = 3.5\)</span>. The null distribution is generated by computing 1000 bootstrap replications of the sample mean, i.e., the sample mean is generated 1000 times by drawing 150 values at random with replacement from the original corpus of <span class="math inline">\(m=150\)</span> samples. (Note that we obtain the null distribution computationally, so we do not need to standardise to <span class="math inline">\(Z\)</span>.)</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="inference-single-sample.html#cb1-1" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(iris<span class="sc">$</span>Petal.Length) </span>
<span id="cb1-2"><a href="inference-single-sample.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="inference-single-sample.html#cb1-3" aria-hidden="true" tabindex="-1"></a>null_dist <span class="ot">&lt;-</span> iris <span class="sc">%&gt;%</span></span>
<span id="cb1-4"><a href="inference-single-sample.html#cb1-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">specify</span>(<span class="at">response =</span> Petal.Length) <span class="sc">%&gt;%</span></span>
<span id="cb1-5"><a href="inference-single-sample.html#cb1-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">hypothesise</span>(<span class="at">null =</span> <span class="st">&quot;point&quot;</span>, <span class="at">mu =</span> <span class="fl">3.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-6"><a href="inference-single-sample.html#cb1-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-7"><a href="inference-single-sample.html#cb1-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb1-8"><a href="inference-single-sample.html#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="inference-single-sample.html#cb1-9" aria-hidden="true" tabindex="-1"></a>null_dist <span class="sc">%&gt;%</span></span>
<span id="cb1-10"><a href="inference-single-sample.html#cb1-10" aria-hidden="true" tabindex="-1"></a> <span class="fu">visualise</span>() <span class="sc">+</span></span>
<span id="cb1-11"><a href="inference-single-sample.html#cb1-11" aria-hidden="true" tabindex="-1"></a> <span class="fu">shade_p_value</span>(<span class="at">obs_stat =</span> mu_hat, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<p><img src="ma22004_files/figure-html/exm-mean-large-sample-infer-htest-1.svg" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="inference-single-sample.html#cb2-1" aria-hidden="true" tabindex="-1"></a>p_val <span class="ot">&lt;-</span> null_dist <span class="sc">%&gt;%</span></span>
<span id="cb2-2"><a href="inference-single-sample.html#cb2-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">get_p_value</span>(<span class="at">obs_stat =</span> mu_hat, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb2-3"><a href="inference-single-sample.html#cb2-3" aria-hidden="true" tabindex="-1"></a>p_val</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  p_value
    &lt;dbl&gt;
1    0.03</code></pre>
<p>The bootstrapped null distribution is plotted using the <code>visualise</code> command, and the regions of the null distribution that are as extreme (or more extreme) than the observed statistic <span class="math inline">\(\widehat{\mu}\)</span> can be highlighted using the <code>shade_p_value</code> command. <span class="math inline">\(P = 0.03\)</span> is found which is quite small; if <span class="math inline">\(\mu \leq 3.5\)</span>, then the probability of obtaining the sample mean value <span class="math inline">\(\widehat{\mu} = 3.758\)</span> is only 0.03! Thus, the data provide sufficient evidence at the 0.05 level against the hypothesis that the true mean petal length is at most 3.5 cm. <span class="math inline">\(\lozenge\)</span></p>
</div>
<div id="mean-normal-var-unknown" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Mean of a normal population with unknown variance<a href="inference-single-sample.html#mean-normal-var-unknown" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Section <a href="inference-single-sample.html#mean-normal-var-known">3.1.1</a>, we considered samples <span class="math inline">\(X_1, \dots, X_m\)</span> from a normal population with a known <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>. In contrast, here, we consider samples from a normal population and assume the population parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are unknown. If the number of samples is large, the discussion in Section <a href="inference-single-sample.html#mean-large-sample">3.1.2</a> indicates that the rv <span class="math inline">\(Z = (\overline{X} - \mu) \sqrt{m} / S\)</span> has approximately a standard normal distribution. However, if <span class="math inline">\(m\)</span> is not sufficiently large<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> then the transformed variable will be more spread out than a standard normal distribution.</p>
<div class="theorem">
<p><span id="thm:sample-mean-t-dist" class="theorem"><strong>Theorem 3.1  </strong></span>For the sample mean <span class="math inline">\(\overline{X}\)</span> based on <span class="math inline">\(m\)</span> samples from a normal distribution with mean <span class="math inline">\(\mu\)</span>, the rv
<span class="math display" id="eq:t-statistic-mean">\[\begin{equation}
T = \frac{\overline{X} - \mu}{S/\sqrt{m}}  \quad \sim \mathsf{t}(m-1)\,, \tag{3.6}
\end{equation}\]</span>
that is, <span class="math inline">\(T\)</span> has Student’s <span class="math inline">\(\mathsf{t}\)</span> distribution with <span class="math inline">\(\nu = m-1\)</span> df.</p>
</div>
<p>This leads us to consider a CI for the population parameter <span class="math inline">\(\mu\)</span> based on critical values of the <span class="math inline">\(\mathsf{t}\)</span> distribution.</p>
<div class="proposition">
<p><span id="prp:ci-norm-unknown-var" class="proposition"><strong>Proposition 3.4  </strong></span>A <strong><span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval</strong> for the mean <span class="math inline">\(\mu\)</span> of a normal population, when <span class="math inline">\(\sigma^2\)</span> is unknown, is given by
<span class="math display" id="eq:ci-norm-unknown-var">\[\begin{equation}
\left(\overline{x} - t_{\alpha/2, m-1} \cdot \frac{s}{\sqrt{m}}\,,
        \overline{x} + t_{\alpha/2, m-1} \cdot \frac{s}{\sqrt{m}} \right)\,,  \tag{3.7}
\end{equation}\]</span>
or <span class="math inline">\(\overline{x} \pm t_{\alpha/2, m-1} \cdot s/ \sqrt{m}\)</span>. Here <span class="math inline">\(\overline{x}\)</span> and <span class="math inline">\(s\)</span> are the sample mean and sample standard deviation, respectively.</p>
</div>
<div class="example">
<p><span id="exm:exm-ci-norm-unknown-var" class="example"><strong>Example 3.5  </strong></span>Let us return to the height of <span class="math inline">\(31\)</span> felled black cherry trees from the <strong>Cherry Tree Data</strong> in Table <a href="statistical-inference.html#tab:cherry-data">2.1</a>. Give a <span class="math inline">\(99\%\)</span> CI for the population mean <span class="math inline">\(\mu\)</span>.</p>
</div>
<p>For <span class="math inline">\(m = 31\)</span>, the critical value of the reference distribution is <span class="math inline">\(t_{0.005, 30} \approx 2.7499\)</span>, which can looked up in a table of critical values for <span class="math inline">\(\mathsf{t}(\nu = m-1)\)</span> or found using the <code>r</code> command <code>qt(1-0.01/2, df = 31-1)</code>. The sample mean <span class="math inline">\(\overline{x} = 76\)</span> (computed in Example <a href="statistical-inference.html#exm:eg-estimators">2.1</a>) is combined with the sample standard deviation,
<span class="math display">\[\begin{equation*}
\begin{aligned}
s &amp;= \sqrt{\frac{1}{m-1} \sum_{i=1}^m (x_i - \overline{x})^2}\\
   &amp;= \sqrt{\frac{1}{30} \left((63-76)^2 + \cdots + (87 - 76)^2\right)}\\
   &amp;= 6.372\,,
\end{aligned}
\end{equation*}\]</span>
to form the interval estimate
<span class="math display">\[\begin{equation*}
\begin{aligned}
&amp; \left(\overline{x} - t_{\alpha/2, m-1}  \cdot \frac{s}{\sqrt{m}}\,,
        \overline{x} + t_{\alpha/2, m-1} \cdot \frac{s}{\sqrt{m}} \right) \\
        &amp;\qquad = \left(76 - 2.750 \cdot \frac{6.372}{\sqrt{31}} \,, 76 + 2.750 \cdot \frac{6.372}{\sqrt{31}} \right)\\
        &amp;\qquad = \left(72.85\,, 79.15\right)\,.
\end{aligned}
\end{equation*}\]</span>
For comparison, the critical value <span class="math inline">\(t_{.01/2, \nu}\)</span> for <span class="math inline">\(\nu = 13, \dots, 30\)</span></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="inference-single-sample.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="dv">1</span><span class="fl">-0.01</span><span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> <span class="fu">seq</span>(<span class="dv">12</span><span class="sc">:</span><span class="dv">39</span>))</span></code></pre></div>
<pre><code> [1] 63.656741  9.924843  5.840909  4.604095  4.032143  3.707428  3.499483  3.355387
 [9]  3.249836  3.169273  3.105807  3.054540  3.012276  2.976843  2.946713  2.920782
[17]  2.898231  2.878440  2.860935  2.845340  2.831360  2.818756  2.807336  2.796940
[25]  2.787436  2.778715  2.770683  2.763262</code></pre>
<p>can deviate significantly from the corresponding <span class="math inline">\(z_{0.01/2} = 2.575829\)</span>. In particular, if we had erroneously used the large sample estimate <a href="inference-single-sample.html#eq:ci-large-sample">(3.5)</a>, then we would have obtained <span class="math inline">\(99\%\)</span> CI <span class="math inline">\((73.05\,, 78.95)\)</span> which might give us a false sense of security as it is narrower. <span class="math inline">\(\lozenge\)</span></p>
<p>In contrast to Proposition <a href="inference-single-sample.html#prp:ci-select-n-fixed-w-alpha">3.1</a>, it is difficult to select the sample size <span class="math inline">\(m\)</span> to control the width of the <span class="math inline">\(\mathsf{t}\)</span>-based CI as the width involves the unknown (before the sample is acquired) <span class="math inline">\(s\)</span> and because <span class="math inline">\(m\)</span> also enters through <span class="math inline">\(t_{\alpha/2, m-1}\)</span>. A one-sample <span class="math inline">\(\mathsf{t}\)</span> test based on <a href="inference-single-sample.html#eq:t-statistic-mean">(3.6)</a> can be used to test a hypothesis about the population mean when the population is normal and <span class="math inline">\(\sigma^2\)</span> is unknown.</p>
<div class="proposition">
<p><span id="prp:htest-mean-normal-var-unknown" class="proposition"><strong>Proposition 3.5  </strong></span>Assume that we sample <span class="math inline">\(X_1, \dots, X_m\)</span> from a normal population with mean <span class="math inline">\(\mu\)</span> and unknown variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Consider <span class="math inline">\(H_0 : \mu = \mu_0\)</span>. The test statistic is
<span class="math display">\[\begin{equation*}
T = \frac{\overline{X} - \mu_0}{S / \sqrt{m}} \,.
\end{equation*}\]</span></p>
<p>For a hypothesis test at level <span class="math inline">\(\alpha\)</span>, we use the following procedure:</p>
<p>If <span class="math inline">\(H_a : \mu &gt; \mu_0\)</span>, then <span class="math inline">\(P\)</span>-value is the area under <span class="math inline">\(\mathsf{t}(m-1)\)</span> to the right of <span class="math inline">\(t\)</span>.</p>
<p>If <span class="math inline">\(H_a : \mu &lt; \mu_0\)</span>, then <span class="math inline">\(P\)</span>-value is the area under <span class="math inline">\(\mathsf{t}(m-1)\)</span> to the left of <span class="math inline">\(t\)</span>.</p>
<p>If <span class="math inline">\(H_a : \mu \neq \mu_0\)</span>, then <span class="math inline">\(P\)</span>-value is twice the area under <span class="math inline">\(\mathsf{t}(m-1)\)</span> to the right of <span class="math inline">\(|t|\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:exm-htest-ttest" class="example"><strong>Example 3.6  </strong></span>From the <strong>Cherry Tree Data</strong>, let’s look at the average timber volume given in Table <a href="inference-single-sample.html#tab:cherry-data-vol">3.1</a>. The distribution for this data is approximately normal.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> We might ask if the data provide compelling evidence, say at level 0.05, for concluding that the true average timber volume exceeds 21.3 cubic feet.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></p>
</div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:cherry-data-vol">Table 3.1: </span>Observations of <span class="math inline">\(m = 31\)</span> felled black cherry trees.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Volume [cu ft]
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 150mm; ">
10.2, 10.3, 10.3, 15.6, 16.4, 18.2, 18.8, 19.1, 19.7, 19.9, 21.0, 21.3, 21.4, 22.2, 22.6, 24.2, 24.9, 25.7, 27.4, 31.7, 33.8, 34.5, 36.3, 38.3, 42.6, 51.0, 51.5, 55.4, 55.7, 58.3, 77.0
</td>
</tr>
</tbody>
</table>
<p>Let’s carry out a significance test for the true average volume of timber <span class="math inline">\(\mu\)</span> at level <span class="math inline">\(\alpha = 0.05\)</span>. We assume the null hypothesis
<span class="math display">\[\begin{equation*}
H_0 : \mu = 21.3\,.
\end{equation*}\]</span>
An appropriate null hypothesis is
<span class="math display">\[\begin{equation*}
H_a : \mu &gt; 21.3\,,
\end{equation*}\]</span>
that is, we will adopt the stance that the true average exceeds <span class="math inline">\(\mu_0 = 21.3\)</span> only if the null is rejected.</p>
<p>From our <span class="math inline">\(m = 31\)</span> samples, we find that <span class="math inline">\(\overline{x} = 30.17\)</span> and that <span class="math inline">\(s = 16.44\)</span>. The computed value of the one-sample <span class="math inline">\(\mathsf{t}\)</span>-statistic is given by
<span class="math display">\[\begin{equation}
\begin{aligned}
t &amp;= \frac{\overline{x} - \mu_0}{s / \sqrt{m}}\\
&amp;= \frac{30.17 - 21.3}{16.44 / \sqrt{31}}\\
&amp; = 3\,.
\end{aligned}
\end{equation}\]</span>
The test is based on <span class="math inline">\(\nu = 31-1\)</span> df, and <span class="math inline">\(P = 0.002663\)</span>. This is the upper-tail area, i.e. the area to the right of <span class="math inline">\(t\)</span> (see Figure <a href="inference-single-sample.html#fig:exm-htest-ttest-plot">3.2</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:exm-htest-ttest-plot"></span>
<img src="ma22004_files/figure-html/exm-htest-ttest-plot-1.svg" alt="For this test, the $P$-value is the upper-tail area, i.e., to the right of the computed statistic t." width="768" />
<p class="caption">
Figure 3.2: For this test, the <span class="math inline">\(P\)</span>-value is the upper-tail area, i.e., to the right of the computed statistic t.
</p>
</div>
<p>Since <span class="math inline">\(P \ll \alpha\)</span>, we reject the null hypothesis that the population mean is <span class="math inline">\(21.3\)</span>. The data provide sufficient evidence that the population mean differs from <span class="math inline">\(21.3\)</span>. <span class="math inline">\(\lozenge\)</span></p>
</div>
</div>
<div id="estimating-proportions" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Estimating proportions<a href="inference-single-sample.html#estimating-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider a population of size <span class="math inline">\(M\)</span> in which each member either satisfies a given property or does not (i.e. a binary classification). The proportion <span class="math inline">\(p \in (0,1)\)</span> of the population satisfying the given property is a parameter characterising the population we might be interested in estimating. A sample of classified observations, <span class="math inline">\(X_1, \dots, X_m \sim \mathsf{Bernoulli}(p)\)</span>, from the population contains a proportion,
<span class="math display" id="eq:proportion-estimator">\[\begin{equation}
\widehat{p} = \frac{1}{m} \sum_{i=1}^m X_i\,,
\tag{3.8}
\end{equation}\]</span>
satisfying the given property. The estimator <span class="math inline">\(\widehat{p}\)</span> varies with the sample, and for large <span class="math inline">\(m\)</span>, its sampling distribution has the following properties:
<span class="math display" id="eq:proportion-mean">\[\begin{equation*}
\mu_{\widehat{p}} = \E[X_i] = p
\tag{3.9}
\end{equation*}\]</span>
and
<span class="math display" id="eq:proportion-var">\[\begin{equation}
\sigma_{\widehat{p}}^2 = \frac{\Var[X_i]}{m} = \frac{p(1-p)}{m}\,,
\tag{3.10}
\end{equation}\]</span>
provided that <span class="math inline">\(m\)</span> is small relative to <span class="math inline">\(M\)</span> (a rule of thumb is <span class="math inline">\(m \leq 0.05 M\)</span>).<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> Moreover, by invoking the Central Limit Theorem, we have the distribution of <span class="math inline">\(\widehat{p}\)</span> is approximately normal for sufficiently large <span class="math inline">\(m\)</span> as <a href="inference-single-sample.html#eq:proportion-estimator">(3.8)</a> is a sample mean. Indeed, this normal approximation works well for moderately large <span class="math inline">\(m\)</span> as long as <span class="math inline">\(p\)</span> is not too close to zero or one; a rule of thumb is that <span class="math inline">\(mp &gt; 5\)</span> and <span class="math inline">\(m(1-p) &gt; 5\)</span>.</p>
<div class="proposition">
<p><span id="prp:ci-proportion" class="proposition"><strong>Proposition 3.6  </strong></span>For large samples <span class="math inline">\(n\)</span>, a <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for the parameter <span class="math inline">\(p\)</span> is given by
<span class="math display" id="eq:proportion-mean-ci">\[\begin{equation}
\widehat{p} \pm z_{\alpha/2} \sqrt{\frac{\widehat{p} (1-\widehat{p})}{m}}\,.
\tag{3.11}
\end{equation}\]</span></p>
</div>
<p>This follows from Proposition <a href="inference-single-sample.html#prp:ci-large-sample">3.3</a> by observing that <a href="inference-single-sample.html#eq:proportion-estimator">(3.8)</a> is a sample mean and replacing the standard error <span class="math inline">\(\sigma_{\widehat{p}}\)</span> from <a href="inference-single-sample.html#eq:proportion-var">(3.10)</a> by the estimated standard error,
<span class="math display">\[\begin{equation*}
\widehat{\se}(\widehat{p}) = \sqrt{\frac{\widehat{p} (1-\widehat{p})}{m}}\,;
\end{equation*}\]</span>
recall the <span class="math inline">\(s\)</span> in <a href="inference-single-sample.html#eq:ci-large-sample">(3.5)</a> is the sample variance for the <em>population</em> and <span class="math inline">\(s / \sqrt{m} = \se\)</span> is the standard error of the point estimator.</p>
<div class="proposition">
<p><span id="prp:htest-proportion" class="proposition"><strong>Proposition 3.7  </strong></span>Let <span class="math inline">\(X\)</span> be the count of members with a given property based on a sample of size <span class="math inline">\(m\)</span> from a population where a proportion <span class="math inline">\(p\)</span> shares the property.
Then <span class="math inline">\(\widehat{p} = X / m\)</span> is an estimator of <span class="math inline">\(p\)</span>. Assume <span class="math inline">\(m p_0 \geq 10\)</span> and <span class="math inline">\(m (1-p_0) \geq 10\)</span>.</p>
<p>Consider <span class="math inline">\(H_0 : p = p_0\)</span>. The test statistic is
<span class="math display">\[\begin{equation*}
Z = \frac{\widehat{p} - p_0}{\sqrt{p_0 (1-p_0) / m}} \,.
\end{equation*}\]</span></p>
<p>For a hypothesis test at level <span class="math inline">\(\alpha\)</span>, we use the following procedure:</p>
<p>If <span class="math inline">\(H_a : p &gt; p_0\)</span>, then <span class="math inline">\(P\)</span>-value is the area under <span class="math inline">\(\mathsf{N}(0,1)\)</span> to the right of <span class="math inline">\(z\)</span>.</p>
<p>If <span class="math inline">\(H_a : p &lt; p_0\)</span>, then <span class="math inline">\(P\)</span>-value is the area under <span class="math inline">\(\mathsf{N}(0,1)\)</span> to the left of <span class="math inline">\(z\)</span>.</p>
<p>If <span class="math inline">\(H_a : p \neq p_0\)</span>, then <span class="math inline">\(P\)</span>-value is twice the area under <span class="math inline">\(\mathsf{N}(0,1)\)</span> to the right of <span class="math inline">\(|z|\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:eg-est-prop-hypothesis-test" class="example"><strong>Example 3.7  </strong></span>Let us revisit Example <a href="statistical-inference.html#exm:htest-setup">2.2</a>, where we considered Churchill’s claim that he would receive half the votes for the House of Commons seat for the constituency of Dundee. We are sceptical that he is as popular as he says. Suppose 116 out of 263 Dundonians polled claimed they intended to vote for Churchill. Can it be concluded at a significance level of <span class="math inline">\(0.10\)</span> that more than half of all eligible Dundonains will vote for Churchill?</p>
</div>
<p>The parameter of interest is <span class="math inline">\(p\)</span>, the proportion of votes for Churchill. The null hypothesis is <span class="math inline">\(H_0 : p = 0.5\)</span>. The alternative hypothesis is <span class="math inline">\(H_a : p &lt; 0.5\)</span>, since we . Since <span class="math inline">\(263(0.5) = 131.5 &gt; 10\)</span>, we satisfy the assumptions stated in Proposition <a href="inference-single-sample.html#prp:htest-proportion">3.7</a>.</p>
<p>Based on the sample, <span class="math inline">\(\widehat{p} = 116 / 263 = 0.4411\)</span>. The test statistic value is
<span class="math display">\[\begin{equation*}
\begin{aligned}
z &amp;= \frac{\widehat{p} - p_0}{\sqrt{p_0 (1-p_0) / m}} \\
&amp;= \frac{0.4411 - 0.5}{\sqrt{0.5 (1-0.5) / 263}}\\
&amp;= -1.91  \,.
\end{aligned}
\end{equation*}\]</span>
The <span class="math inline">\(P\)</span>-value for this lower-tailed <span class="math inline">\(z\)</span> test is <span class="math inline">\(P = \Phi(-1.91) = 0.028\)</span>. Since <span class="math inline">\(P &lt; 0.10 = \alpha\)</span>, we reject the null hypothesis at the <span class="math inline">\(0.1\)</span> level. The evidence for concluding that the true proportion is different from <span class="math inline">\(p_0 = 0.5\)</span> at the <span class="math inline">\(0.10\)</span> level is compelling.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> <span class="math inline">\(\lozenge\)</span></p>
</div>
<div id="estimating-variances" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Estimating variances<a href="inference-single-sample.html#estimating-variances" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Next, we consider estimates of the population variance (and standard deviation) when the population is assumed to have a normal distribution. In this case, the sample variance <span class="math inline">\(S^2\)</span> in <a href="statistical-inference.html#eq:sample-var">(2.2)</a> provides the basis for inferences. Consider iid samples <span class="math inline">\(X_1, \dots, X_m \sim \mathsf{N}(\mu, \sigma^2)\)</span>. We provide the following theorem without proof.</p>
<div class="theorem">
<p><span id="thm:samp-var-chisq" class="theorem"><strong>Theorem 3.2  </strong></span>For the sample variance <span class="math inline">\(S^2\)</span> based on <span class="math inline">\(m\)</span> samples from a normal distribution with variance <span class="math inline">\(\sigma^2\)</span>, the rv
<span class="math display">\[\begin{equation*}
V = \frac{(m-1)S^2}{\sigma^2} = \frac{\sum_i(X_i - \overline{X})^2}{\sigma^2} \qquad \sim \chi^2_{m-1}\,,
\end{equation*}\]</span>
that is, <span class="math inline">\(V\)</span> has a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(\nu = m-1\)</span> df.</p>
</div>
<p>Based on Theorem <a href="inference-single-sample.html#thm:samp-var-chisq">3.2</a>,
<span class="math display">\[\begin{equation*}
P\left(\chi^2_{1-\alpha/2, m-1} &lt; \frac{(m-1)S^2}{\sigma^2} &lt; \chi^2_{\alpha/2, m-1} \right) = 1 - \alpha \,,
\end{equation*}\]</span>
i.e., the area captured between the right and left tail critical <span class="math inline">\(\chi^2\)</span> values is <span class="math inline">\(1-\alpha\)</span>. The expression above can be further manipulated to obtain an interval for the unknown parameter <span class="math inline">\(\sigma^2\)</span>:
<span class="math display">\[\begin{equation*}
P\left(\frac{(m-1) s^2}{\chi^2_{\alpha/2, m-1}} &lt; \sigma^2 &lt; \frac{(m-1) s^2}{\chi^2_{1-\alpha/2, m-1}} \right) = 1 - \alpha \,,
\end{equation*}\]</span>
where we substitute the computed value of the point estimate <span class="math inline">\(s^2\)</span> for the estimator into the limits to give a CI for <span class="math inline">\(\sigma^2\)</span>. If we take square roots in the inequality above, we obtain a CI for the population standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<div class="proposition">
<p><span id="prp:ci-variance" class="proposition"><strong>Proposition 3.8  </strong></span>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for the variance of a normal population is
<span class="math display" id="eq:ci-variance">\[\begin{equation*}
\left( (m-1)s^2 / \chi^2_{\alpha/2, m-1} \,,  (m-1)s^2 / \chi^2_{1-\alpha/2, m-1} \right) \,.
\tag{3.12}
\end{equation*}\]</span>
A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for the standard deviation <span class="math inline">\(\sigma\)</span> of a normal population is given by taking the square roots of the lower and upper limits in <a href="inference-single-sample.html#eq:ci-variance">(3.12)</a>.</p>
</div>
<div class="example">
<p><span id="exm:eg-ci-variance" class="example"><strong>Example 3.8  </strong></span>For the <strong>Cherry Tree Data</strong> in Table <a href="inference-single-sample.html#tab:cherry-data-vol">3.1</a> concerning the timber volume of <span class="math inline">\(31\)</span> felled black cherry trees, give a <span class="math inline">\(95%\)</span> CI for the variance.</p>
</div>
<p>We are interested in estimating the true variance <span class="math inline">\(\sigma^2\)</span> of the timber volume based on <span class="math inline">\(m=31\)</span> samples. Recall that the mean of our data is <span class="math inline">\(\overline{x} = 30.17\)</span> cu ft and that the sample variance is <span class="math inline">\(s^2 = 270.2\)</span> using the estimator <a href="statistical-inference.html#eq:sample-var">(2.2)</a>. The critical values for the <span class="math inline">\(\chi^2_{.975, 30} = 16.7908\)</span> and <span class="math inline">\(\chi^2{.025, 30} = 46.9792\)</span> can be found by checking a table of critical values of the <span class="math inline">\(\chi^2(\nu=30)\)</span> distribution or by using the <code>r</code> code <code>qchisq(1-0.05/2, df=30, lower.tail = FALSE)</code> and <code>qchisq(0.05/2, df=df, lower.tail = FALSE)</code>, respectively (see <a href="inference-single-sample.html#fig:exm-htest-chisq-plot">3.3</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:exm-htest-chisq-plot"></span>
<img src="ma22004_files/figure-html/exm-htest-chisq-plot-1.svg" alt="As the $\chi^2$ distribution is not symmetric, the upper and lower critical values will not be the same (the shaded areas are equal)." width="768" />
<p class="caption">
Figure 3.3: As the <span class="math inline">\(\chi^2\)</span> distribution is not symmetric, the upper and lower critical values will not be the same (the shaded areas are equal).
</p>
</div>
<p>Pulling everything together, a <span class="math inline">\(95\%\)</span> CI for the population variance is given by
<span class="math display">\[\begin{equation*}
\begin{aligned}
&amp; \left( (m-1)s^2 / \chi^2_{\alpha/2, m-1} \,,  (m-1)s^2 / \chi^2_{1-\alpha/2, m-1} \right) \\
&amp;\qquad = \left( (30) 270.2 / 46.9792 \,, (30) 270.2 / 16.7908  \right) \\
&amp;\qquad = \left(172.5\,, 482.8\right)\,.
\end{aligned}
\end{equation*}\]</span>
Note the position of the critical values—don’t swap them around. <span class="math inline">\(\lozenge\)</span></p>
<div class="example">
<p><span id="exm:eg-ci-variance-infer" class="example"><strong>Example 3.9  </strong></span>Revisit Example <a href="inference-single-sample.html#exm:eg-ci-variance">3.8</a> and use the <code>infer</code> package to construct a <span class="math inline">\(95\%\)</span> confidence interval for the true standard deviation of the timber volume of black cherry trees based on the available measurements in the <strong>Cherry Tree Data</strong>, Table <a href="inference-single-sample.html#tab:cherry-data-vol">3.1</a>.</p>
</div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="inference-single-sample.html#cb6-1" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">sd</span>(trees<span class="sc">$</span>Volume)</span>
<span id="cb6-2"><a href="inference-single-sample.html#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="inference-single-sample.html#cb6-3" aria-hidden="true" tabindex="-1"></a>null_dist <span class="ot">&lt;-</span> trees <span class="sc">%&gt;%</span></span>
<span id="cb6-4"><a href="inference-single-sample.html#cb6-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">specify</span>(<span class="at">response =</span> Volume) <span class="sc">%&gt;%</span></span>
<span id="cb6-5"><a href="inference-single-sample.html#cb6-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb6-6"><a href="inference-single-sample.html#cb6-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;sd&quot;</span>)</span>
<span id="cb6-7"><a href="inference-single-sample.html#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="inference-single-sample.html#cb6-8" aria-hidden="true" tabindex="-1"></a>ci <span class="ot">&lt;-</span> null_dist <span class="sc">%&gt;%</span></span>
<span id="cb6-9"><a href="inference-single-sample.html#cb6-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">get_confidence_interval</span>(<span class="at">point_estimate =</span> s, <span class="at">level =</span> <span class="fl">0.95</span>, <span class="at">type =</span> <span class="st">&quot;se&quot;</span>)</span>
<span id="cb6-10"><a href="inference-single-sample.html#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="inference-single-sample.html#cb6-11" aria-hidden="true" tabindex="-1"></a>null_dist <span class="sc">%&gt;%</span> </span>
<span id="cb6-12"><a href="inference-single-sample.html#cb6-12" aria-hidden="true" tabindex="-1"></a> <span class="fu">visualise</span>() <span class="sc">+</span> <span class="fu">shade_ci</span>(ci)</span></code></pre></div>
<p><img src="ma22004_files/figure-html/eg-ci-variance-infer-code-1.svg" width="768" style="display: block; margin: auto;" /></p>
<p>We plot the 95% confidence interval for the standard deviation based on the computational null distribution obtained using 1000 bootstrap replications; note the interval estimate</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="inference-single-sample.html#cb7-1" aria-hidden="true" tabindex="-1"></a>ci<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>  lower_ci upper_ci
1 138.6375 445.2628</code></pre>
<p>is in good agreement with the values obtained Example <a href="inference-single-sample.html#exm:eg-ci-variance">3.8</a>. Due to the computational nature, the bootstrapped interval estimate is not precisely the same as the theoretical interval estimate and rerunning the code will yield a slightly different interval. <span class="math inline">\(\lozenge\)</span></p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-vanBelle:2008rt" class="csl-entry">
Belle, G. van (2008), <em>Statistical <span>R</span>ules of <span>T</span>humb</em>, Wiley series in probability and statistics, Hoboken, NJ: John Wiley &amp; Sons, Inc., p. xxii+272.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>Note <span class="math inline">\(\Phi(z) = P(Z \leq z)\)</span> is found by calling <code>pnorm(z)</code> in <code>r</code> or by looking up the value in a <span class="math inline">\(Z\)</span> table.<a href="inference-single-sample.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>For <span class="math inline">\(m &gt; 20\)</span>, the interval estimate <span class="math display">\[\text{point estimate } \pm 2\sd\]</span> has <span class="math inline">\(95\%\)</span> coverage and is surprisingly robust, i.e. applies to a wide variety of population distributions including the normal. However, this rule of thumb won’t apply if you want to consider some different level, say <span class="math inline">\(80\%\)</span> <span class="citation">(<a href="#ref-vanBelle:2008rt" role="doc-biblioref">Belle 2008,sec. 1</a>)</span>.<a href="inference-single-sample.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Recall that we would consider <span class="math inline">\(m &gt; 40\)</span> to be large.<a href="inference-single-sample.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>After looking at the normal quantile-quantile plot, I decided to test a hypothesis. For level <span class="math inline">\(0.01\)</span>, I ran a Kolmogorov–Smirnov test for the null hypothesis that the data is consistent with <span class="math inline">\(\mathsf{N}(\overline{x}, s^2)\)</span> vs the alternative that the data is not consistent with the specified reference distribution. The <span class="math inline">\(P\)</span>-value attained was <span class="math inline">\(P = 0.2532 &gt; 0.10\)</span>, and therefore I fail to reject the null hypothesis. The data is consistent with being drawn from a normal population.<a href="inference-single-sample.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>How much wood is that? About a sixth of a cord. A full cord of chopped firewood in the US is <span class="math inline">\(124\)</span> cu ft; about enough to keep you warm through a New England winter (according to my mother-in-law).<a href="inference-single-sample.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Note that if <span class="math inline">\(m\)</span> is large relative to <span class="math inline">\(M\)</span> (<span class="math inline">\(m &gt; 0.05 M\)</span>) then the variance <a href="inference-single-sample.html#eq:proportion-var">(3.10)</a> must be adjusted by a factor (related to the hypergeometric distribution):
<span class="math display">\[\begin{equation*}
\sigma_{\widehat{p}}^2 = \frac{p(1-p)}{m} \frac{M-m}{M-1}\,,
\end{equation*}\]</span>
where for fixed <span class="math inline">\(m\)</span> the factor converges to <span class="math inline">\(1\)</span> as <span class="math inline">\(M\to \infty\)</span>.<a href="inference-single-sample.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Churchill took ca. <span class="math inline">\(44\%\)</span> of the vote in the 1908 by-election to become MP for Dundee [<a href="https://www.wikiwand.com/en/1908_Dundee_by-election">https://www.wikiwand.com/en/1908_Dundee_by-election</a>].<a href="inference-single-sample.html#fnref22" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inference-two-samples.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dundeemath/MA22004/edit/master/03-infer-single-sample.Rmd",
"text": "Suggest an edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ma22004.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true,
"highlight": "pygments",
"number_sections": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
