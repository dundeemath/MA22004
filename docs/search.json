[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA22004 — Statistics II",
    "section": "",
    "text": "Welcome\nWelcome to MA22004 Statistics II at the University of Dundee.\nThis module covers the basics of statistical inference including point estimation, interval estimation, hypothesis testing, linear regression, and simple goodness-of-fit tests. The appendix contains a list of curated content for your to investigate.\nThese notes are available at dundeemath.github.io/MA22004/ and also as a PDF (visit the page and click on the PDF icon to download).",
    "crumbs": [
      "Module Introduction",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#about-your-instructor",
    "href": "index.html#about-your-instructor",
    "title": "MA22004 - Statistics II",
    "section": "About your instructor",
    "text": "About your instructor\nHi, folks!\n\nI’m Eric—your instructor for MA22004 this semester. I am a new Baxter Fellow in Applied Mathematics at Dundee, and my research focuses on uncertainty quantification and predictive modelling.\nOriginally from the US, I graduated from the University of Pennsylvania with a BA in Mathematics. I wrote my PhD in Probability and Stochastic Analysis at the University of Edinburgh. Math and stats have opened up some exciting doors for me, and I’ve had the opportunity to undertake postdoctoral work at KTH Stockholm, the University of Massachusetts Amherst, and RWTH Aachen University. I’m very excited to be at Dundee and back in Scotland. I’m even more excited to be teaching you statistics this semester!\n\nThese notes are available at dundeemath.github.io/MA22004/ and also as a PDF (visit the page and click on the PDF icon to download).",
    "crumbs": [
      "Module Introduction",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "MA22004 — Statistics II",
    "section": "Licence",
    "text": "Licence\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
    "crumbs": [
      "Module Introduction",
      "Welcome"
    ]
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Lab Guide",
    "section": "",
    "text": "You will learn about the statistical programming language R and the software RStudio by working through seven interactive lab tutorials and completing lab reports. The lab reports should answer the exercise questions at the end of each tutorial.\nTutorials and all associated materials (templates, data sets, further instructions, etc.) are available as an R package at the GitHub repository dundeemath/MA22004labs (i.e., https://github.com/dundeemath/MA22004labs).\nInstructions on how to install and access the interactive lab tutorials can be found at:\n\nhttps://dundeemath.github.io/MA22004labs/.\n\nThe following section contains details about writing lab reports.",
    "crumbs": [
      "Module Introduction",
      "Lab Guide"
    ]
  },
  {
    "objectID": "writing.html",
    "href": "writing.html",
    "title": "Writing Lab Reports",
    "section": "",
    "text": "Assessment Criteria\nThere are seven interactive lab tutorials with accompanying exercises. Each lab tutorial specifies how marks are allocated across the exercises (a maximum of 20 marks available for each lab report).",
    "crumbs": [
      "Module Introduction",
      "Writing Lab Reports"
    ]
  },
  {
    "objectID": "writing.html#w-assess",
    "href": "writing.html#w-assess",
    "title": "Writing Lab Reports",
    "section": "",
    "text": "Marks are awarded for both content and presentation.",
    "crumbs": [
      "Module Introduction",
      "Writing Lab Reports"
    ]
  },
  {
    "objectID": "writing.html#w-content",
    "href": "writing.html#w-content",
    "title": "Writing Lab Reports",
    "section": "Content",
    "text": "Content\nPlease work through the interactive tutorial for each lab. Your lab report should answer the exercises found at the end of each tutorial.",
    "crumbs": [
      "Module Introduction",
      "Writing Lab Reports"
    ]
  },
  {
    "objectID": "writing.html#w-present",
    "href": "writing.html#w-present",
    "title": "Writing Lab Reports",
    "section": "Presentation",
    "text": "Presentation\nPlease use Quarto to create your lab report. Further instructions on using Quarto for creating reproducible lab reports that combine data analysis and text can be found in Lab 1. This set of lecture notes was authored using Quarto; you can see the source code that was used to create various output types in the GitHub repository https://github.com/dundeemath/MA22004.\n\nPlots\nPlots should be neat and legible, with appropriate aesthetic elements. Please use ggplot for creating plots and visualisations. Each plot should be annotated with titles, axis labels, and legends as appropriate. Plot aesthetics should be distinguished, e.g. using colours or line styles that are identified using a legend. Important data points and coordinates should be annotated using labels.\n\n\nMathematical formulas\nMathematical formulas should follow the same style rules as the lecture notes. Formulas can be included in Quarto documents using \\LaTeX{} syntax. There should be appropriate spacing around operators and equals signs, e.g. a + b = c. For punctuation, formulas are treated as part of the text, so they often need to end with a full stop or comma. Important formulas can appear “displayed” on their own line (with line spacing above and below them), e.g., A=πr^2\\,.\n\n\nStructure\nStructure should be logical and clear. Organise your writing with suitable headings and sub-headings. For example, provide a solution to each exercise under its own heading.\n\n\nWriting\nWriting should follow the usual rules of good written English, including writing complete sentences and paragraphs that get to the point quickly. Your tone and language should be similar to lecture notes or scientific journal articles. Formal writing does not require unnecessary words, long words or monotonous use of passive voice. I will reward concise and clear communication, so please do not write, “Upon carefully analysing the aforementioned equations, the following mathematical solution was found,” when “The solution is” conveys the same thing.\n\n\nFormatting\nFormatting should rely on the MA22004 Lab Report template. This is available in the MA22004labs package, and further instructions can be found in Lab 1.",
    "crumbs": [
      "Module Introduction",
      "Writing Lab Reports"
    ]
  },
  {
    "objectID": "00-prelim.html",
    "href": "00-prelim.html",
    "title": "Preliminaries",
    "section": "",
    "text": "Abbreviations\nIn Table 1 we list abbreviations used throughout these lecture notes. These abbreviations are pretty standdard and you might encounter them outside the module in other references.\nTable 1: Commonly used abbreviations.\n\n\n\n\n\n\n\nAbbreviation\nExpanded\n\n\n\n\npdf\nprobability density function\n\n\ncdf\ncumulative distribution function\n\n\nrv\nrandom variable\n\n\niid\nindependent and identically distributed\n\n\nobs\nobservations\n\n\nCI\nconfidence interval\n\n\ndf\ndegrees of freedom",
    "crumbs": [
      "Lecture Notes",
      "Preliminaries"
    ]
  },
  {
    "objectID": "00-prelim.html#notation",
    "href": "00-prelim.html#notation",
    "title": "Preliminaries",
    "section": "Notation",
    "text": "Notation\nUppercase roman letters, e.g., X, will typically denote random variables (rvs); lower case letters, e.g., x, will represent a particular value (observation) of a rv. Rvs have probability distributions. Distributions are typically characterised by parameters that describe population characteristics. In the present module, we will adopt the (frequentists) view that parameters are fixed real numbers that are often unknown and must be estimated from data. Statistical inference is a tool that will help us to do this.\n\n\n\n\n\n\nVariables and parameters\n\n\n\nStatistical models comprise both rvs and parameters. Be careful not to confuse them!\n\n\nFor a random variable X that has a distribution F depending on a set of parameters \\Theta, we will write X \\sim F(\\Theta).\n\n\n\n\n\n\nSpecifying a probability distribution\n\n\n\nWe write X \\sim F(\\Theta) to indicate X has distribution function F(\\Theta). This is not read as “X is approximately F(\\Theta)”!",
    "crumbs": [
      "Lecture Notes",
      "Preliminaries"
    ]
  },
  {
    "objectID": "00-prelim.html#sample-space-events-probabilities",
    "href": "00-prelim.html#sample-space-events-probabilities",
    "title": "Preliminaries",
    "section": "Sample space, events, probabilities",
    "text": "Sample space, events, probabilities\nA sample space \\Omega is a set of possible outcomes of an experiment. Points \\omega \\in \\Omega are sample outcomes or realizations. Subsets A \\subset \\Omega are called events.\n\nExample 1 (Sample space) Consider an experiment where we measure the petal widths from a randomly sampled cyclamen flowers. Before we observe the petal width, there is uncertainty that we can model using a sample space of events. The sample space is \\Omega = (0, \\infty), since measurements of length should be positive (practically, the lengths will have a finite size, too). Each \\omega \\in \\Omega is a measurement of petal width for a cyclamen flower. Consider an event A = (5, 12]; this is the event that the petal width is larger than 5 but less than or equal to 12. Remember, we use probability to model uncertainty before we observe the petal width — after we take a measurement, the petal width is no longer uncertain (we have collected a statistic).\n\nAs sample spaces and events are described using sets, we recall the following notations, definitions, and laws about set theory. Let A, B, and A_1, A_2, \\dots be events in a sample space \\Omega.\n\ncomplement: A^c = \\{ \\omega \\in \\Omega: \\omega \\notin A\\}.\nnull event: \\emptyset = \\Omega^c.\nintersection: A \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ and } \\omega \\in B\\}. In particular, for A_1, A_2, \\dots, then \\bigcap_{i=1}^\\infty A_i = \\{\\omega \\in \\Omega : \\omega \\in A_i \\text{ for all } i \\}\\,.\ndifference: A \\setminus B = \\{\\omega \\in \\Omega : \\omega \\in A, \\omega \\notin B\\}.\nsize: |A| denotes the number of elements in A.\ndisjoint: A_i \\cap A_j = \\emptyset, for i\\neq j.\npartition: disjoint A_1, A_2, \\dots such that \\bigcup_{i=1}^\\infty A_i = \\Omega.\nindicator: I_A(\\omega) = I(\\omega \\in A) = \\{1 \\text{ if } \\omega \\in A; 0 \\text{ if } \\omega \\notin A\\}.\nmonotone increasing: A_1 \\subset A_2 \\subset \\dots and define limit \\lim_{n \\to \\infty}A_n = \\bigcup_{i=1}^\\infty A_i\\,.\nmonotone decreasing: A_1 \\supset A_2 \\supset \\dots and define limit \\lim_{n \\to \\infty} A_n = \\bigcap_{i=1}^\\infty A_i\\,.\ndistributive laws: A\\cap (B\\cup C) = (A\\cap B) \\cup (A \\cap C)\\,, A\\cup(B\\cap C) = (A \\cup B) \\cap (A\\cup C)\\,.\nDe Morgan’s laws: (A \\cap B)^c = A^c \\cup B^c\\,, (A\\cup B)^c = A^c \\cap B^c\\,.\n\nWe assign probabilities to events in our sample space.\n\nDefinition 1 (Probability distribution) A probability distribution is a function P : \\Omega \\to \\mathbf{R} satisfying three axioms:\n\nP(A) \\geq 0 for every A \\subset \\Omega (positivity),\nP(\\Omega) = 1 (totality),\nif A_1, A_2, \\dots are disjoint subsets of \\Omega, then P(\\cup_{i=1}^\\infty A_i) = \\sum_{i=1}^\\infty P(A_i)\\,.\n\n\n\n\n\n\n\n\nPerspectives\n\n\n\nWe can interpret P(A) as representing:\n\nfrequency, i.e., the long-run proportion of times A is true (the frequentist perspective),\ndegrees of belief, i.e, as a measure of the observer’s strength of belief that A is true (the Bayesian perspective).\n\n\n\n\nTheorem 1 (PIE) The principal of inclusion-exclusion, P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\,.\n\nTheorem 1 follows from the definition of a probability distributions and facts about set theory.\n\nDefinition 2 (Probability of an event) For events A from finite sample spaces \\Omega, we assign probabilities according to: P(A) = \\frac{|A|}{|\\Omega|} \\,.\n\nFor finite sample spaces, we assign probabilities according to their long-run frequency of occurring. For an event A, this is the ratio of the size of A (number of ways A can happen) to the size of \\Omega (number of total outcomes).\n\nDefinition 3 (Independent events) Events A and B are independent, i.e., A \\perp \\!\\!\\! \\perp B, iff P(A\\cap B) = P(A)P(B).\n\nThat is, events A and B are independent if and only if the probability of A and B occurring is equal to the the probability A occurring times the probability of B occurring.\n\nDefinition 4 (Conditional probability) If P(B) &gt; 0, then P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\\,.\n\nNote that:\n\nP(\\cdot \\mid B) satisfies the axioms of probability, for fixed B,\nin general, P(A \\mid \\cdot) is not a probability for fixed A, and,\nin general, P(A\\mid B) \\neq P(B \\mid A).\n\n\nTheorem 2 (Bayes Theorem) Let events A_1, \\dots, A_k partition \\Omega, with P(A_i) &gt; 0.\nIf P(B) &gt; 0, then P(A_i \\mid B) = \\frac{P(B\\mid A_i) P(A_i)}{\\sum_j P(B \\mid A_j) P(A_j)}\\,.\n\nGenerally, it is not feasible to assign probabilities to all subsets of \\Omega (e.g., if is infinite). In that case, we restrict to our attention to a \\sigma-algebra \\mathcal{A} (also called, \\sigma-field), which is a collection of sets satisfying:\n\n\\emptyset \\in \\mathcal{A},\nif A_1, A_2, \\dots, \\in \\mathcal{A} then \\cup_{i = 1}^\\infty A_i \\in \\mathcal{A}, 3.A\\in \\mathcal{A} \\implies A^c \\in \\mathcal{A}.\n\nSets in \\mathcal{A} are said to be measurable and (\\Omega, \\mathcal{A}) is a measure space. If P is a probability defined on \\mathcal{A}, then (\\Omega, \\mathcal{A}, P) is called a probability space.\nE.g., when \\Omega \\equiv \\mathbf{R}, we take \\mathcal{A} to be the smallest \\sigma-field containing all open subsets of \\mathbf{R}, which is called the Borel \\sigma-field. If you find these details interesting, take: MA42008 Mathematical Statistics!",
    "crumbs": [
      "Lecture Notes",
      "Preliminaries"
    ]
  },
  {
    "objectID": "00-prelim.html#random-variables",
    "href": "00-prelim.html#random-variables",
    "title": "Preliminaries",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nHow do we link sample spaces and events to data?\n\n\n\nWe use random variables to link sample spaces and events to data.\n\n\n\nDefinition 5 (Random variables) A random variable (rv) is a mapping X : \\Omega \\to \\mathbf{R} that maps \\omega \\in \\Omega \\mapsto X(\\omega).\n\n\nExample 2 Consider a coin flipping experiment where you flip a fair coin eight times. Let X be the number of heads in the sequence. If three heads occur, e.g., \\omega = HTTTTTHH, then X(\\omega) = 3.\n\n\nExample 3 Consider an experiment where you draw a point a random from the unit disk. Then \\Omega = \\{(x,y) : x^2 + y^2 \\leq 1\\} and a typical outcome will be the pair \\omega = (x,y). Some random variables to consider are X(\\omega) = x, Y(\\omega) = y, Z(\\omega) = x+y, and W(\\omega) = \\sqrt{x^2 + y^2}.\n\n\nDefinition 6 (Assigning probabilities to rvs) Given X and A \\subset \\mathbf{R}, we define X^{-1}(A) = \\{\\omega \\in \\Omega : X(\\omega) \\in A\\} and let P(X \\in A) = P(X^{-1}(A)) = P(\\{\\omega \\in \\Omega : X(\\omega) \\in A\\})\\,, e.g., P(X=x) = P(X^{-1}(x)) = P(\\{\\omega \\in \\Omega : X(\\omega) = x\\}).\n\n\n\n\n\n\n\nObservations vs rvs\n\n\n\nX denotes a rv and x denotes a particular value of X.\n\n\n\n\n\n\n\n\nWe measure probabilities of events\n\n\n\nA rv X by itself is not an event. You would never write P(X), would you!?\n\n\n\nExample 4 Consider a coin flipping experiment where you flip a fair coin twice. Let X be the number of heads. Then P(X=0) = P(\\{TT\\}) = \\frac{1}{4}\\,, P(X=1) = P(\\{HT\\} \\cup \\{TH\\}) = P(\\{HT\\}) + P(\\{TH\\}) = \\frac{1}{2}\\,, P(X=2) = P(\\{HH\\}) = \\frac{1}{4}\\,.\n\n\nDefinition 7 (Cdf) The cumulative distribution function (cdf), F_X:\\mathbf{R} \\to [0,1], is defined by F_X(x) = P(X \\leq x).\n\nFigure 1 displays the cdf for the coin flip experiment considered in Example 4. The cdf F_X(x) jumps at x = 0, x=1, and x=2. The height of the jumps are given by P(X=x). We observe as well that F_X(x) = 0 for x&lt;0, as no probability has been accumulated; recall that probabilities are always non-negative, so a function that accumulates probability will always be non-negative. Further, F_X(x) = 1 for x \\geq 2, as all the probability has been accumulated; remember that the total probability that can be assigned over the whole sample space must sum to one.\n\n\n\n\n\n\n\n\nFigure 1: The cdf for the two coin flip example.\n\n\n\n\n\nNote that a cdf completely determines the distribution of a random variable. This statement is captured in Theorem 3.\n\nTheorem 3 Let X have cdf F and Y have cdf G. If F(x) = G(x) for all x, then P(X \\in A)= P(Y \\in A) \\forall A \\in \\mathbf{R}.\n\nSince cdfs determine or characterize a probability distribution, it is useful to know the key properties of cdfs, which are listed below in Theorem 4.\n\nTheorem 4 (Properties of cdfs) F : \\mathbf{R} \\to [0,1] is a cdf for some P iff,\n\nF is nondecreasing (i.e., x_1 &lt; x_2 \\implies F(x_1) \\leq F(x_2)),\nF is normalized to [0,1] (i.e., \\lim_{x \\to -\\infty} F(x) = 0 and \\lim_{x \\to \\infty} F(x) = 1),\nF is right-continuous (i.e., F(x) = F(x^*) \\forall x where F(x^*) = \\lim_{y &gt; x; y \\to x} F(y)).\n\n\nFor a rv X we say X is discrete if it assumes at most a countable number of (discrete) values. For a discrete sample space, the collection of all probabilities of X(\\omega) gives us a probability distribution.\n\nDefinition 8 (Pmf) A pdf for a discrete rv X is f_X(x) = P(X = x). Since this density function places a “point mass” at each x, it is sometimes referred to as a probability mass function (pmf).\n\nFigure 2 displays the pmf for the coin flip experiment considered in Example 4. The pmf is a histogram with point masses at x = 0, x=1, and x=2. The mass placed at these points is given by P(X = x). Since the pmf is a pdf for a discrete random variable, recall from the axioms of probability that the pmf therefore satisfies f(x) \\geq 0, \\forall x \\in \\mathbf{R}, and \\sum_i f(x_i) = 1. This fact can be observed in Figure 2: f_X(0) + f_X(1) + f_X(2) = 0.25 + 0.5 + 0.25 = 1.\n\n\n\n\n\n\n\n\nFigure 2: The histogram (pmf) for the two coin flip example.\n\n\n\n\n\nA rv X is continuous if there exists a continuous function f_X such that,\n\nf_X(x) \\geq 0 \\forall x,\n\\int_{-\\infty}^\\infty f_X(x) dx = 1 and\nP(a &lt; X &lt; b) = \\int_a^b f_X(x) dx, for a\\leq b.\n\n\nDefinition 9 (Pdf) A f_X satisfying the three properties above is a pdf for the continous rv X.\n\n\n\n\n\n\n\nEvents of probability zero\n\n\n\nIf X is continuous, then P(X = x) = 0 for every x. That is, \nP(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b),.\n\n\n\nThe cdf is related to the pdf by the derivative (difference). If X is continuous:  F_X(x) = P(X \\leq x) = \\int_{-\\infty}^x f_X(t) dt and f_X(x) = F_X^\\prime(x) at all x at which F_X is differentiable. (Likewise, if X is discrete, then we replace the integral with a sum F_X(x) = P(X \\leq x) = \\sum_{x_i \\leq x} f_X(x_i).)\n\nDefinition 10 (Quantile function) Let X be a rv with cdf F. The inverse cdf, or quantile function, is defined by F^{-1}(q) = \\inf \\{x : F(x) &gt; q\\} for q \\in [0,1]. If F is monotonic increasing and continuous then F^{-1}(q) is the unique real number x such that F(x) = q.\n\nSome quantiles get used more than others (and therefore get names). Important quantiles include, F^{-1}(\\frac{1}{4}) is the first quantile, F^{-1}(\\frac{1}{2}) is the median, and F^{-1}(\\frac{3}{4}) is the third quantile.\n\nDefinition 11 (Equality in distribution) We say X and Y are equal in distribution, X \\equiv Y, if F_X(x) = F_Y(x) for all x.\n\n\n\n\n\n\n\nEquality in distribution versus equality of rvs\n\n\n\nNote that equality in distribution does not mean that the random variables are the same. Rather, probability statements are the same.\nConsider the following example. Suppose P(X = 1) = P(X = -1) = \\frac{1}{2}\\,. Let Y = -X. Then P(Y = 1) = P(Y = -1) = \\frac{1}{2}\\,. Thus, X \\equiv Y \\,, but X and Y are not equal! In fact, P(X = Y) = 0.\n\n\nWe sometimes consider more than one random variable, taken to together. This leads to the concept of a joint and marginal densities.\n\nDefinition 12 (Joint pdf) A joint pdf for (X,Y) satisfies\n\nf(x,y) \\geq 0 \\forall x,y,\n\\iint_{-\\infty}^\\infty f(x,y) dx dy = 1,\nfor A \\in \\mathbf{R}\\times \\mathbf{R}, P((X,Y) \\in A) = \\iint_A f(x,y) dx dy.\n\n\n\nDefinition 13 (Joint cdf) A joint cdf is given by F(x,y) = P(X\\leq x, Y\\leq y).\n\n\nDefinition 14 (marginal pdf) For X,Y with joint pdf f(x,y), we define the marginals for X and Y as f_X(x) \\int f(x,y) dy and f_Y(y) = \\int f(x,y) dx, respectively.\n\nWe also have a notion of independence for two rvs.\n\nDefinition 15 (Independence of rvs) Rvs X and Y are independent if P(X \\in A, Y \\in B) = P(X \\in A) P(Y \\in B).\n\n\nTheorem 5 Let X,Y have joint f_{XY}. Then X and Y are independent iff f_{XY} = f_X \\cdot f_Y for all x,y.\n\nIf X_1, \\dots X_n are independent and each as the same marginal distribution with cdf F, we say X_1, \\dots, X_n are iid and write X_1, \\dots, X_n \\sim F iid. We also write X_1, \\dots, X_n \\sim f if F has corresponding density f, when no confusion arises. We will often consider collections of iid random variables.\n\nDefinition 16 (Random sample) X_1, \\dots, X_n \\sim F iid is a random sample of size n from a distribution F.\n\nWe also consider the expected value of a rv.\n\nDefinition 17 (Expectation) For a discrete rv X with possible outcomes x_1, x_2, \\dots and corresponding probabilities p_1, p_2, \\dots, the expectation is defined by \\mathbf{E}[X] = \\sum_{i=1}^\\infty x_i p_i\\,.\nFor a continuous rv X with pdf f, the expectation is defined by \\mathbf{E}[X] = \\int_{-\\infty}^{\\infty} x f(x) dx\\,.\n\nFor both discrete and continuous rvs, we refer to various statistics relating to expected values as moments of the distribution.\n\nDefinition 18 (n-th raw moment) For a rv X, the n-th raw moment is given by \\mathbf{E}[X^n].\n\n\nDefinition 19 (n-th central moment) For a rv X with \\mu = \\mathbf{E}[X], the n-th central moment is defined as \\mathbf{E}[(X-\\mu)^n].\n\nThe mean of a distribution is the first raw moment. The variance of a distribution is the second central moment. Quantities related to higher order central moments are also of interest; Table 2 lists some of these with associated “names” that you might encounter. Variance is a measure of dispersion about the mean. Skewness is a measure of the lopsidedness of a distribution. If a distribution is symmetric (and its third central moment is defined) then it will have skewness equal to zero. A distribution that is skewed to the left (i.e., the tail of the distribution is longer on the left) will have negative skewness and a distribution that is skewed to the right (i.e., the tail of the distribution is longer on the right) will have positive skewness. Kurtosis is a measure of how “fat” or “heavy” the tails of a distribution are; distributions with heavy tails will have high kurtosis values. Since variance and kurtosis are related to the even-powered central moments, they will always be non-negative.\n\n\n\nTable 2: First few moments for a rv X with mean \\mu = \\mathbf{E}[X].\n\n\n\n\n\n\n\n(a) Quantities related to raw moments\n\n\n\n\n\nExpression\nName\n\n\n\n\n\\mathbf{E}[X]\nmean\n\n\n\\mathbf{E}[X^2]\n—\n\n\n\\mathbf{E}[X^3]\n—\n\n\n\\mathbf{E}[X^4]\n—\n\n\n\n\n\n\n\n\n\n\n\n(b) Quantities related to central moments\n\n\n\n\n\nExpression\nName\n\n\n\n\n\\mathbf{E}[(X - \\mu)]\n—\n\n\n\\mathbf{E}[(X - \\mu)^2]\nvariance\n\n\n\\mathbf{E}[(X - \\mu)^3 / \\sigma^3]\n(Fisher’s) skewness\n\n\n\\mathbf{E}[(X - \\mu)^4 / \\sigma^4]\nkurtosis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIts all Greek … when it comes to kurtosis\n\n\n\nThe root of kurtosis comes from the Greek word for “bulging” or “convex”. You may see a heavy-tailed or high kurtosis distributions described as leptokurtic (“narrow” + “bulging”) and a light-tailed or low kurtosis distributions described as platykurtic (“broad” or “flat” + “bulging”). The “high” and “low” qualifications are made in relation to the tails of the normal distribution; a distribution having the same kurtosis as the normal distribution can be described as mesokurtic (“middle” + “bulging”).",
    "crumbs": [
      "Lecture Notes",
      "Preliminaries"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html",
    "href": "01-sampling-distributions.html",
    "title": "1  Sampling distributions",
    "section": "",
    "text": "1.1 Uniform distribution\nThe uniform distribution places equal on uniform weight on the items being sampled.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#uniform-distribution",
    "href": "01-sampling-distributions.html#uniform-distribution",
    "title": "1  Sampling distributions",
    "section": "",
    "text": "Definition 1.3 (Uniform distribution) A continuous rv X has a uniform distribution on [a,b] with a&lt;b, if X has pdf \nf(x; a,b) = \\frac{1}{b-a}\\,,\n\\quad a &lt; x &lt; b\\,,\n or zero otherwise. We write X \\sim \\mathsf{Unif}(a,b).\n\n\n\n\n\n\n\nParameters\n\n\n\nNote that a and b are parameters in Definition 1.3.\n\n\n\nExercise 1.1 As an exercise, derive the cdf using the definition. Derive a formula for the mean and variance in terms of the parameters a and b.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#sec-normal-distribution",
    "href": "01-sampling-distributions.html#sec-normal-distribution",
    "title": "1  Sampling distributions",
    "section": "1.2 Normal distribution",
    "text": "1.2 Normal distribution\nNormal distributions play an important role in probability and statistics as they describe many natural phenomena. For instance, the Central Limit Theorem tells us that the sample mean of a large random sample (size m) of rvs with mean \\mu and variance \\sigma^2 is approximately normal in distribution with mean \\mu and variance \\sigma^2/m.\n\nDefinition 1.4 (Normal or Gaussian distribution) A continuous rv X has a normal distribution with parameters \\mu and \\sigma^2, where -\\infty &lt; \\mu &lt; \\infty and \\sigma &gt; 0, if X has pdf \nf(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma}e^{-(x-\\mu)^2/(2\\sigma^2)}\\,,\n\\quad -\\infty &lt; x &lt; \\infty \\,.\n We write X \\sim \\mathsf{N}(\\mu, \\sigma^2).\n\nFor X\\sim \\mathsf{N}(\\mu,\\sigma^2), it can be shown that \\mathbf{E}(X) = \\mu and \\mathop{\\mathrm{Var}}(X) = \\sigma^2, that is, \\mu is the mean and \\sigma^2 is the variance of X. The pdf forms a bell-shaped curve that is symmetric about \\mu, as illustrated in Figure 1.1. The value \\sigma (standard deviation) is the distance from \\mu to the inflection points of the curve. As \\sigma increases, the dispersion in the density increases, as illustrated in Figure 1.2. Thus, the distribution’s position (location) and spread depend on \\mu and \\sigma.\n\n\n\n\n\n\n\n\nFigure 1.1: The pdfs of two normal rvs, X_1 \\sim \\mathsf{N}(-2, 1) and X_2 \\sim \\mathsf{N}(2, 1), with different means and the same standard deviations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: The pdfs of two normal rvs, X_1 \\sim \\mathsf{N}(0, 9) and X_2 \\sim \\mathsf{N}(0, 1), with the same means and different standard deviations.\n\n\n\n\n\n\nDefinition 1.5 (Standard normal distribution) We say that X has a standard normal distribution if \\mu=0 and \\sigma = 1 and we will usually denote standard normal rvs by Z \\sim \\mathsf{N}(0,1) (why Z? tradition!1). We denote the cdf of the standard normal by \\Phi(z) = P(Z \\leq z) and write \\varphi = \\Phi' for its density function.\n\n\n\n\n\n\n\nUseful facts about normal variates\n\n\n\n\nIf X \\sim \\mathsf{N}(\\mu, \\sigma^2), then Z = (X - \\mu) / \\sigma  \\sim \\mathsf{N}(0,1).\nIf Z \\sim \\mathsf{N}(0, 1), then X = \\mu + \\sigma Z \\sim \\mathsf{N}(\\mu, \\sigma^2).\nIf X_i \\sim \\mathsf{N}(\\mu_i, \\sigma_i^2) for i = 1, \\dots, n are independent rvs, then \\sum_{i=1}^{n} X_i \\sim \\mathsf{N} \\left( \\sum_{i=1}^{n} \\mu_i, \\sum_{i=1}^{n} \\sigma_i^2 \\right) \\,.\n\n\n\n\n\n\n\n\n\n\nVariances add\n\n\n\nIn particular, for differences of independent rvs X_1 \\sim \\mathsf{N}(\\mu_1, \\sigma_1^2) and X_2 \\sim \\mathsf{N}(\\mu_2, \\sigma_2^2) then the variances add:  X_1 - X_2 \\sim \\mathsf{N}(\\mu_1 - \\mu_2, \\sigma_1^2 + \\sigma_2^2) \\,.\n\n\nProbabilities P(a \\leq X \\leq b) are found by converting the problem in X \\sim \\mathsf{N}(\\mu, \\sigma^2) to the standard normal distribution Z \\sim \\mathsf{N}(0, 1) whose probability values \\Phi(z) = P(Z\\leq z) can then be looked up in a table. From (1.) above, \n\\begin{aligned}\n   P(a &lt; X &lt; b) &= P\\left( \\frac{a-\\mu}{\\sigma} &lt; Z &lt; \\frac{b-\\mu}{\\sigma} \\right) \\\\\n    &= \\Phi \\left( \\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right) \\,.\n\\end{aligned}\n This process is often referred to as standardising (the normal rv).\n\nExample 1.1 Let X \\sim \\mathsf{N}(5, 9) and find P(X \\geq 5.5).\n\n\\begin{aligned}\n   P(X \\geq 5.5) &= P\\left(Z \\geq \\frac{5.5 - 5}{3}\\right) \\\\\n    &= P(Z \\geq 0.1667) \\\\\n    &= 1 - P(Z \\leq 0.1667) \\\\\n    &= 1 - \\Phi(0.1667) \\\\\n    &= 1 - 0.5662 \\\\\n    &= 0.4338\\,,\n\\end{aligned}\n where we look up the value of \\Phi(z) = P(Z\\leq z) in a table of standard normal curve areas.\nThe probability corresponds to the shaded area under the normal density \\varphi(x) = \\Phi'(x) corresponding to x \\geq 5.5 (see Figure 1.3). To calculate this area, we can also use the r code: pnorm(5.5, mean = 5, sd = 3, lower.tail = FALSE).\n\n\n\n\n\n\n\n\nFigure 1.3: The normal density \\mathsf{N}(5,9) with the (one-sided) interval shaded in blue that corresponds to the probability P(X \\geq 5.5).\n\n\n\n\n\n\n\nExample 1.2 Let X \\sim \\mathsf{N}(5, 9) and find P(4 \\leq X \\leq 5.25).\n\n\\begin{aligned}\n   P(4 \\leq X \\leq 5.25) &= P\\left(\\frac{4-5}{3} \\leq Z \\leq \\frac{5.25-5}{3}\\right) \\\\\n   &= P(-0.3333 \\leq Z \\leq 0.0833) \\\\\n   &= \\Phi(0.0833) - \\Phi(-0.3333) \\\\\n   &= 0.5332 - 0.3694 \\\\\n   &= 0.1638\\,.\n  \\end{aligned}\n where we look up the value of \\Phi(z) = P(Z\\leq z) in a table of standard normal curve areas.\nThe probability corresponds to the shaded area under the normal density \\varphi(x) = \\Phi'(x) corresponding to 4 \\leq x \\leq 5.25 (see Figure 1.4). To calculate this area, we can use the r code: pnorm(5.25, mean = 5, sd = 3) - pnorm(4, mean = 5, sd = 3).\n\n\n\n\n\n\n\n\nFigure 1.4: The normal density \\mathsf{N}(5,9) with the (two-sided) interval shaded in blue that corresponds to the probability P(4 \\leq X \\leq 5.25).\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical rule (68-95-99.7 rule)\n\n\n\nFor samples from a normal distribution, the percentage of values that lie within one, two, and three standard deviations of the mean are 68.27\\%, 95.45\\%, and 99.73\\%, respectively. That is, for X \\sim \\mathsf{N}(\\mu, \\sigma^2), \nP(\\mu - 1 \\sigma \\leq X \\leq \\mu + 1 \\sigma ) \\approx 0.6827\\,,\n \nP(\\mu - 2 \\sigma \\leq X \\leq \\mu + 2 \\sigma ) \\approx 0.9545\\,,\n \nP(\\mu - 3 \\sigma \\leq X \\leq \\mu + 3 \\sigma ) \\approx 0.9973\\,.\n For a normal population, nearly all the values lie within “three sigmas” of the mean.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#t-distribution",
    "href": "01-sampling-distributions.html#t-distribution",
    "title": "1  Sampling distributions",
    "section": "1.3 Student’s \\mathsf{t} distribution",
    "text": "1.3 Student’s \\mathsf{t} distribution\nStudent’s \\mathsf{t} distribution gets its peculiar name as it was first published under the pseudonym “Student”.2 This bit of obfuscation was to protect the identity of his employer,3 and thereby vital trade secrets, in a highly competitive and lucrative industry.\n\nDefinition 1.6 (Student’s \\mathsf{t} distribution) A continuous rv X has a \\mathsf{t} distribution with parameter \\nu &gt; 0, if X has pdf \nf(x; \\nu) = \\frac{\\Gamma\\left(\\tfrac{\\nu+1}{2}\\right)}{\\sqrt{\\nu \\pi} \\Gamma \\left(\\tfrac{\\nu}{2}\\right)} \\left( 1 + \\tfrac{x^2}{\\nu} \\right)^{- \\frac{\\nu+1}{2}} \\,, \\quad -\\infty &lt; x &lt; \\infty\\,.\n We write X \\sim \\mathsf{t}(\\nu). Note \\Gamma is the standard gamma function.4\n\nThe density for \\mathsf{t}(\\nu) for several values of \\nu are plotted below in Figure 1.5.\n\n\n\n\n\n\n\n\nFigure 1.5: The density for \\mathsf{t}(\\nu) for several values of \\nu (df).\n\n\n\n\n\n\n\n\n\n\n\nProperties of \\mathsf{t} distributions\n\n\n\n\nThe density for \\mathsf{t}(\\nu) is a bell-shaped curve centred at 0.\nThe density for \\mathsf{t}(\\nu) is more spread out than the standard normal density (i.e., it has “fatter tails” than the normal).\nAs \\nu \\to \\infty, the spread of the corresponding \\mathsf{t}(\\nu) density converges to the standard normal density (i.e., the spread of the \\mathsf{t}(\\nu) density decreases relative to the standard normal).\n\nIf X \\sim \\mathsf{t}(\\nu), then \\mathbf{E}[X] = 0 for \\nu &gt; 1 (otherwise the mean is undefined).\n\n\n\n\n\n\n\n\nCauchy distribution\n\n\n\nA \\mathsf{t} distributions with \\nu = 1 has pdf f(x) = \\frac{1}{\\pi (1 + x^2)}\\,, and we call this the Cauchy distribution.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#chisq-distribution",
    "href": "01-sampling-distributions.html#chisq-distribution",
    "title": "1  Sampling distributions",
    "section": "1.4 \\chi^2 distribution",
    "text": "1.4 \\chi^2 distribution\nThe \\chi^2 distribution arises as the distribution of a sum of the squares of \\nu independent standard normal rvs.\n\nDefinition 1.7 (\\chi^2 distribution) A continuous rv X has a \\chi^2 distribution with parameter \\nu \\in \\mathbf{N}_{&gt;}, if X has pdf \\begin{equation*}\nf(x; \\nu) = \\frac{1}{2^{\\nu/2} \\Gamma(\\nu/2)} x^{(\\nu/2)-1} e^{-x/2} \\,,\n\\end{equation*} with support x \\in (0, \\infty) if \\nu=1, otherwise x \\in [0, \\infty). We write X \\sim \\chi^2(\\nu).\n\nThe pdf f(x; \\nu) of the \\chi^2(\\nu) distribution depends on a positive integer \\nu referred to as the df. The densities for several values of \\nu are plotted below in Figure 1.6. The density f(x;\\nu) is positively skewed, i.e., the right tail is longer, so the mass is concentrated to the figure’s left in Figure 1.6. The distribution becomes more symmetric as \\nu increases. We denote critical values of the \\chi^2(\\nu) distribution by \\chi^2_{\\alpha, \\nu}.\n\n\n\n\n\n\n\n\nFigure 1.6: The density for \\chi^2(\\nu) for several values of \\nu (df).\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nUnlike the normal and t distributions, the \\chi^2 distribution is not symmetric! This means that critical values, e.g., \\chi^2_{.99, \\nu} \\quad \\text{and}\\quad \\chi^2_{0.01,\\nu}\\,, are not equal. Hence, it will be necessary to look up both values for CIs based on \\chi^2 critical values.\n\n\nIf X \\sim \\chi^2(\\nu), then \\mathbf{E}[X] = \\nu and \\Var[X] = 2\\nu.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#F-distribution",
    "href": "01-sampling-distributions.html#F-distribution",
    "title": "1  Sampling distributions",
    "section": "1.5 \\mathsf{F} distribution",
    "text": "1.5 \\mathsf{F} distribution\nThe \\mathsf{F} distribution (“F” for Fisher) arises as a test statistic when comparing population variances and in the analysis of variance (see @ref(anova)).\n\nDefinition 1.8 (\\mathsf{F} distribution) A continuous rv X has an \\mathsf{F} distribution with df parameters \\nu_1 and \\nu_2, if X has pdf \nf(x; \\nu_1, \\nu_2) =\n    \\frac{\\Gamma\\left(\\frac{\\nu_1+\\nu_2}{2}\\right) \\nu_1^{\\nu_1/2} \\nu_2^{\\nu_2/2}}\n{\\Gamma\\left(\\frac{\\nu_1}{2}\\right) \\Gamma\\left(\\frac{\\nu_2}{2}\\right)}\n\\frac{x^{\\nu_1/2 - 1}}{(\\nu_2+\\nu_1 x)^{(\\nu_1+\\nu_2)/2}} \\,.\n\n\nThe pdf f(x; \\nu_1, \\nu_2) of the \\mathsf{F}(\\nu_1, \\nu_2) distribution depends on two positive integers \\nu_1 and \\nu_2 referred to, respectively, as the numerator and denominator df. The density is plotted below for several combinations of (\\nu_1, \\nu_2) in Figure 1.7.\n\n\n\n\n\n\n\n\nFigure 1.7: The density for \\mathsf{F}(\\nu_1, \\nu_2) for several combinations of (\\nu_1, \\nu_2).\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhere do the terms numerator and denominator df come from?\n\n\nThe \\mathsf{F} distribution is related to ratios of \\chi^2 rvs, as captured in Theorem 1.1.\n\nTheorem 1.1 (Ratio of \\chi^2 rvs) If X_1 \\sim \\chi^2(\\nu_1) and X_2 \\sim \\chi^2(\\nu_2) are independent rvs, then the rv \nF = \\frac{X_1 / \\nu_1}{X_2 / \\nu_2} \\quad \\sim \\mathsf{F}(\\nu_1,\\nu_2)\\,,\n that comprises the ratio of two \\chi^2 rvs divided by their respective df has an \\mathsf{F}(\\nu_1, \\nu_2) distribution.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#footnotes",
    "href": "01-sampling-distributions.html#footnotes",
    "title": "1  Sampling distributions",
    "section": "",
    "text": "“Traditions, traditions… Without our traditions, our lives would be as shaky as a fiddler on the roof!” [https://www.youtube.com/watch?v=gRdfX7ut8gw].↩︎\nWilliam Sealy Gosset (1876–1937) wrote under the pseudonym “Student” [https://mathshistory.st-andrews.ac.uk/Biographies/Gosset/].↩︎\nGosset invented the t-test to handle small samples for quality control in brewing, specifically for the Guinness brewery in Dublin [https://www.wikiwand.com/en/Guinness_Brewery].↩︎\nThe gamma function is defined by \\Gamma(z) = \\int_0^\\infty x^{z-1}e^{-x} dx when the real part of z is positive. For any positive integer n, \\Gamma(n) = (n-1)! and for half-integers \\Gamma(\\tfrac{1}{2} + n) = \\frac{(2n)!}{4^n n!} \\sqrt{\\pi}.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "10-investigations.html",
    "href": "10-investigations.html",
    "title": "Curated Content",
    "section": "",
    "text": "Investigation 0\nWhat is Statistics?",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-0",
    "href": "10-investigations.html#investigation-0",
    "title": "Curated Content",
    "section": "",
    "text": "Cambridge Ideas - Professor Risk\n\nhttps://www.youtube.com/watch?v=a1PtQ67urG4 Prof David Spiegelhalter (Cambridge University) discusses public understanding of risk. You may also be interested in reading (Spiegelhalter 2020).\n\n\n\nThe Joy of Statistics\n\nhttps://www.youtube.com/watch?v=jbkSRLYSojo Prof Hans Rosling (Karolinska Institute and Gapminder Foundation) analyses data from 200 Countries over 200 Years in 4 Minutes - The Joy of Stats - BBC Four.\n\n\n\nTeach statistics before calculus!\n\nhttps://www.ted.com/talks/arthur_benjamin_teach_statistics_before_calculus Prof Arthur Benjamin (Harvey Mudd College) argues that the pinnacle of math education is probability and statistics — not calculus.\n\n\n\nKaggle\n\nhttps://www.kaggle.com/ Towards data science.\n\n\nhttps://www.youtube.com/watch?v=TNzDMOg_zsw What’s Kaggle?",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-1",
    "href": "10-investigations.html#investigation-1",
    "title": "Curated Content",
    "section": "Investigation 1",
    "text": "Investigation 1\nDefence against the dark arts.\n\n\nThree ways to spot bad statistics\n\nhttps://www.ted.com/talks/mona_chalabi_3_ways_to_spot_a_bad_statistic Mona Chalabi (Data Journalist) discusses three ways to spot bad statistics.\n\n\n\n\n\n\n\nStatistics Done Wrong\n\nhttps://www.statisticsdonewrong.com/ A book by Dr Alex Reinhart (Carnegie Mellon University).\n\n\n\nHow to defend yourself against misleading statistics in the news\n\nhttps://www.youtube.com/watch?v=mJ63-bQc9Xg Sanne Blauw (Journalist) discusses how the presentation of statistics can mislead.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-2",
    "href": "10-investigations.html#investigation-2",
    "title": "Curated Content",
    "section": "Investigation 2",
    "text": "Investigation 2\nData analysis and visualisation.\n\n\nThe Grammar of Graphics\n\nhttps://www.youtube.com/watch?v=h-62NwWUI5c What Makes A Good Visualisation? Rhys Jackson from RocketMill, a UK Digital Marketing Agency, gives a perspective on visualising data from a marketing perspective.\n\n\nhttps://www.youtube.com/watch?v=kepKM7Z2O54 David Keyes (RStudio) discusses how the grammar of graphics underpins the ggplot2 data visualization package in R.\n\n\n\nSame Stats, Different Graphs\n\nhttps://www.autodeskresearch.com/publications/samestats Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing (ACM SIGCHI Conference on Human Factors in Computing Systems) by Justin Matejka, George Fitzmaurice.\n\n\n\nWhy do we so often use 0.05 for hypothesis testing?\n\nhttps://www.openintro.org/book/stat/why05/ In this online exercise, you will gain an improved understanding of what a significance level is, and why a value in the neighbourhood of 0.05 is reasonable as a default.\n\n\n\nData visualisations\n\nhttps://flowingdata.com/ FlowingData blog by Nathan Yau.\n\n\nhttps://fivethirtyeight.com/ FiveThirtyEight blog by Nate Silver.\n\n\n\nStorytelling with data\n\nhttp://www.storytellingwithdata.com/blog Blog with nice hints and tips for how to present data in tables, graphics, and visualisations.\n\n\nhttps://community.storytellingwithdata.com/challenges Monthly challenge.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-3",
    "href": "10-investigations.html#investigation-3",
    "title": "Curated Content",
    "section": "Investigation 3",
    "text": "Investigation 3\nStatistical paradoxes.\n\n\nHow statistics can be misleading (TED-Ed)\n\nhttps://www.ted.com/talks/mark_liddell_how_statistics_can_be_misleading Mark Liddell (Educator) discusses Simpson’s Paradox in this TED-Ed animation.\n\n\n\nLow birth-weight paradox\n\nhttps://www.wikiwand.com/en/Low_birth-weight_paradox\n\n\n\nGambler’s Fallacy\n\nhttps://www.youtube.com/watch?v=4eVluL-idkM Prof Kelly Shue (Chicago Booth) discusses the gambler’s fallacy.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-4",
    "href": "10-investigations.html#investigation-4",
    "title": "Curated Content",
    "section": "Investigation 4",
    "text": "Investigation 4\nThe law and interpreting statistics.\n\n\nHow stats fool juries.\n\nhttps://youtu.be/kLmzxmRcUTo Prof Peter Donnelly (Oxford University) discusses common mistakes in interpreting statistics.\n\n\n\n\n\n\n\nMeasurement Uncertainty Calculator (MUCalc)\n\nhttps://discovery.dundee.ac.uk/en/publications/measurement-uncertainty-calculator-mucalc The Leverhulme Research Centre for Forensic Science Measurement Uncertainty Calculator (MUCalc) is an application for calculating measurement uncertainty in accordance with the standards of International Organization for Standardization ISO/IEC 17025.\n\n\n\nProsecutor’s fallacy\n\nhttps://www.wikiwand.com/en/Prosecutor%27s_fallacy A fallacy of statistical reasoning, typically used by a prosecutor to exaggerate the likelihood of guilt: because P(\\text{hypothesis} \\mid \\text{evidence}) \\neq P(\\text{evidence} \\mid \\text{hypothesis})!",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-5",
    "href": "10-investigations.html#investigation-5",
    "title": "Curated Content",
    "section": "Investigation 5",
    "text": "Investigation 5\nData-driven decision making in epidemiology.\n\n\nProject Tycho\n\nhttps://www.tycho.pitt.edu/ Digitized archival epidemiological data for the United States and the world.\n\n\nhttps://www.youtube.com/watch?v=Kn9OJy1BPDo An overview of the origins of project Tycho.\n\n\n\n\n\n\n\nOur World in Data\n\nhttps://ourworldindata.org/ A project of the Oxford Martin School to make public health data, including progress in UN Sustainable Development Goals, available and accessible.\n\n\n\nDemographic Party Trick\n\nhttps://www.youtube.com/watch?v=2nDh8MQuS-Y Prof Hans Rosling (Karolinska Institute and Gapminder Foundation) and Bill Gates seek to shed light on the true statistics of childhood vaccinations.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-6",
    "href": "10-investigations.html#investigation-6",
    "title": "Curated Content",
    "section": "Investigation 6",
    "text": "Investigation 6\nSpurious correlations!\n\n\nThe danger of mixing up causality and correlation\n\nhttps://www.youtube.com/watch?v=8B271L3NtAw Prov Ionica Smeets (University of Leiden) discusses causality and correlation.\n\n\n\nSpurious correlations\n\nhttps://tylervigen.com/spurious-correlations Tyler Vigen’s site dedicated to spurious correlations.\n\n\n\nCause & Effect\n\nhttps://www.youtube.com/watch?v=lbODqslc4Tg Correlation vs. causality from the Clip from the 2010 documentary “Freakonomics: The Movie”.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-7",
    "href": "10-investigations.html#investigation-7",
    "title": "Curated Content",
    "section": "Investigation 7",
    "text": "Investigation 7\nData and Society: can data-driven and predictive modelling lead to a better world? What are the ethics of mass data collection?\n\n\nScience behind the news: Predictive Policing\n\nhttps://www.youtube.com/watch?v=74_jreara3w The Los Angeles Police Department is using a new tactic in their fight against crime called “predictive policing.” It’s a computer program originally developed by a team at UCLA, including mathematician Andrea Bertozzi and anthropologist Jeff Brantingham. “Science Behind the News” is produced in partnership with NBC Learn. (Provided by the National Science Foundation & NBC Learn)\n\n\n\nYou should get paid for your data\n\nhttps://www.nytimes.com/video/opinion/100000006678020/data-privacy-jaron-lanier-2.html Jaron Lanier (Computer Scientist and Author) discusses a compensation plan and data dignity.\n\n\nhttps://www.ted.com/talks/jennifer_zhu_scott_why_you_should_get_paid_for_your_data Jennifer Zhu Scott (Computer Scientist) also thinks you should get paid for your data.\n\n\n\nHow tech companies deceive you into giving up your data and privacy\n\nhttps://www.ted.com/talks/finn_lutzow_holm_myrstad_how_tech_companies_deceive_you_into_giving_up_your_data_and_privacy Finn Lützow-Holm Myrstad (Norwegian Consumer Council) discusses consumer protections and data collection.\n\n\n\nYour company’s data could help end world hunger\n\nhttps://www.ted.com/talks/mallory_freeman_your_company_s_data_could_help_end_world_hunger Mallory Freeman (Data Scientist) discusses how to do the most good with data.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "10-investigations.html#investigation-8",
    "href": "10-investigations.html#investigation-8",
    "title": "Curated Content",
    "section": "Investigation 8",
    "text": "Investigation 8\nMachine learning / big data.\n\n\nWhat is Machine Learning?\n\nhttps://www.youtube.com/watch?v=f_uwKZIAeM0 OxfordSparks discusses the topic of supervised learning algorithms and how machine learning is used all around us.\n\n\n\nBig Data (TED-Ed)\n\nhttps://www.youtube.com/watch?v=j-0cUmUyb-Y Tim Smith (educator) discusses the historical arc of big data in this TED-Ed animation.\n\n\n\nThe human insights missing from big data\n\nhttps://www.ted.com/talks/tricia_wang_the_human_insights_missing_from_big_data Tricia Wang (Ethnographer) discusses the human insights missing from big data.\n\n\n\nHow we can find ourselves in data\n\nhttps://www.ted.com/talks/giorgia_lupi_how_we_can_find_ourselves_in_data Giorgia Lupi (Designer) discusses a humanistic approach to data and data visualization.\n\n\n\n\n\n\n\nSpiegelhalter, David J. 2020. The Art of Statistics: Learning from Data. London: Pelican Books.",
    "crumbs": [
      "Appendices",
      "Curated Content"
    ]
  },
  {
    "objectID": "about-me.html",
    "href": "about-me.html",
    "title": "About Your Instructor",
    "section": "",
    "text": "Hi, folks!\n\nI’m Eric—your instructor for MA22004 this semester. I am a new Baxter Fellow in Applied Mathematics at Dundee, and my research focuses on uncertainty quantification and predictive modelling.\nOriginally from the US, I graduated from the University of Pennsylvania with a BA in Mathematics. I wrote my PhD in Probability and Stochastic Analysis at the University of Edinburgh. Math and stats have opened up some exciting doors for me, and I’ve had the opportunity to undertake postdoctoral work at KTH Stockholm, the University of Massachusetts Amherst, and RWTH Aachen University. I’m very excited to be at Dundee and back in Scotland. I’m even more excited to be teaching you statistics this semester!\nEric Hall\nDundee, 2024",
    "crumbs": [
      "Home",
      "Module Introduction",
      "About Your Instructor"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#sec-uniform-distribution",
    "href": "01-sampling-distributions.html#sec-uniform-distribution",
    "title": "1  Sampling distributions",
    "section": "",
    "text": "Definition 1.3 (Uniform distribution) A continuous rv X has a uniform distribution on [a,b] with a&lt;b, if X has pdf \nf(x; a,b) = \\frac{1}{b-a}\\,,\n\\quad a &lt; x &lt; b\\,,\n or zero otherwise. We write X \\sim \\mathsf{Unif}(a,b).\n\n\n\n\n\n\n\nParameters\n\n\n\nNote that a and b are parameters in Definition 1.3.\n\n\n\nExercise 1.1 As an exercise, derive the cdf using the definition. Derive a formula for the mean and variance in terms of the parameters a and b.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#sec-t-distribution",
    "href": "01-sampling-distributions.html#sec-t-distribution",
    "title": "1  Sampling distributions",
    "section": "1.3 Student’s \\mathsf{t} distribution",
    "text": "1.3 Student’s \\mathsf{t} distribution\nStudent’s \\mathsf{t} distribution gets its peculiar name as it was first published under the pseudonym “Student”.2 This bit of obfuscation was to protect the identity of his employer,3 and thereby vital trade secrets, in a highly competitive and lucrative industry.\n\nDefinition 1.6 (Student’s \\mathsf{t} distribution) A continuous rv X has a \\mathsf{t} distribution with parameter \\nu &gt; 0, if X has pdf \nf(x; \\nu) = \\frac{\\Gamma\\left(\\tfrac{\\nu+1}{2}\\right)}{\\sqrt{\\nu \\pi} \\Gamma \\left(\\tfrac{\\nu}{2}\\right)} \\left( 1 + \\tfrac{x^2}{\\nu} \\right)^{- \\frac{\\nu+1}{2}} \\,, \\quad -\\infty &lt; x &lt; \\infty\\,.\n We write X \\sim \\mathsf{t}(\\nu). Note \\Gamma is the standard gamma function.4\n\nThe density for \\mathsf{t}(\\nu) for several values of \\nu are plotted below in Figure 1.5.\n\n\n\n\n\n\n\n\nFigure 1.5: The density for \\mathsf{t}(\\nu) for several values of \\nu (df).\n\n\n\n\n\n\n\n\n\n\n\nProperties of \\mathsf{t} distributions\n\n\n\n\nThe density for \\mathsf{t}(\\nu) is a bell-shaped curve centred at 0.\nThe density for \\mathsf{t}(\\nu) is more spread out than the standard normal density (i.e., it has “fatter tails” than the normal).\nAs \\nu \\to \\infty, the spread of the corresponding \\mathsf{t}(\\nu) density converges to the standard normal density (i.e., the spread of the \\mathsf{t}(\\nu) density decreases relative to the standard normal).\n\nIf X \\sim \\mathsf{t}(\\nu), then \\mathbf{E}[X] = 0 for \\nu &gt; 1 (otherwise the mean is undefined).\n\n\n\n\n\n\n\n\nCauchy distribution\n\n\n\nA \\mathsf{t} distributions with \\nu = 1 has pdf f(x) = \\frac{1}{\\pi (1 + x^2)}\\,, and we call this the Cauchy distribution.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#sec-chisq-distribution",
    "href": "01-sampling-distributions.html#sec-chisq-distribution",
    "title": "1  Sampling distributions",
    "section": "1.4 \\chi^2 distribution",
    "text": "1.4 \\chi^2 distribution\nThe \\chi^2 distribution arises as the distribution of a sum of the squares of \\nu independent standard normal rvs.\n\nDefinition 1.7 (\\chi^2 distribution) A continuous rv X has a \\chi^2 distribution with parameter \\nu \\in \\mathbf{N}_{&gt;}, if X has pdf \\begin{equation*}\nf(x; \\nu) = \\frac{1}{2^{\\nu/2} \\Gamma(\\nu/2)} x^{(\\nu/2)-1} e^{-x/2} \\,,\n\\end{equation*} with support x \\in (0, \\infty) if \\nu=1, otherwise x \\in [0, \\infty). We write X \\sim \\chi^2(\\nu).\n\nThe pdf f(x; \\nu) of the \\chi^2(\\nu) distribution depends on a positive integer \\nu referred to as the df. The densities for several values of \\nu are plotted below in Figure 1.6. The density f(x;\\nu) is positively skewed, i.e., the right tail is longer, so the mass is concentrated to the figure’s left in Figure 1.6. The distribution becomes more symmetric as \\nu increases. We denote critical values of the \\chi^2(\\nu) distribution by \\chi^2_{\\alpha, \\nu}.\n\n\n\n\n\n\n\n\nFigure 1.6: The density for \\chi^2(\\nu) for several values of \\nu (df).\n\n\n\n\n\n\n\n\n\n\n\nSkew\n\n\n\nUnlike the normal and t distributions, the \\chi^2 distribution is not symmetric! This means that critical values, e.g., \\chi^2_{.99, \\nu} \\quad \\text{and}\\quad \\chi^2_{0.01,\\nu}\\,, are not equal. Hence, it will be necessary to look up both values for CIs based on \\chi^2 critical values.\n\n\nIf X \\sim \\chi^2(\\nu), then \\mathbf{E}[X] = \\nu and \\mathop{\\mathrm{Var}}[X] = 2\\nu.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "01-sampling-distributions.html#sec-F-distribution",
    "href": "01-sampling-distributions.html#sec-F-distribution",
    "title": "1  Sampling distributions",
    "section": "1.5 \\mathsf{F} distribution",
    "text": "1.5 \\mathsf{F} distribution\nThe \\mathsf{F} distribution (“F” for Fisher) arises as a test statistic when comparing population variances and in the analysis of variance (see @sec-anova).\n\nDefinition 1.8 (\\mathsf{F} distribution) A continuous rv X has an \\mathsf{F} distribution with df parameters \\nu_1 and \\nu_2, if X has pdf \nf(x; \\nu_1, \\nu_2) =\n    \\frac{\\Gamma\\left(\\frac{\\nu_1+\\nu_2}{2}\\right) \\nu_1^{\\nu_1/2} \\nu_2^{\\nu_2/2}}\n{\\Gamma\\left(\\frac{\\nu_1}{2}\\right) \\Gamma\\left(\\frac{\\nu_2}{2}\\right)}\n\\frac{x^{\\nu_1/2 - 1}}{(\\nu_2+\\nu_1 x)^{(\\nu_1+\\nu_2)/2}} \\,.\n\n\nThe pdf f(x; \\nu_1, \\nu_2) of the \\mathsf{F}(\\nu_1, \\nu_2) distribution depends on two positive integers \\nu_1 and \\nu_2 referred to, respectively, as the numerator and denominator df. The density is plotted below for several combinations of (\\nu_1, \\nu_2) in Figure 1.7.\n\n\n\n\n\n\n\n\nFigure 1.7: The density for \\mathsf{F}(\\nu_1, \\nu_2) for several combinations of (\\nu_1, \\nu_2).\n\n\n\n\n\n\n\n\n\n\n\nWhere do the terms numerator and denominator df come from?\n\n\n\nThe \\mathsf{F} distribution is related to ratios of \\chi^2 rvs, as captured in Theorem 1.1.\n\n\n\nTheorem 1.1 (Ratio of \\chi^2 rvs) If X_1 \\sim \\chi^2(\\nu_1) and X_2 \\sim \\chi^2(\\nu_2) are independent rvs, then the rv \nF = \\frac{X_1 / \\nu_1}{X_2 / \\nu_2} \\quad \\sim \\mathsf{F}(\\nu_1,\\nu_2)\\,,\n that comprises the ratio of two \\chi^2 rvs divided by their respective df has an \\mathsf{F}(\\nu_1, \\nu_2) distribution.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html",
    "href": "02-basics-stat-infer.html",
    "title": "2  Basics of statistical inference",
    "section": "",
    "text": "2.1 Point estimation\nStatistical inference seeks to draw conclusions about the characteristics of a population from data. For example, suppose we are botanists interested in the taxonomic classification of iris flowers. Let \\mu denote the true average petal length (in cm) of the Iris setosa1 (AKA the bristle-pointed iris). The parameter \\mu is a characteristic of the whole population of the setosa species. Before we collect data, the petal lengths of m independent setosa flowers are denoted by rvs X_1, X_2, \\dots, X_m. Any function of the X_i’s, such as the sample mean, \n  \\overline{X} = \\frac{1}{m} \\sum_{i=1}^m X_i\\,,\n\\tag{2.1} or the sample variance, \n  S^2 = \\frac{1}{m-1} \\sum_{i=1}^m (X_i - \\overline{X})^2 \\,,\n\\tag{2.2} is also a rv.\nSuppose we actually find and measure the petal length of 50 independent setosa flowers resulting in observations x_1, x_2, \\dots, x_{50}; the distribution (counts) of 50 such petal length measurements are displayed in Figure 2.1. The sample mean \\overline{x} for petal length can then be used to draw a conclusion about the (true) value of the population mean \\mu. Based on the data in Figure 2.1 and using Equation 2.1, the value of the sample mean is \\overline{x} = 1.462. The value \\overline{x} provides a “best guess” or point estimate for the true value of \\mu based on the m=50 samples.\nFigure 2.1: The distribution (counts) of m = 50 setosa petal length measurments.\nDefinition 2.1 does not say how to select an appropriate statistic. For the setosa example, the sample mean \\overline{X} is suggested as a good estimator of the population mean \\mu. That is, \\widehat{\\mu} = \\overline{X} or:\nHere, while \\mu and \\sigma^2 are fixed quantities representing population characteristics, \\overline{X} and S^2 are rvs with sampling distributions. If the population is normally distributed or if the sample is large then the sampling distribution for \\overline{X} has a known form: \n  \\overline{X} \\sim \\mathsf{N}(\\mu, \\sigma^{2} / m) \\,,\n that is, \\overline{X} is normal with mean \\mu_{\\overline{X}} = \\mu and variance \\sigma_{\\overline{X}}^2 = \\sigma^{2} / m where m is the sample size and \\mu and \\sigma are the (typically unknown) population parameters.\nIn addition to reporting a point estimate and its estimator, some indication of its precision should be given. One measure of the precision of an estimate is its standard error.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#sec-point-estimation",
    "href": "02-basics-stat-infer.html#sec-point-estimation",
    "title": "2  Basics of statistical inference",
    "section": "",
    "text": "Loading datasets\n\n\n\nThe datasets package has a variety of datasets that you can play with. Once installed, data sets can be accessed in r by loading library(datasets) and then calling, e.g., data(iris) to see the iris data set. For a full list of available data sets, call library(help = \"datasets\") from the console.\n\n\n\n\n\n\n\n\nNote 2.1: Iris Data\n\n\n\n\n\nThe botanist Edgar Anderson’s Iris Data contains 50 obs. of four features (sepal length [cm], sepal width [cm], petal length [cm], and petal width [cm]) for each of three plant species (setosa, virginica, versicolor) for 150 obs. total.\n\n\nCode\niris |&gt; glimpse()\n\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, set…\n\n\n\n\n\n\nDefinition 2.1 (Point estimate) A point estimate of a parameter \\theta (recall: a parameter is a fixed, unknown quantity) is a single number that we consider a reasonable value for \\theta. Consider \\text{iid}\\; X_1, X_2, \\dots, X_m \\sim F(\\theta)\\,. A point estimator \\widehat{\\theta}_m of \\theta is obtained by selecting a suitable statistic g, \n  \\widehat{\\theta}_m = g(X_1, \\dots, X_m) \\,.\n A point estimate \\widehat{\\theta}_m can then be computed from the estimator using sample data.\n\n\n\n\n\n\n\nOverloaded notation\n\n\n\nThe symbol \\widehat{\\theta}_m (or simply \\widehat{\\theta} when the sample size m is clear from context) is typically used to denote both the estimator and the point estimate resulting from a given sample.\n\n\n\n\n\n\n\n\nBest practice for reporting\n\n\n\nWriting, e.g., \\widehat{\\theta} = 42 does not indicate how the point estimate was obtained. Therefore, it is essential to report both the estimator and the resulting point estimate.\n\n\n\n\n“the point estimator of \\mu is the sample mean \\overline{X}”.\n\n\n\n\n\n\n\n\nNote 2.2: Cherry Tree Data\n\n\n\n\n\nThe Cherry Tree Data contains 31 obs. of three features (diameter, height, and volume).\n\n\nCode\ntrees |&gt; glimpse()\n\n\nRows: 31\nColumns: 3\n$ Girth  &lt;dbl&gt; 8.3, 8.6, 8.8, 10.5, 10.7, 10.8, 11.0, 11.0, 11.1, 11.2, 11.3, 11.4, 11.4…\n$ Height &lt;dbl&gt; 70, 65, 63, 72, 81, 83, 66, 75, 80, 75, 79, 76, 76, 69, 75, 74, 85, 86, 7…\n$ Volume &lt;dbl&gt; 10.3, 10.3, 10.2, 16.4, 18.8, 19.7, 15.6, 18.2, 22.6, 19.9, 24.2, 21.0, 2…\n\n\n\n\n\n\nExample 2.1 Let us consider the heights (measured in inches) of 31 black cherry trees (sorted, for your enjoyment) in Table 2.1.\n\n\n\n\nTable 2.1: Observations of m = 31 felled black cherry trees.\n\n\n\n\n\n\n\nHeight [in]\n\n\n\n\n63, 64, 65, 66, 69, 70, 71, 72, 72, 74, 74, 75, 75, 75, 76, 76, 77, 78, 79, 80, 80, 80, 80, 80, 81, 81, 82, 83, 85, 86, 87\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.2: Normal quantile-quantile plot for the Height variable (feature) in the Cherry Tree Data.\n\n\n\n\n\nThe quantile-quantile plot in Figure 2.2, which compares the quantiles of this data to the quantiles of a normal distribution, is fairly straight. Therefore, we assume that the distribution of black cherry tree heights is (at least approximately) normal with a mean value \\mu; i.e., that the population of heights is distributed \\mathsf{N}(\\mu, \\sigma^2), where \\mu is a parameter to be estimated and \\sigma^2 is unknown. The observations X_1, \\dots, X_{31} are then assumed to be a random sample from this normal distribution, \n\\text{iid} \\quad X_1, \\dots, X_{31} \\sim \\mathsf{N}(\\mu, \\sigma^2) \\,.\n\nConsider the following three different estimators and the resulting point estimates for \\mu based on the 31 samples in Table 2.1.\n\nEstimator (sample mean) \\overline{X} as in Equation 2.1 and estimate \\overline{x} = \\sum x_i / n = 2356 / 31 = 76.\nEstimator (average of extreme heights) \\widetilde{X} = [\\min(X_i) + \\max(X_i)]/2 and estimate \\widetilde{x} = (63 + 87)/2 = 75.\nEstimator (10\\% trimmed mean – i.e., in this instance exclude the smallest and largest three values) \\overline{X}_{\\text{tr}(10)} and estimate \\overline{x}_{\\text{tr}(10)} = (2356 - 63 - 64 - 65 - 87 - 86 - 85) / 25 = 76.24.\n\nEach estimator above uses a different notion of “centre” for the sample data, i.e., represents a different statistic. An interesting question is: which estimator will tend to produce estimates closest to the true parameter value? Will the estimators work universally well for all distributions?\n\n\n\n\n\n\n\nHow do we tell whether a population is normal?\n\n\n\nConstructing a normal quantile-quantile plot (or QQ plot) is one way of assessing whether a normality assumption is reasonable. A QQ plot compares the quantiles of the sample data x_i against the theoretical standard normal quantiles, see Figure 2.2. If the sample data is consistent with a sample from a normal distribution, the points will lie in a straight line (more or less). The QQ plot in Figure 2.2 compares quantiles of cherry tree heights from Table 2.1 to normal quantiles. It is produced using the following code.\n\n\nCode\ntrees |&gt; ggplot(aes(sample = Height)) + stat_qq() + stat_qq_line()\n\n\nThe data trees is piped to the command ggplot. For a QQ plot the key aesthetic element is sample; in this particular instance we set this to Height. The geometry stat_qq() adds the data quantiles plotted versus the normal quantiles. The geometry stat_qq_line() simply adds the fit line.\n\n\n\nExample 2.2 Although probably overkill for this problem, the infer package can be used for point estimation using the specify and calculate commands as follows:\n\n\nCode\ntrees |&gt;\n specify(response = Height) |&gt;\n calculate(stat = \"mean\")\n\n\nResponse: Height (numeric)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1    76\n\n\nThe response option specifies the variable of interest, and the stat option can be changed to several quantities of interest.\n\n\n\nDefinition 2.2 (Standard error) The standard error of an estimator \\widehat{\\theta} is the standard deviation \n\\sigma_{\\widehat{\\theta}} = \\sqrt{\\mathop{\\mathrm{Var}}(\\widehat{\\theta})}\\,.\n Often, the standard error depends on unknown parameters and must also be estimated. The estimated standard error is denoted by \\widehat{\\sigma}_{\\widehat{\\theta}} or simply s_{\\widehat{\\theta}}.\n\n\n\n\n\n\n\nAlternative notation\n\n\n\nThe standard error is sometimes denoted \\mathsf{se}= \\mathsf{se}(\\widehat{\\theta}) and the estimated standard error by \\widehat{\\mathsf{se}}.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#confidence-intervals",
    "href": "02-basics-stat-infer.html#confidence-intervals",
    "title": "2  Basics of statistical inference",
    "section": "2.2 Confidence intervals",
    "text": "2.2 Confidence intervals\nAn alternative to reporting a point estimate for a parameter is to report an interval estimate suggesting an entire range of plausible values for the parameter of interest. A confidence interval is an estimate that makes a probability statement about the interval’s degree of reliability. The first step in computing a confidence interval is to select the confidence level \\alpha. A popular choice is a 95\\% confidence interval which corresponds to level \\alpha = 0.05.\n\n\nCode\nA $100(1-\\alpha)\\%$ **confidence interval** for a parameter $\\theta$ is a *random* interval $C_m = (L_m , U_m)$, where $L_m = \\ell(X_1, \\dots, X_m)$ and $U_m = u(X_1, \\dots, X_m)$ are functions of the data, such that \n\\begin{equation}\nP_{\\theta}(L_m &lt; \\theta &lt; U_m ) = 1 - \\alpha\\,, \n\\end{equation}\nfor all $\\theta \\in \\Theta$. \n\n\nMy favourite interpretation of a confidence interval is due to (Wasserman 2004, p 92):\n\nOn day 1, you collect data and construct a 95 percent confidence interval for a parameter \\theta_1. On day 2, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\theta_2. On day 3, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\theta_3. You continue this way constructing confidence intervals for a sequence of unrelated parameters \\theta_1, \\theta_2, \\dots Then 95 percent of your intervals will trap the true parameter value. There is no need to introduce the idea of repeating the same experiment over and over.\n\nThis interpretation clarifies that a confidence interval is not a probability statement about the parameter \\theta. In Definition @ref(def:confidence-interval-gen), note that \\theta is fixed (\\theta is not a rv) and the interval C_m is random. After data has been collected and a point estimator has been calculated, the resulting CIs either contain the true parameter value or do not, as illustrated in Figure @ref(fig:fifty-cis).\n\n\n\n\n\nFifty 95\\% CIs for a population mean \\mu. After a sample is taken, the computed interval estimate either contains \\mu or does not (asterisks identify intervals that do not include \\mu). When drawing such a large number of 95\\% CIs, we would anticipate that approximately 5\\% (ca. 2 or 3) would fail to cover the true parameter \\mu.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#hypothesis-testing",
    "href": "02-basics-stat-infer.html#hypothesis-testing",
    "title": "2  Basics of statistical inference",
    "section": "2.3 Hypothesis testing",
    "text": "2.3 Hypothesis testing\nSections @ref(point-estimation) and @ref(confidence-intervals) reviewed how to estimate a parameter by a single number (point estimate) or range of plausible values (confidence interval), respectively. Next, we discuss methods for determining which of two contradictory claims, or hypotheses, about a parameter is correct.\n\n\nCode\nThe **null hypothesis**, denoted by $H_0$, is a claim we initially assume to be true by default. The **alternative hypothesis**, denoted by $H_a$, is an assertion contradictory to $H_0$. \n\n\nTypically, we shall consider a hypothesis test concerning a parameter \\theta \\in \\Theta, i.e., taking values in a parameter space \\Theta. The statistical hypotheses are contradictory in that H_0 and H_a divide \\Theta into two disjoint sets. For example, for a statistical inference regarding the equality of a parameter \\theta with a fixed quantity \\theta_0, the null and alternative hypotheses will usually take one of the following forms in Table @ref(tab:htest-null-alt-forms).\n\n\n\n\nTypical null hypothesis and corresponding alternative hypothesis.\n\n\nNull hypothesis\nAlternative hypothesis\nTest form\n\n\n\n\n$H_0 : \\theta = \\theta_0$\n$H_a : \\theta \\neq \\theta_0$\ntwo-sided test\n\n\n$H_0 : \\theta \\leq \\theta_0$\n$H_a : \\theta \\gt \\theta_0$\none-sided test\n\n\n$H_0 : \\theta \\geq \\theta_0$\n$H_a : \\theta \\lt \\theta_0$\none-sided test\n\n\n\n\n\n\n\n\nThese hypothesis pairs are associated with either a one-sided or two-sided test; what this means will become apparent in the sequel. The value \\theta_0, called the null value, separates the alternative from the null.\n\n\nCode\nA **hypothesis test** asks if the available data provides sufficient evidence to reject $H_0$. If the observations disagree with $H_0$, we reject the null hypothesis. If the sample evidence does not strongly contradict $H_0$, then we continue to believe $H_0$. The two possible conclusions of a hypothesis test are: *reject $H_0$* or *fail to reject $H_0$*.^[We comment that *fail to reject $H_0$* is sometimes phrased as *retain $H_0$* or (perhaps less accurately) *accept $H_0$*. Why not just *accept* the null and move on with our lives? Well, if I search the Highlands for the Scottish wildcat (critically endangered) and fail to find any, does that prove they do not exist?]  \n\n\nA procedure for carrying out a hypothesis test is based on specifying two additional items: a test statistic and a corresponding rejection region. A test statistic T is a function of the sample data (like an estimator). The decision to reject or fail to reject H_0 will involve computing the test statistic. The rejection region R is the collection of values of the test statistic for which H_0 is to be rejected in favour of the alternative, e.g., \\begin{equation*}\nR = \\left\\{ x : T(x) &gt; c \\right\\}\\,,\n\\end{equation*} where c is referred to as a critical value. If a given sample falls in the rejection region, we reject H_0. If X \\in R (e.g., the calculated test statistic exceeds some critical value), we reject H_0. The alternative is that X \\not\\in R and we fail to reject the null in this case.\nTwo types of errors can be made when carrying out a hypothesis test. The basis for choosing a rejection region involves considering these errors.\n\n\nCode\nA **type I** error occurs if $H_0$ is rejected when $H_0$ is actually true. A **type II** error is made if we fail to reject $H_0$ when $H_0$ is actually false.\n\n\nIf a test’s maximal type I error is fixed at an acceptably small value, then the type II error decreases as the sample size increases. In particular, a conclusion is reached in a hypothesis test by selecting a significance level \\alpha for the test linked to the maximal type I error rate. Typically, \\alpha = 0.10, 0.05, 0.01, or 0.001 is selected for the significance level.\n\n\nCode\nA **$P$-value** is the probability, calculated assuming $H_0$ is true, of obtaining a value of the test statistic at least as contradictory to $H_0$ as the value calculated from the sample data. \n\n\nSmaller P-values indicate stronger evidence against H_0 in favor of H_a. If P \\leq \\alpha then we reject H_0 at significance level \\alpha. If P \\geq \\alpha we fail to reject H_0 at significance level \\alpha.\n\nThe P-value is a probability calculated assuming that H_0 is true. However, the P-value is not the probability that:\n\nH_0 is TRUE,\nH_0 is FALSE, or\na wrong conclusion is reached.\n\n\n\n\nCode\nThe hypothesis test procedure that \n\\begin{equation*}\n\\begin{cases} \n\\text{rejects}\\; H_0 & \\text{if}\\; P \\leq \\alpha\\\\\n\\text{fails to reject}\\; H_0 & \\text{otherwise}\n\\end{cases}\n\\end{equation*}\nhas $P(\\text{type I error}) = \\alpha$. \n\n\n\n\nCode\nChurchill claims that he will receive half the votes for the House of Commons seat for the constituency of Dundee.^[Sir Winston Churchill was Member of Parliament for Dundee from 1908--1922 [[https://www.wikiwand.com/en/Winston_Churchill](https://www.wikiwand.com/en/Winston_Churchill)].] If we do not believe Churchill's claim and are doubtful of his popularity, we would seek to test an alternative hypothesis. How should we write down our research hypotheses?\n\n\nIf we let p be the fraction of the population voting for Churchill, then we have the null hypothesis, \\begin{equation*}\nH_0 : p = 0.5 \\,,\n\\end{equation*} and the alternative hypothesis (we believe Churchill is less popular than he claims), \\begin{equation*}\nH_a : p &lt; 0.5 \\,.\n\\end{equation*} Support for the alternative hypothesis is obtained by showing a lack of support for its converse hypothesis (the null hypothesis). \\lozenge\n\n\nCode\nSuppose that $m = 15$ voters are selected from Dundee and $X$, the number favouring Churchill, is recorded. Based on observing $X$, we construct a rejection region $R = \\{x : x \\leq k \\}$. If $k$ is small compared to $m$, then the rejection region would provide strong evidence to reject $H_0$. How should one choose the rejection region?\n\n\nAssume now that m = 15 voters are polled and that we select k = 2 to have a rejection region R = \\{ x \\leq 2 \\}. For this choice of k, the rejection region R provides strong support to reject H_0. Assuming the null hypothesis is true, we expect approximately half of the 15 voters (ca. 7) to vote for Churchill. Observing x = 0, x = 1 or x = 2 (the values that would place us in the rejection region) would provide strong evidence against H_0.\nWe can calculate the probability of a type I error. From the definition of type I error, \\begin{equation*}\n\\begin{aligned}\n\\alpha &= P(\\text{type I error})\\\\\n  &= P(\\text{rejecting } H_0 \\text{ when } H_0 \\text{ is true})\\\\\n  &= P(X \\in R \\text{ when } H_0 \\text{ is true})\\\\\n  &= P(X \\leq 2 \\text{ when } p = 0.5) \\,.\n\\end{aligned}\n\\end{equation*} Since X \\sim \\mathsf{Binom}(15, 0.50),3 we calculate that \\alpha = 0.00369. Thus, for this particular choice of rejection region R, the risk of concluding that Churchill will lose if, in fact, he is the winner is tiny.\nFor this rejection region, how good is the test at protecting us from type II errors, i.e., concluding that Churchill is the winner if, in fact, he will lose? Suppose that Churchill receives 25% of the votes (p=0.25). The probability of type II error \\beta is, \\begin{equation*}\n  \\begin{aligned}\n  \\beta &= P(\\text{type II error})\\\\\n  &= P(\\text{fail to reject } H_0 \\text{ when } H_0 \\text{ false})\\\\\n  &= P(X \\not\\in R \\text{ when } H_0 \\text{ false})\\\\\n  &= P(X &gt; 2 \\text{ when } p = 0.3)\\,.\n\\end{aligned}\n\\end{equation*} For X \\sim \\mathsf{Binom}(15, 0.25), we calculate \\beta = 0.764. If we use R = \\{ x \\leq 2\\}, then our test will lead us to conclude that Churchill is the winner with a probability of 0.764 even if p is as low as 0.25!\nIf we repeat these calculations for R^* = \\{x \\leq 5\\}, we find \\alpha = 0.151 versus \\beta = 0.148, even if p is as low as 0.25, which is a much better balance between type I and type II errors. \\lozenge\n\n\n\n\n\n\n\n\nFigure 2.1: Ballot listing Churchill from the collection of the McManus, Dundee. When you take a break from studying, go and see if you can find it! For more information on visiting the McManus visit https://www.mcmanus.co.uk/.\n\n\n\n\n\n\nTo summarise, the elements of a statistical test are:\n\nNull hypothesis (H_0)\nAlternative hypothesis (H_a)\nTest statistic\nRejection region\nSignificance level (\\alpha)\n\n\n\n\n\n\nWasserman, Larry. 2004. All of Statistics. New York: Springer-Verlag.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#footnotes",
    "href": "02-basics-stat-infer.html#footnotes",
    "title": "2  Basics of statistical inference",
    "section": "",
    "text": "More about the Iris setosa here [https://www.wikiwand.com/en/Iris_setosa].↩︎\nSir Winston Churchill was Member of Parliament for Dundee from 1908–1922 [https://www.wikiwand.com/en/Winston_Churchill].↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#sec-confidence-intervals",
    "href": "02-basics-stat-infer.html#sec-confidence-intervals",
    "title": "2  Basics of statistical inference",
    "section": "2.2 Confidence intervals",
    "text": "2.2 Confidence intervals\nAn alternative to reporting a point estimate for a parameter is to report an interval estimate suggesting an entire range of plausible values for the parameter of interest. A confidence interval is an estimate that makes a probability statement about the interval’s degree of reliability. The first step in computing a confidence interval is to select the confidence level \\alpha. A popular choice is a 95\\% confidence interval which corresponds to level \\alpha = 0.05.\n\nDefinition 2.3 (Confidence interval) A 100(1-\\alpha)\\% confidence interval for a parameter \\theta is a random interval C_m = (L_m , U_m)\\,, where L_m = \\ell(X_1, \\dots, X_m) and U_m = u(X_1, \\dots, X_m) are functions of the data, such that \nP_{\\theta}(L_m &lt; \\theta &lt; U_m ) = 1 - \\alpha\\,,\n for all \\theta \\in \\Theta.\n\nMy favourite interpretation of a confidence interval is due to (Wasserman 2004, p 92):\n\nOn day 1, you collect data and construct a 95 percent confidence interval for a parameter \\theta_1. On day 2, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\theta_2. On day 3, you collect new data and construct a 95 percent confidence interval for an unrelated parameter \\theta_3. You continue this way constructing confidence intervals for a sequence of unrelated parameters \\theta_1, \\theta_2, \\dots Then 95 percent of your intervals will trap the true parameter value. There is no need to introduce the idea of repeating the same experiment over and over.\n\nThis interpretation clarifies that a confidence interval is not a probability statement about the parameter \\theta. In Definition 2.3, note that \\theta is fixed (\\theta is not a rv) and the interval C_m is random. After data has been collected and a point estimator has been calculated, the resulting CIs either contain the true parameter value or do not, as illustrated in Figure 2.3.\n\n\n\n\n\n\n\n\nFigure 2.3: Fifty 95\\% CIs for a population mean \\mu. After a sample is taken, the computed interval estimate either contains \\mu or does not (asterisks identify intervals that do not include \\mu). When drawing such a large number of 95\\% CIs, we would anticipate that approximately 5\\% (ca. 2 or 3) would fail to cover the true parameter \\mu.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "02-basics-stat-infer.html#sec-hypothesis-testing",
    "href": "02-basics-stat-infer.html#sec-hypothesis-testing",
    "title": "2  Basics of statistical inference",
    "section": "2.3 Hypothesis testing",
    "text": "2.3 Hypothesis testing\nSection 2.1 and Section 2.2 reviewed how to estimate a parameter by a single number (point estimate) or range of plausible values (confidence interval), respectively. Next, we discuss methods for determining which of two contradictory claims, or hypotheses, about a parameter is correct.\n\nDefinition 2.4 (Null and alternative) The null hypothesis, denoted by H_0, is a claim we initially assume to be true by default. The alternative hypothesis, denoted by H_a, is an assertion contradictory to H_0.\n\nTypically, we shall consider a hypothesis test concerning a parameter \\theta \\in \\Theta, i.e., taking values in a parameter space \\Theta. The statistical hypotheses are contradictory in that H_0 and H_a divide \\Theta into two disjoint sets. For example, for a statistical inference regarding the equality of a parameter \\theta with a fixed quantity \\theta_0, the null and alternative hypotheses will usually take one of the following forms in Table 2.2.\n\n\n\nTable 2.2: Typical null hypothesis and corresponding alternative hypothesis.\n\n\n\n\n\n\n\n\n\n\nNull hypothesis\nAlternative hypothesis\nTest form\n\n\n\n\nH_0 : \\theta = \\theta_0\nH_a : \\theta \\neq \\theta_0\ntwo-sided test\n\n\nH_0 : \\theta \\leq \\theta_0\nH_a : \\theta &gt; \\theta_0\none-sided test\n\n\nH_0 : \\theta \\geq \\theta_0\nH_a : \\theta &lt; \\theta_0\none-sided test\n\n\n\n\n\n\nThese hypothesis pairs are associated with either a one-sided or two-sided test; what this means will become apparent in the sequel. The value \\theta_0, called the null value, separates the alternative from the null.\n\nDefinition 2.5 (Hypothesis test) A hypothesis test asks if the available data provides sufficient evidence to reject H_0. If the observations disagree with H_0, we reject the null hypothesis. If the sample evidence does not strongly contradict H_0, then we continue to believe H_0. The two possible conclusions of a hypothesis test are: reject H_0 or fail to reject H_0.\n\n\n\n\n\n\n\n“Fail to reject” versus “accept”\n\n\n\nWe comment that fail to reject H_0 is sometimes phrased as retain H_0 or (perhaps less accurately) accept H_0.\nWhy not just accept the null and move on with our lives?\nWell, if I search the Highlands for the Scottish wildcat (endangered) and fail to find any, does that prove they do not exist?\n\n\nA procedure for carrying out a hypothesis test is based on specifying two additional items: a test statistic and a corresponding rejection region. A test statistic T is a function of the sample data (like an estimator). The decision to reject or fail to reject H_0 will involve computing the test statistic. The rejection region R is the collection of values of the test statistic for which H_0 is to be rejected in favour of the alternative, e.g., \nR = \\left\\{ x : T(x) &gt; c \\right\\}\\,,\n where c is referred to as a critical value. If a given sample falls in the rejection region, we reject H_0. If X \\in R (e.g., the calculated test statistic exceeds some critical value), we reject H_0. The alternative is that X \\not\\in R and we fail to reject the null in this case.\nTwo types of errors can be made when carrying out a hypothesis test. The basis for choosing a rejection region involves considering these errors.\n\nDefinition 2.6 (Error types) A type I error occurs if H_0 is rejected when H_0 is actually true. A type II error is made if we fail to reject H_0 when H_0 is actually false.\n\nIf a test’s maximal type I error is fixed at an acceptably small value, then the type II error decreases as the sample size increases. In particular, a conclusion is reached in a hypothesis test by selecting a significance level \\alpha for the test linked to the maximal type I error rate. Typically, \\alpha = 0.10, 0.05, 0.01, or 0.001 is selected for the significance level.\n\nDefinition 2.7 (P-value) A P-value is the probability, calculated assuming H_0 is true, of obtaining a value of the test statistic at least as contradictory to H_0 as the value calculated from the sample data.\n\nSmaller P-values indicate stronger evidence against H_0 in favor of H_a. If P \\leq \\alpha then we reject H_0 at significance level \\alpha. If P \\geq \\alpha we fail to reject H_0 at significance level \\alpha.\n\n\n\n\n\n\nWhat a P-value isn’t…\n\n\n\nThe P-value is a probability calculated assuming that H_0 is true. However, the P-value is not the probability that:\n\nH_0 is TRUE,\nH_0 is FALSE, or\na wrong conclusion is reached.\n\n\n\n\nProposition 2.1 The hypothesis test procedure that \n\\begin{cases}\n\\text{rejects}\\; H_0 & \\text{if}\\; P \\leq \\alpha,\\\\\n\\text{fails to reject}\\; H_0 & \\text{otherwise},\n\\end{cases}\n has P(\\text{type I error}) = \\alpha.\n\n\nExample 2.3 Churchill claims that he will receive half the votes for the House of Commons seat for the constituency of Dundee.2 If we do not believe Churchill’s claim and are doubtful of his popularity, we would seek to test an alternative hypothesis. How should we write down our research hypotheses?\nIf we let p be the fraction of the population voting for Churchill, then we have the null hypothesis, \nH_0 : p = 0.5 \\,,\n and the alternative hypothesis (we believe Churchill is less popular than he claims), \nH_a : p &lt; 0.5 \\,.\n Support for the alternative hypothesis is obtained by showing a lack of support for its converse hypothesis (the null hypothesis).\n\n\nExample 2.4 Suppose that m = 15 voters are selected from Dundee and X, the number favouring Churchill, is recorded. Based on observing X, we construct a rejection region R = \\{x : x \\leq k \\}. If k is small compared to m, then the rejection region would provide strong evidence to reject H_0. How should one choose the rejection region?\nAssume now that m = 15 voters are polled and that we select k = 2 to have a rejection region R = \\{ x \\leq 2 \\}. For this choice of k, the rejection region R provides strong support to reject H_0. Assuming the null hypothesis is true, we expect approximately half of the 15 voters (ca. 7) to vote for Churchill. Observing x = 0, x = 1 or x = 2 (the values that would place us in the rejection region) would provide strong evidence against H_0.\nWe can calculate the probability of a type I error. From the definition of type I error, \n\\begin{aligned}\n\\alpha &= P(\\text{type I error})\\\\\n  &= P(\\text{rejecting } H_0 \\text{ when } H_0 \\text{ is true})\\\\\n  &= P(X \\in R \\text{ when } H_0 \\text{ is true})\\\\\n  &= P(X \\leq 2 \\text{ when } p = 0.5) \\,.\n\\end{aligned}\n Since X \\sim \\mathsf{Binom}(15, 0.50), we calculate that \\alpha = 0.00369. Thus, for this particular choice of rejection region R, the risk of concluding that Churchill will lose if, in fact, he is the winner is tiny.\nFor this rejection region, how good is the test at protecting us from type II errors, i.e., concluding that Churchill is the winner if, in fact, he will lose? Suppose that Churchill receives 25% of the votes (p=0.25). The probability of type II error \\beta is, \n  \\begin{aligned}\n  \\beta &= P(\\text{type II error})\\\\\n  &= P(\\text{fail to reject } H_0 \\text{ when } H_0 \\text{ false})\\\\\n  &= P(X \\not\\in R \\text{ when } H_0 \\text{ false})\\\\\n  &= P(X &gt; 2 \\text{ when } p = 0.3)\\,.\n\\end{aligned}\n For X \\sim \\mathsf{Binom}(15, 0.25), we calculate \\beta = 0.764. If we use R = \\{ x \\leq 2\\}, then our test will lead us to conclude that Churchill is the winner with a probability of 0.764 even if p is as low as 0.25!\nIf we repeat these calculations for R^* = \\{x \\leq 5\\}, we find \\alpha = 0.151 versus \\beta = 0.148, even if p is as low as 0.25, which is a much better balance between type I and type II errors.\n\n\n\n\n\n\n\nWhat if the sample size is close to the population size?\n\n\n\nIn Example 2.4, X is a binomial random variable because it can be modelled as m independent Bernoulli trails each with probability p of success (i.e., votes for Churchill) as long as the sample size m is much smaller than the population of Dundee. If we had the means to canvas nearly the whole population, what goes wrong conceptually?\n\n\n\n\n\n\n\n\nFigure 2.4: Ballot listing Churchill from the collection of the McManus, Dundee. When you take a break from studying, go and see if you can find it! For more information on visiting the McManus visit https://www.mcmanus.co.uk/.\n\n\n\n\n\n\n\n\n\nElements of a statistical test\n\n\n\nA statistical test is based on a null hypothesis (H_0) and an alternative hypothesis (H_a).\nAn appropriate test statistic T is computed. Then either:\n\nT is compared to a rejection region (based on significance level \\alpha)\n\nOR\n\nP-value (based on T) is compare to the significance level \\alpha.\n\n\n\n\n\n\n\n\n\nWasserman, Larry. 2004. All of Statistics. New York: Springer-Verlag.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of statistical inference</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "References",
    "section": "",
    "text": "Belle, Gerald van. 2008. Statistical Rules of\nThumb. Second. Wiley Series in Probability and\nStatistics. Hoboken, NJ: John Wiley & Sons, Inc.\n\n\nSpiegelhalter, David J. 2020. The Art of\nStatistics: Learning from\nData. London: Pelican Books.\n\n\nWasserman, Larry. 2004. All of Statistics. New\nYork: Springer-Verlag.",
    "crumbs": [
      "Lecture Notes",
      "References"
    ]
  },
  {
    "objectID": "03-infer-single-sample.html",
    "href": "03-infer-single-sample.html",
    "title": "3  Single sample inferences",
    "section": "",
    "text": "3.1 Estimating means\nIf the parameter of interest is the population mean \\theta = \\mu, then what can be said about the distribution of the sample mean estimator \\widehat{\\theta} = \\overline{X} in Equation 2.1? We will consider three cases,\nIn each, the form of the confidence interval and hypothesis test statistic for \\mu can be derived using the approximate normality of the sample mean.\nIn general, the confidence intervals for the mean based on normality theory will have the form: \n\\text{point estimate}\\; \\mu \\pm (\\text{critical value}) \\cdot (\\text{precision of point estimate})\\,,\n\\tag{3.1} where the reference distribution will be the standard normal (for 1. and 2.) and the Student’s \\mathsf{t} distribution (for 3.). The critical value corresponds to the value under the reference distribution that yields the two-sided (symmetric) tail areas summing to 1-\\alpha.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single sample inferences</span>"
    ]
  },
  {
    "objectID": "03-infer-single-sample.html#sec-estimating-means",
    "href": "03-infer-single-sample.html#sec-estimating-means",
    "title": "3  Single sample inferences",
    "section": "",
    "text": "normal population with known \\sigma^2,\nany population with unknown \\sigma^2, when the sample size m is large, and\nnormal population with unknown \\sigma^2, when the sample size m is small.\n\n\n\n\n3.1.1 Mean of a normal population with known variance\nWhen sampling from a normal population with a known mean and variance, the estimator for the sample mean is also normal with mean \\mu and variance \\sigma^2/m where m is the sample size. Standardising, \n\\frac{\\overline{X} - \\mu}{ \\sigma / \\sqrt{m}} \\quad \\sim \\mathsf{N}(0, 1)\n\\tag{3.2} we see that \nP\\left(-z_{\\alpha/2} &lt;  \\frac{\\overline{X} - \\mu}{ \\sigma / \\sqrt{m}} &lt; z_{\\alpha/2}\\right) = 1 - \\alpha\\,.\n Based on knowing the estimator’s sampling distribution, we state the following CI.\n\nDefinition 3.1 (Confidence interval for mean of normal population) A 100(1-\\alpha)\\% confidence interval for the mean \\mu of a normal population when the value of \\sigma^2 is known is given by \n\\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{m}}\\,,\n        \\overline{x} + z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{m}} \\right)\\,,\n\\tag{3.3} or \\overline{x} \\pm z_{\\alpha/2} \\cdot \\sigma / \\sqrt{m}, where m is the sample size.\n\nThe CI for the mean Equation 3.3 can be expressed (cf. Equation 3.1) as \n\\text{point estimate}\\; \\mu \\pm\n(z \\;\\text{critical value}) \\cdot (\\text{standard error of mean})\\,.\n The z critical value is related to the tail areas under the standard normal curve; we need to find the z-score having a cumulative probability equal to 1-\\alpha according to Definition @ref(def:confidence-interval-gen).\n\nExample 3.1 Consider 400 samples from a normal population with a known standard deviation \\sigma = 17000 with mean \\overline{x} = 20992 as depicted in Figure 3.1. How do we construct a 95\\% confidence interval for \\mu?\n\n\n\n\n\n\n\n\nFigure 3.1: 400 samples from a normal population with known variance \\sigma = 17000 together with the corresponding (normal) sampling distribution for the observed mean.\n\n\n\n\n\nFor \\alpha = 0.05, the critical value z_{0.025} = 1.96; this value can be found by looking in a table of critical z values or using the r code qnorm(1-.05/2). From Definition 3.1, \n\\begin{aligned}\n\\left(\\overline{x} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{m}}\\,, \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{m}} \\right)\n&= \\left(20992 - 1.96 \\frac{17000}{\\sqrt{400}}\\,, 20992 + 1.96 \\frac{17000}{\\sqrt{400}} \\right) \\\\\n&= \\left(19326 \\,, 22658\\right)\\,.\n\\end{aligned}\n\nThe data above was generated with a true population parameter \\mu = 21500, and the CI contains the parameter value (incidentally).\n\nAs noted in Equation 3.1 and Equation 3.3, the width of a CI is related to the estimator’s precision. The confidence level (or reliability) is inversely related to this precision. When the population is normal and the variance is known, determining the sample size necessary to achieve a desired confidence level and precision is an appealing strategy. A general formula for the sample size m^* necessary to achieve an interval width w is obtained at confidence level \\alpha by equating w = 2z_{\\alpha/2} \\cdot \\sigma /\\sqrt{m^*} and then solving for m^*.\n\nProposition 3.1 The sample size m required to achieve a CI for \\mu with width w at level \\alpha is given by, \nm^* = \\left( 2 z_{\\alpha/2} \\cdot \\frac{\\sigma}{w} \\right)^2 \\,.\n\n\nFrom Proposition 3.1, we see that the smaller the desired w, the larger m^* must be (and subsequently, the more effort that must be allocated to data collection).\n\nExample 3.2 In Example 3.1 we identified a 95\\% confidence interval for a normal population with known variance. The range (width) of that interval was 22658 - 19326 = 3332. How much would m need to increase to halve the interval width?\nUsing Proposition 3.1, \nm = \\left( 2 \\cdot 1.96 \\cdot \\frac{17000}{1666} \\right)^2 = (40)^2 = 1600\\,.\n Thus, we find that for the same level \\alpha = 0.05, we would need to quadruple our original sample size to halve the interval.\n\n\n\n\n\n\n\nYou heard it here first…\n\n\n\nAs Example 3.2 shows, it is expensive to reduce uncertainty!\n\n\nSuppose now that we would like to consider a hypothesis test for the population mean, such as H_0 : \\mu = \\mu_0. Starting from Equation 3.2 and assuming that the null hypothesis is true, we find \nZ = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{m}}\\,.\n The statistic Z measures the distance (measured in units of \\mathop{\\mathrm{sd}}[\\overline{X}]) between \\overline{X} and its expected value under the null hypothesis. We will use the statistic Z to determine if there is substantial evidence against H_0, i.e. if the distance is too far in a direction consistent with H_a.\n\nProposition 3.2 Assume that we sample X_1, \\dots, X_m from a normal population with mean \\mu and known variance \\sigma^2.\nConsider H_0 : \\mu = \\mu_0. The test statistic is \nZ = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{m}}\\,.\n\\tag{3.4}\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\mu &gt; \\mu_0, then P = 1 - \\Phi(z), i.e., upper-tail R = \\{z &gt; z_{\\alpha}\\}.\nIf H_a : \\mu &lt; \\mu_0, then P = \\Phi(z), i.e., lower-tail R = \\{z &lt; - z_{\\alpha}\\}.\nIf H_a : \\mu \\neq \\mu_0, then P = 2(1-\\Phi(|z|)), i.e., two-tailed R = \\{|z| &gt; z_{\\alpha/2}\\}.\n\nWe recall that \\Phi(z) is the area in the lower tail of the standard normal density, i.e., to the left of the calculated value of z. Thus 1 - \\Phi(z) is the area in the upper-tail, and 2(1 - \\Phi(|z|)) is twice the area captured in the upper-tail by |z|, i.e. the sum of the area in the tails corresponding to \\pm z. If P &lt; \\alpha, then we reject H_0 at level \\alpha as the data provides sufficient evidence at the \\alpha level against the null hypothesis.\n\nExample 3.3 Let’s return to the data in Example 3.1, where we sample from a normal population with a known standard deviation \\sigma = 17000. Suppose that someone claims the true mean is \\mu_0 = 20000. Does our sample mean \\overline{x} = 20992 based on m = 400 samples provide evidence to contradict this claim at the \\alpha = 0.05 level?\nThe first thing to record is our parameter of interest: \\mu, the true population mean. The null hypothesis, which we assume to be true, is a statement about the value of \\mu, \nH_0 : \\mu = 20000\\,,\n and the alternative hypothesis is \nH_a : \\mu \\neq 20000\\,,\n since we are concerned with a deviation in either direction from \\mu_0 = 20000.\nSince the population is normal with known variance, we compute the test statistic: \nz = \\frac{\\overline{x} - \\mu_0}{\\sigma / \\sqrt{m}} = \\frac{20992 - 20000}{17000 / \\sqrt{400}} = 1.167\\,.\n That is, the observed sample mean \\overline{x} is slightly more than 1 standard deviation than what we expect under H_0. Consulting Proposition 3.2, we see that a two-tailed test is indicated for this particular H_a (i.e., containing “\\neq”). The P-value is the area, \nP = 2(1 - \\Phi(1.167)) = 2 (0.1216052) = 0.2432.\n Thus, since P = 0.2432 &gt; 0.05 = \\alpha, we fail to reject H_0 at the level 0.05. The data does not support the claim that the true population mean differs from the value 20000 at the 0.05 level.\n\n\n\n\n\n\n\nRecall\n\n\n\nNote \\Phi(z) = P(Z \\leq z) is found by calling pnorm(z) in r or by looking up the value in a Z table.\n\n\n\n\n3.1.2 Mean of a population with unknown variance (large-sample)\nConsider samples X_1, \\dots, X_m from a population with mean \\mu and variance \\sigma^2. Provided that m is large enough, the Central Limit Theorem implies that the estimator for the sample mean \\overline{X} in Equation 2.1 has approximately a normal distribution. Then \nP \\left( - z_{\\alpha/2} &lt; \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{m}} &lt; z_{\\alpha/2} \\right) \\approx 1 - \\alpha\\,,\n since the transformed variable has approximately a standard normal distribution. Thus, computing a point estimate based on a large m of samples yields a CI for the population parameter \\mu at an approximate confidence level \\alpha. However, it is often the case that the variance is unknown. When m is large, replacing the population variance \\sigma^2 by the sample variance S^2 in Equation 2.2 will not typically introduce too much additional variability.\n\nProposition 3.3 For a large sample size m, an approximate 100(1-\\alpha)\\% confidence interval for the mean \\mu of any population when the variance is unknown is given by \n\\left(\\overline{x} - z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{m}} \\,,\n        \\overline{x} + z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{m}} \\right)\\,,  \n\\tag{3.5} or \\overline{x} \\pm z_{\\alpha/2} \\cdot s / \\sqrt{m}.\n\nThe CI for the mean Equation 3.5 applies regardless of the shape of the population distribution so long as the number of samples is large. A rule of thumb is that m &gt; 40 is sufficient. In words, the CI Equation 3.5 can be expressed (cf. Equation 3.1) as \n\\text{point estimate}\\; \\mu \\pm\n(z \\;\\text{critical value}) \\cdot (\\text{estimated standard error of mean})\\,.\n Typically, a large-sample CI for a general parameter \\theta holds that is similar to Equation 3.5 for any estimator \\widehat{\\theta} that satisfies: (1) approximately normal in distribution, (2) approximately unbiased, and (3) an expression for the standard error is available.\nTo conduct a large-sample hypothesis test regarding the population mean \\mu, we consider the test statistic \nZ = \\frac{\\overline{X} - \\mu_0}{S / \\sqrt{m}}\n under the null hypothesis, i.e., we replace the population standard deviation \\sigma with the sample standard deviation S. When the number of samples m is large (say m &gt; 40), then Z will be approximately normal. Substituting this test statistic Z for Equation 3.4, we follow Proposition 3.2 to determine how to calculate the P-value.\n\n\n\n\n\n\nRule of thumb\n\n\n\nFor estimating means, we consider a sample size of m &gt; 40 to be large.\nHowever, ‘large’ depends on the context: for example, the level of support for the evidence that you are seeking. For m &gt; 20, the interval estimate \\text{point estimate } \\pm 2\\mathop{\\mathrm{sd}} has 95\\% coverage and is surprisingly robust, i.e. applies to a wide variety of population distributions including the normal. However, this rule of thumb won’t apply if you want to consider some different level, say 80\\% (Belle 2008, sec. 1).\n\n\n\nExample 3.4 Let’s consider the Iris Data from Note 2.1 and use the infer package to make inferences. In particular, consider whether there is evidence at the 0.05 level to support the statement that the true mean petal length of Iris flowers exceeds 3.5 cm.\nRecall that the Iris Data contains m= 150 measurements of petal length across three species of Iris flowers and that the true variance is unknown. We are interested in testing the null hypothesis, H_0 : \\mu \\leq 3.5\\,, against the alternative, H_a : \\mu &gt; 3.5\\,, i.e., a one-sided test.\nWe first compute the observed statistic (sample mean) \\widehat{\\mu}. We use the infer package to construct a null distribution computationally for the response variable (petal length). We specify that the hypothesis test is for the parameter based on a point estimate and that we are testing for equality with the value \\mu_0 = 3.5. The null distribution is generated by computing 1000 bootstrap replications of the sample mean, i.e., the sample mean is generated 1000 times by drawing 150 values at random with replacement from the original corpus of m=150 samples. (Note that we obtain the null distribution computationally, so we do not need to standardise to Z.)\n\n\nCode\nmu_hat &lt;- mean(iris$Petal.Length) \n\nnull_dist &lt;- iris |&gt;\n specify(response = Petal.Length) |&gt;\n hypothesise(null = \"point\", mu = 3.5) |&gt;\n generate(reps = 1000, type = \"bootstrap\") |&gt;\n calculate(stat = \"mean\")\n\nnull_dist |&gt;\n visualise() +\n shade_p_value(obs_stat = mu_hat, direction = \"greater\")\n\n\n\n\n\n\n\n\n\nThe bootstrapped null distribution is plotted using the visualise command, and the regions of the null distribution that are as extreme (or more extreme) than the observed statistic \\widehat{\\mu} can be highlighted using the shade_p_value command.\n\n\nCode\np_val &lt;- null_dist |&gt;\n get_p_value(obs_stat = mu_hat, direction = \"greater\")\np_val\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.038\n\n\nThe test yields a P-value of P = 0.038. This values is quite small; if \\mu \\leq 3.5, then the probability of obtaining the sample mean value \\widehat{\\mu} = 3.758 is only 0.038! Thus, the data provide sufficient evidence at the 0.05 level against the hypothesis that the true mean petal length is at most 3.5 cm.\n\n\n\n3.1.3 Mean of a normal population with unknown variance\nIn Section 3.1.1, we considered samples X_1, \\dots, X_m from a normal population with a known \\mu and \\sigma^2. In contrast, here, we consider samples from a normal population and assume the population parameters \\mu and \\sigma^2 are unknown. If the number of samples is large, the discussion in Section 3.1.2 indicates that the rv Z = (\\overline{X} - \\mu) \\sqrt{m} / S  has approximately a standard normal distribution. However, if m is not sufficiently large then the transformed variable will be more spread out than a standard normal distribution.\n\nTheorem 3.1 For the sample mean \\overline{X} based on m samples from a normal distribution with mean \\mu, the rv \nT = \\frac{\\overline{X} - \\mu}{S/\\sqrt{m}}  \\quad \\sim \\mathsf{t}(m-1)\\,,\n\\tag{3.6} that is, T has Student’s \\mathsf{t} distribution with \\nu = m-1 df.\n\nThis leads us to consider a CI for the population parameter \\mu based on critical values of the \\mathsf{t} distribution.\n\nProposition 3.4 A 100(1-\\alpha)\\% confidence interval for the mean \\mu of a normal population, when \\sigma^2 is unknown, is given by \n\\left(\\overline{x} - t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}}\\,,\n        \\overline{x} + t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}} \\right)\\,,\n\\tag{3.7} or \\overline{x} \\pm t_{\\alpha/2, m-1} \\cdot s/ \\sqrt{m}. Here \\overline{x} and s are the sample mean and sample standard deviation, respectively.\n\n\nExample 3.5 Let us return to the height of 31 felled black cherry trees from the Cherry Tree Data in Note 2.2. Give a 99\\% CI for the population mean \\mu.\nFor m = 31, the critical value of the reference distribution is t_{0.005, 30} \\approx 2.7499\\,, which can looked up in a table of critical values for \\mathsf{t}(\\nu = 30) or found using the r command qt(1-0.01/2, df = 31-1). The sample mean \\overline{x} = 76 (computed in Example 2.1) is combined with the sample standard deviation, \n\\begin{aligned}\ns &= \\sqrt{\\frac{1}{m-1} \\sum_{i=1}^m (x_i - \\overline{x})^2}\\\\\n   &= \\sqrt{\\frac{1}{30} \\left((63-76)^2 + \\cdots + (87 - 76)^2\\right)}\\\\\n   &= 6.372\\,,\n\\end{aligned}\n to form the interval estimate \n\\begin{aligned}\n& \\left(\\overline{x} - t_{\\alpha/2, m-1}  \\cdot \\frac{s}{\\sqrt{m}}\\,,\n        \\overline{x} + t_{\\alpha/2, m-1} \\cdot \\frac{s}{\\sqrt{m}} \\right) \\\\\n        &\\qquad = \\left(76 - 2.750 \\cdot \\frac{6.372}{\\sqrt{31}} \\,, 76 + 2.750 \\cdot \\frac{6.372}{\\sqrt{31}} \\right)\\\\\n        &\\qquad = \\left(72.85\\,, 79.15\\right)\\,.\n\\end{aligned}\n For comparison, the critical value t_{.01/2, \\nu} for \\nu = 14, \\dots, 40 can be recalled with the following command.\n\n\nCode\nqt(1-0.01/2, df = seq(14,40))\n\n\n [1] 2.976843 2.946713 2.920782 2.898231 2.878440 2.860935 2.845340 2.831360 2.818756\n[10] 2.807336 2.796940 2.787436 2.778715 2.770683 2.763262 2.756386 2.749996 2.744042\n[19] 2.738481 2.733277 2.728394 2.723806 2.719485 2.715409 2.711558 2.707913 2.704459\n\n\nNote that these critical values can deviate significantly from the corresponding z_{0.01/2} = 2.575829. In particular, if we had erroneously used the large sample estimate Equation 3.5, then we would have obtained a 99\\% CI (73.05\\,, 78.95) which might give us a false sense of security as it is narrower.\n\nIn contrast to Proposition 3.1, it is difficult to select the sample size m to control the width of the \\mathsf{t}-based CI as the width involves the unknown (before the sample is acquired) s and because m also enters through t_{\\alpha/2, m-1}. A one-sample \\mathsf{t} test based on Equation 3.6 can be used to test a hypothesis about the population mean when the population is normal and \\sigma^2 is unknown.\n\nProposition 3.5 Assume that we sample X_1, \\dots, X_m from a normal population with mean \\mu and unknown variance \\sigma^2.\nConsider H_0 : \\mu = \\mu_0. The test statistic is \nT = \\frac{\\overline{X} - \\mu_0}{S / \\sqrt{m}} \\,.\n\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\mu &gt; \\mu_0, then P-value is the area under \\mathsf{t}(m-1) to the right of t.\nIf H_a : \\mu &lt; \\mu_0, then P-value is the area under \\mathsf{t}(m-1) to the left of t.\nIf H_a : \\mu \\neq \\mu_0, then P-value is twice the area under \\mathsf{t}(m-1) to the right of |t|.\n\n\nExample 3.6 Let’s consider the Cherry Tree Data in Note 2.2. The average timber volume is given in Table 3.1. The distribution for this data is approximately normal. We might ask if the data provide compelling evidence, say at level 0.05, for concluding that the true average timber volume exceeds 21.3 cubic feet.1\n\n\n\n\nTable 3.1: Observations of m = 31 felled black cherry trees.\n\n\n\n\n\n\n\nVolume [cu ft]\n\n\n\n\n10.2, 10.3, 10.3, 15.6, 16.4, 18.2, 18.8, 19.1, 19.7, 19.9, 21.0, 21.3, 21.4, 22.2, 22.6, 24.2, 24.9, 25.7, 27.4, 31.7, 33.8, 34.5, 36.3, 38.3, 42.6, 51.0, 51.5, 55.4, 55.7, 58.3, 77.0\n\n\n\n\n\n\n\n\n\n\n\nLet’s carry out a significance test for the true average volume of timber \\mu at level \\alpha = 0.05. We assume the null hypothesis \nH_0 : \\mu = 21.3\\,.\n An appropriate alternative hypothesis is \nH_a : \\mu &gt; 21.3\\,,\n that is, we will adopt the stance that the true average exceeds \\mu_0 = 21.3 only if the null is rejected.\nFrom our m = 31 samples, we find that \\overline{x} = 30.17 and that s = 16.44. The computed value of the one-sample \\mathsf{t}-statistic is given by \n\\begin{aligned}\nt &= \\frac{\\overline{x} - \\mu_0}{s / \\sqrt{m}}\\\\\n&= \\frac{30.17 - 21.3}{16.44 / \\sqrt{31}}\\\\\n& = 3\\,.\n\\end{aligned}\n The test is based on \\nu = 31-1 df, and P = 0.002663. This is the upper-tail area, i.e., the area to the right of t in Figure 3.2. Since P \\ll \\alpha, we reject the null hypothesis that the population mean is 21.3. The data provide sufficient evidence that the population mean differs from 21.3.\n\n\n\n\n\n\n\n\nFigure 3.2: For this test, the reference distribution is \\mathsf{t}(\\nu = 30) (not a Normal distribution) and the P-value is the upper-tail area, i.e., to the right of the computed statistic t.\n\n\n\n\n\n\n\n\n\n\n\n\nShapiro-Wilk normality test\n\n\n\nWe can assess the normality of the sample by examining the normal quantile-quantile plot as in Example 2.1. For the data in Example 3.6 recall that this is done using the following r code.\n\n\nCode\ntrees |&gt; ggplot(aes(sample = Volume)) + stat_qq() + stat_qq_line()\n\n\n\n\n\n\n\n\nFigure 3.3: Normal quantile-quantile plot for the Volume variable (feature) in the Cherry Tree Data.\n\n\n\n\n\nThe data deviates quite a bit in the centre and in the tails of the distribution, indicating that there might be a moderate departure from normality.\nIt is also possible to test the null hypothesis that the data is consistent with a normal distribution versus the alternative that the data is not normal. This is called a Shapiro-Wilk normality test.\n\n\nCode\nshapiro.test(trees$Height)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  trees$Height\nW = 0.96545, p-value = 0.4034\n\n\nAt level 0.05, the Shapiro-Wilk test yields a P-value P = 0.4034 &gt; 0.05, and therefore we fail to reject the null hypothesis. We cannot exclude that the data is drawn from a normal population. This “prove” the data is drawn from a normal distribution, but it does tell us that for this particular example, an inference based on a normal distribution instead of a \\mathsf{t} distribution will probably be reasonable. It is always good to view the QQ plot as well — sometimes if the number of samples is very large then the Shapiro-Wilk test will reject the null for trivial deviations from normality.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single sample inferences</span>"
    ]
  },
  {
    "objectID": "03-infer-single-sample.html#sec-estimating-proportions",
    "href": "03-infer-single-sample.html#sec-estimating-proportions",
    "title": "3  Single sample inferences",
    "section": "3.2 Estimating proportions",
    "text": "3.2 Estimating proportions\nConsider a population of size M in which each member either satisfies a given property or does not (i.e. a binary classification). The proportion p \\in (0,1) of the population satisfying the given property is a parameter characterising the population we might be interested in estimating. A sample of classified observations, X_1, \\dots, X_m \\sim \\mathsf{Bernoulli}(p)\\,, from the population contains a proportion, \n\\widehat{p} = \\frac{1}{m} \\sum_{i=1}^m X_i\\,,\n\\tag{3.8} satisfying the given property. The estimator \\widehat{p} varies with the sample, and for large m, its sampling distribution has the following properties: \n\\mu_{\\widehat{p}} = \\mathop{\\mathrm{\\mathbf{E}}}[X_i] = p\n\\tag{3.9} and \n\\sigma_{\\widehat{p}}^2 = \\frac{\\mathop{\\mathrm{Var}}[X_i]}{m} = \\frac{p(1-p)}{m}\\,,\n\\tag{3.10} provided that m is small relative to M. Moreover, by invoking the Central Limit Theorem, we have the distribution of \\widehat{p} is approximately normal for sufficiently large m as Equation 3.8 is a sample mean. Indeed, this normal approximation works well for moderately large m as long as p is not too close to zero or one; a rule of thumb is that mp &gt; 5 and m(1-p) &gt; 5.\n\n\n\n\n\n\nRule of thumb\n\n\n\nFor estimating proportions, a rule of thumb is m \\leq 0.05 M.\nNote that if m is large relative to M (m &gt; 0.05 M) then the variance Equation 3.10 must be adjusted by a factor (related to the hypergeometric distribution): \n\\sigma_{\\widehat{p}}^2 = \\frac{p(1-p)}{m} \\frac{M-m}{M-1}\\,,\n where for fixed m the factor converges to 1 as M\\to \\infty.\n\n\n\nProposition 3.6 For large samples n, a 100(1-\\alpha)\\% confidence interval for the parameter p is given by \n\\widehat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{m}}\\,.\n\\tag{3.11}\n\nThis follows from Proposition 3.3 by observing that Equation 3.8 is a sample mean and replacing the standard error \\sigma_{\\widehat{p}} from Equation 3.10 by the estimated standard error, \n\\widehat{\\mathsf{se}}(\\widehat{p}) = \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{m}}\\,;\n recall the s in Equation 3.5) is the sample variance for the population and s / \\sqrt{m} = \\mathsf{se} is the standard error of the point estimator.\n\nProposition 3.7 Let X be the count of members with a given property based on a sample of size m from a population where a proportion p shares the property. Then \\widehat{p} = X / m is an estimator of p. Assume m p_0 \\geq 10 and m (1-p_0) \\geq 10.\nConsider H_0 : p = p_0. The test statistic is \nZ = \\frac{\\widehat{p} - p_0}{\\sqrt{p_0 (1-p_0) / m}} \\,.\n\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : p &gt; p_0, then P-value is the area under \\mathsf{N}(0,1) to the right of z.\nIf H_a : p &lt; p_0, then P-value is the area under \\mathsf{N}(0,1) to the left of z.\nIf H_a : p \\neq p_0, then P-value is twice the area under \\mathsf{N}(0,1) to the right of |z|.\n\n\nExample 3.7 Let us revisit Example 2.3, where we considered Churchill’s claim that he would receive half the votes for the House of Commons seat for the constituency of Dundee. We are sceptical that he is as popular as he says. Suppose 116 out of 263 Dundonians polled claimed they intended to vote for Churchill. Can it be concluded at a significance level of 0.10 that more than half of all eligible Dundonains will vote for Churchill?\nThe parameter of interest is p, the proportion of votes for Churchill. The null hypothesis is H_0 : p = 0.5\\,, and the alternative hypothesis is, H_a : p &lt; 0.5\\,. The test is oneside (i.e. H_a : p &lt; 0.5) since we are interested in testing support for “more than half”. Since 263(0.5) = 131.5 &gt; 10, we satisfy the assumptions stated in Proposition 3.7.\nBased on the sample, \\widehat{p} = 116 / 263 = 0.4411. The test statistic value is \n\\begin{aligned}\nz &= \\frac{\\widehat{p} - p_0}{\\sqrt{p_0 (1-p_0) / m}} \\\\\n&= \\frac{0.4411 - 0.5}{\\sqrt{0.5 (1-0.5) / 263}}\\\\\n&= -1.91  \\,.\n\\end{aligned}\n The P-value for this lower-tailed z test is P = \\Phi(-1.91) = 0.028. Since P &lt; 0.10 = \\alpha, we reject the null hypothesis at the 0.1 level. The evidence for concluding that the true proportion is different from p_0 = 0.5 at the 0.10 level is compelling.2",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single sample inferences</span>"
    ]
  },
  {
    "objectID": "03-infer-single-sample.html#sec-estimating-variances",
    "href": "03-infer-single-sample.html#sec-estimating-variances",
    "title": "3  Single sample inferences",
    "section": "3.3 Estimating variances",
    "text": "3.3 Estimating variances\nNext, we consider estimates of the population variance (and standard deviation) when the population is assumed to have a normal distribution. In this case, the sample variance S^2 in Equation 2.2 provides the basis for inferences. Consider iid samples X_1, \\dots, X_m \\sim \\mathsf{N}(\\mu, \\sigma^2). We provide the following theorem without proof.\n\nTheorem 3.2 For the sample variance S^2 based on m samples from a normal distribution with variance \\sigma^2, the rv \nV = \\frac{(m-1)S^2}{\\sigma^2} = \\frac{\\sum_i(X_i - \\overline{X})^2}{\\sigma^2} \\qquad \\sim \\chi^2_{m-1}\\,,\n that is, V has a \\chi^2 distribution with \\nu = m-1 df.\n\nBased on Theorem 3.2, \nP\\left(\\chi^2_{1-\\alpha/2, m-1} &lt; \\frac{(m-1)S^2}{\\sigma^2} &lt; \\chi^2_{\\alpha/2, m-1} \\right) = 1 - \\alpha \\,,\n i.e., the area captured between the right and left tail critical \\chi^2 values is 1-\\alpha. The expression above can be further manipulated to obtain an interval for the unknown parameter \\sigma^2: \nP\\left(\\frac{(m-1) s^2}{\\chi^2_{\\alpha/2, m-1}} &lt; \\sigma^2 &lt; \\frac{(m-1) s^2}{\\chi^2_{1-\\alpha/2, m-1}} \\right) = 1 - \\alpha \\,,\n where we substitute the computed value of the point estimate s^2 for the estimator into the limits to give a CI for \\sigma^2. If we take square roots in the inequality above, we obtain a CI for the population standard deviation \\sigma.\n\nProposition 3.8 A 100(1-\\alpha)\\% confidence interval for the variance of a normal population is \n\\left( (m-1)s^2 / \\chi^2_{\\alpha/2, m-1} \\,,  (m-1)s^2 / \\chi^2_{1-\\alpha/2, m-1} \\right) \\,.\n\\tag{3.12} A 100(1-\\alpha)\\% confidence interval for the standard deviation \\sigma of a normal population is given by taking the square roots of the lower and upper limits in Equation 3.12.\n\n\nExample 3.8 For the Cherry Tree Data in Table 3.1 concerning the timber volume of 31 felled black cherry trees, give a 95% CI for the variance.\nWe are interested in estimating the true variance \\sigma^2 of the timber volume based on m=31 samples. Recall that the mean of our data is \\overline{x} = 30.17 cu ft and that the sample variance is s^2 = 270.2 using the estimator Equation 2.2. The critical values for the \\chi^2_{.975, 30} = 16.7908 and \\chi^2{.025, 30} = 46.9792 can be found by checking a table of critical values of the \\chi^2(\\nu=30) distribution or by using the r code qchisq(1-0.05/2, df=30, lower.tail = FALSE) and qchisq(0.05/2, df=df, lower.tail = FALSE), respectively, see Figure 3.4 below.\n\n\n\n\n\n\n\n\nFigure 3.4: As the \\chi^2 distribution is not symmetric, the upper and lower critical values will not be the same (the shaded areas are equal).\n\n\n\n\n\nPulling everything together, a 95\\% CI for the population variance is given by \n\\begin{aligned}\n& \\left( (m-1)s^2 / \\chi^2_{\\alpha/2, m-1} \\,,  (m-1)s^2 / \\chi^2_{1-\\alpha/2, m-1} \\right) \\\\\n&\\qquad = \\left( (30) 270.2 / 46.9792 \\,, (30) 270.2 / 16.7908  \\right) \\\\\n&\\qquad = \\left(172.5\\,, 482.8\\right)\\,.\n\\end{aligned}\n Note the position of the critical values—don’t swap them around.\n\n\nExample 3.9 Let’s Revisit Example 3.8) and use the infer package to construct a 95\\% confidence interval for the true standard deviation of the timber volume of black cherry trees based on the available measurements in the Cherry Tree Data, Table 3.1).\n\n\nCode\ns &lt;- sd(trees$Volume)\n\nnull_dist &lt;- trees |&gt;\n specify(response = Volume) |&gt;\n generate(reps = 1000, type = \"bootstrap\") |&gt;\n calculate(stat = \"sd\")\n\nci &lt;- null_dist |&gt;\n get_confidence_interval(point_estimate = s, level = 0.95, type = \"se\")\n\nnull_dist |&gt; \n visualise() + shade_ci(ci)\n\n\n\n\n\n\n\n\n\nWe plot the 95\\% confidence interval for the standard deviation based on the computational null distribution obtained using 1000 bootstrap replications; note the interval estimate is in good agreement with the values obtained in Example 3.8.\n\n\nCode\nci^2\n\n\n  lower_ci upper_ci\n1 141.2539  440.608\n\n\nDue to the computational nature, the bootstrapped interval estimate is not precisely the same as the theoretical interval estimate and rerunning the code will yield a slightly different interval.\n\n\n\n\n\nBelle, Gerald van. 2008. Statistical Rules of Thumb. Second. Wiley Series in Probability and Statistics. Hoboken, NJ: John Wiley & Sons, Inc.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single sample inferences</span>"
    ]
  },
  {
    "objectID": "03-infer-single-sample.html#footnotes",
    "href": "03-infer-single-sample.html#footnotes",
    "title": "3  Single sample inferences",
    "section": "",
    "text": "How much wood is that? About a sixth of a cord. A full cord of chopped firewood in the US is 124 cu ft; about enough to keep you warm through a New England winter (according to my mother-in-law).↩︎\nChurchill took ca. 44\\% of the vote in the 1908 by-election to become MP for Dundee [https://www.wikiwand.com/en/1908_Dundee_by-election].↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single sample inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html",
    "href": "04-infer-two-samples.html",
    "title": "4  Two samples inferences",
    "section": "",
    "text": "4.1 Comparing means\nLet us assume that we have two normal populations with iid samples \nX_1, \\dots, X_m \\sim \\mathsf{N}(\\mu_X, \\sigma_X^2)\n and \nY_1, \\dots, Y_n \\sim \\mathsf{N}(\\mu_Y, \\sigma_Y^2)\n and, moreover, that the X and Y samples are independent of one another. When comparing the means of two populations, the quantity of interest is the difference: \\mu_X - \\mu_Y.\nProposition 4.1 follows directly from the definition of the sample mean in Equation 2.1 and properties of expectation and variance. If our parameter of interest is \n\\theta = \\mu_1 - \\mu_2\\,,\n then its estimator, \n\\widehat{\\theta} = \\overline{X} - \\overline{Y}\\,,\n is normally distributed with mean and variance given by Proposition 4.1. If the sample sizes m and n are large, then the estimator is approximately normally distributed by the Central Limit Theorem regardless of the population. We now discuss CIs and hypothesis tests for comparing population means \\theta = \\mu_X - \\mu_Y. We consider three cases when comparing means:\nnoting that the development primarily reflects that of Section 3.1.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two samples inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html#sec-compare-means",
    "href": "04-infer-two-samples.html#sec-compare-means",
    "title": "4  Two samples inferences",
    "section": "",
    "text": "Proposition 4.1 If we consider the sample means \\overline{X} and \\overline{Y}, then the mean of the variable \\overline{X} - \\overline{Y} is, \n\\mu_{\\overline{X} - \\overline{Y}}\n= \\mathop{\\mathrm{\\mathbf{E}}}\\left[ \\overline{X} - \\overline{Y} \\right] = \\mu_X - \\mu_Y\\,,\n and the variance is, \n\\sigma_{\\overline{X} - \\overline{Y}}^2\n= \\mathop{\\mathrm{Var}}\\left[ \\overline{X} - \\overline{Y} \\right]\n= \\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n} \\,.\n\n\n\n\nnormal populations when the variances \\sigma_X^2 and \\sigma_Y^2 are known,\nany populations with unknown variances \\sigma_X^2 and \\sigma_Y^2, when the sample sizes m and n are large,\nnormal populations when the variances \\sigma_X^2 and \\sigma_Y^2 are unknown, when the sample sizes m and n are small,\n\n\n\n4.1.1 Comparing means of normal populations when variances are known\nWhen \\sigma_X^2 and \\sigma_Y^2 are known, standardizing \\overline{X} - \\overline{Y} yields the standard normal variable: \nZ = \\frac{\\overline{X} - \\overline{Y} - (\\mu_X - \\mu_Y)}{\\sqrt{\\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n}}}\\quad \\sim \\mathsf{N}(0,1)\\,.\n\\tag{4.1}\nInferences proceed by treating the parameter of interest \\theta as in the single sample case using the test statistic Equation 4.1.\n\nProposition 4.2 A 100(1-\\alpha)\\% CI for the parameter \\theta = \\mu_X - \\mu_Y based on samples of size m from a normal population \\mathsf{N}(\\mu_X, \\sigma_X^2) and of size n from \\mathsf{N}(\\mu_Y, \\sigma_Y^2) with known variances, is given by \n(\\overline{x} - \\overline{y}) \\pm z_{\\alpha/2}\n\\cdot \\sqrt{\\frac{\\sigma_X^2}{m} + \\frac{\\sigma_Y^2}{n}} \\,.\n\n\n\nProposition 4.3 Assume that we sample iid X_1, \\dots, X_m \\sim \\mathsf{N}(\\mu_X, \\sigma_X^2) and iid Y_1, \\dots, Y_n \\sim \\mathsf{N}(\\mu_Y, \\sigma_Y^2) and that the X and Y samples are independent.\nConsider H_0 : \\mu_X - \\mu_Y = \\theta_0. The test statistic is \nZ = \\frac{\\overline{X} - \\overline{Y} - \\theta_0}{\\sqrt{\\frac{\\sigma_{X}^2}{m} + \\frac{\\sigma_{Y}^2}{n}}}\\,.\n\\tag{4.2}\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\mu_X - \\mu_Y &gt; \\theta_0, then P = 1 - \\Phi(z), i.e., upper-tail R = \\{z &gt; z_{\\alpha}\\}.\nIf H_a : \\mu_X - \\mu_Y &lt; \\theta_0, then P = \\Phi(z), i.e., lower-tail R = \\{z &lt; - z_{\\alpha}\\}.\nIf H_a : \\mu_X - \\mu_Y \\neq \\theta_0, then P = 2(1-\\Phi(|z|)), i.e., two-tailed R = \\{|z| &gt; z_{\\alpha/2}\\}.\n\n\n\n4.1.2 Comparing means when the sample sizes are large\nWhen the samples are large, the assumptions about the normality of the populations and knowledge of the variances \\sigma_X^2 and \\sigma_Y^2 can be relaxed. For sufficiently large m and n, the difference of the sample means, \\overline{X} - \\overline{Y}, has approximately a normal distribution for any underlying population distributions by the Central Limit Theorem. Moreover, if m and n are large enough, replacing the population variances with the sample variances S_X^2 and S_Y^2 will not increase the variability of the estimator or the test statistic too much.\n\nProposition 4.4 For m and n sufficiently large, an approximate 100(1-\\alpha)\\% CI for \\mu_X - \\mu_Y for two samples from populations with any underlying distribution is given by \n(\\overline{x} - \\overline{y}) \\pm z_{\\alpha/2}\n\\cdot \\sqrt{\\frac{s_{X}^2}{m} + \\frac{s_{Y}^2}{n}}\n\n\n\nProposition 4.5 Under the same assumptions and procedures as in Proposition 4.3, a large-sample, i.e., m &gt; 40 and n &gt; 40, test statistic, \nZ = \\frac{\\overline{X} - \\overline{Y} - \\theta_0}{\\sqrt{\\frac{S_{X}^2}{m} + \\frac{S_{Y}^2}{n}}}\\,,\n can be used in place of Equation 4.2 for hypothesis testing.\n\n\n\n4.1.3 Comparing means of normal populations when variances are unknown and the sample size is small\nIf \\sigma_X and \\sigma_Y are unknown and either sample is small (e.g., m &lt; 30 or n &lt;30), but both populations are normally distributed, then we can use Student’s \\mathsf{t} distribution to make inferences. We provide the following theorem without proof.\n\nTheorem 4.1 When both population distributions are normal, the standardised variable \nT = \\frac{\\overline{X}-\\overline{Y} - (\\mu_X - \\mu_Y)}{\\sqrt{\\frac{S_X^2}{m} + \\frac{S_Y^2}{n}}}\n\\quad \\sim \\mathsf{t}(\\nu)\\,,\n where the df \\nu is estimated from the data. Namely, \\nu is given by (round \\nu down to the nearest integer): \n\\nu = \\frac{ \\left( \\frac{s_X^2}{m} + \\frac{s_Y^2}{n} \\right)^2}{\\frac{(s_X^2 / m)^2}{m-1} + \\frac{(s_Y^2/n)^2}{n-1}}\n= \\frac{ \\left( s_{\\overline{X}}^2 + s_{\\overline{Y}}^2 \\right)^2}{\\frac{s_{\\overline{X}}^4}{m-1} + \\frac{s_{\\overline{Y}}^4}{n-1}}\\,,\n\\tag{4.3} where s_X^2 and s_Y^2 are point estimators of the sample variances; alternatively, we see that the formula Equation 4.3 can also be written in terms of the standard error of the sample means: \ns_{\\overline{X}} = \\frac{s_X}{\\sqrt{m}}\n\\quad \\text{and} \\quad \\qquad\ns_{\\overline{Y}} = \\frac{s_Y}{\\sqrt{n}} \\,.\n\n\nThe formula Equation 4.3 for the data-driven choice of \\nu calls for the computation of the standard error of the sample means.\n\nProposition 4.6 A 100(1-\\alpha)\\% CI for \\mu_X - \\mu_Y for two samples of size m and n from normal populations where the variances are unknown is given by \n(\\overline{x} - \\overline{y}) \\pm t_{\\alpha/2, \\nu} \\sqrt{ \\frac{s_X^2}{m} + \\frac{s_Y^2}{n}}\\,,\n where we recall that t_{\\alpha/2, \\nu} is the \\alpha/2 critical value of \\mathsf{t}(\\nu) with \\nu given by Equation 4.3.\n\n\nProposition 4.7 Assume that we sample iid X_1, \\dots, X_m and iid Y_1, \\dots, Y_n from normal populations with unknown variances and means \\mu_X and \\mu_Y, respectively, and that the X and Y samples are independent.\nConsider H_0 : \\mu_X - \\mu_Y = \\theta_0. The test statistic is \nT = \\frac{\\overline{X} - \\overline{Y} - \\theta_0}{\\sqrt{\\frac{S_{X}^2}{m} + \\frac{S_{Y}^2}{n}}}\\,.\n\\tag{4.4}\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\mu_X - \\mu_Y &gt; \\theta_0, then P-value is the area under \\mathsf{t}(\\nu) to the right of t, i.e., upper-tail R = \\{t &gt; t_{\\alpha,\\nu}\\}.\nIf H_a : \\mu_X - \\mu_Y &lt; \\theta_0, then P-value is the area under \\mathsf{t}(\\nu) to the left of t, i.e., lower-tail R = \\{t &lt; - t_{\\alpha,\\nu}\\}.\nIf H_a : \\mu_X - \\mu_Y \\neq \\theta_0, then P-value is twice the area under \\mathsf{t}(\\nu) to the right of |t|, i.e., two-tailed R = \\{|t| &gt; t_{\\alpha/2, \\nu}\\}.\nHere \\nu is given by Equation 4.3.\n\nIf the variances of the normal populations are unknown but are the same, \\sigma_X^2 = \\sigma_Y^2, then deriving CIs and test statistics for comparing the means can be simplified by considering a combined or pooled estimator for the single parameter \\sigma^2. If we have two samples from populations with variance \\sigma^2, each sample provides an estimate for \\sigma^2. That is, S_X^2, based on the m observations of the first sample, is one estimator for \\sigma^2 and another is given by S_Y^2, based on n observations of the second sample. The correct way to combine these two estimators into a single estimator for the sample variance is to consider the pooled estimator of \\sigma^2, \nS_{\\mathsf{p}}^2 = \\frac{m-1}{m+n-2} S_X^2 + \\frac{n-1}{m+n-2} S_Y^2 \\,.\n\\tag{4.5} The pooled estimator is a weighted average that adjusts for differences between the sample sizes m and n.\n\n\n\n\n\n\nWhy a weighted average?\n\n\n\nIf m \\neq n, then the estimator with more samples will contain more information about the parameter \\sigma^2. Thus, the simple average (S_X^2 + S_Y^2)/2 wouldn’t be fair, would it?\n\n\n\nProposition 4.8 A 100(1-\\alpha)\\% CI for \\mu_X - \\mu_Y for two samples of size m and n from normal populations where the variance \\sigma^2 is unknown is given by \n(\\overline{x} - \\overline{y}) \\pm t_{\\alpha/2, m  + n - 2} \\cdot \\sqrt{ s_{\\mathsf{p}}^2 \\left( \\frac{1}{m} + \\frac{1}{n} \\right)} \\,,\n where we recall that t_{\\alpha/2, m+n-2} is the \\alpha/2 critical value of the \\mathsf{t}(\\nu) with \\nu = m + n - 2 df.\n\nSimilarly, one can consider a pooled \\mathsf{t} test, i.e., a hypothesis test based on the pooled estimator for the variance as opposed to the two-sample \\mathsf{t} test in Proposition 4.7. In the case of a pooled \\mathsf{t} test, the test statistic \nT = \\frac{\\overline{X} - \\overline{Y} - \\theta_0}{\\sqrt{S_{\\mathsf{p}}^2 \\left(\\frac{1}{m} + \\frac{1}{n}\\right)}}\\,,\n with the pooled estimator of the variance, replaces Equation 4.4 in Proposition 4.7 and the same procedures are followed for determining the P-value with \\nu = m+n-2 in place of Equation 4.3. If you have reasons to believe that \\sigma_X^2 = \\sigma_Y^2, these pooled \\mathsf{t} procedures are appealing because \\nu is very easy to compute.\n\nPooled t procedures are not robust if the assumption of equalised variance is violated. Theoretically, you could first carry out a statistical test H_0 : \\sigma_X^2 = \\sigma_Y^2 on the equality of variances and then use a pooled \\mathsf{t} procedure if the null hypothesis is not rejected. However, there is no free lunch: the typical \\mathsf{F} test for equal variances (see Section 4.4) is sensitive to normality assumptions. The two sample \\mathsf{t} procedures, with the data-driven choice of \\nu in Equation 4.3, are therefore recommended unless, of course, you have a very compelling reason to believe \\sigma_X^2 = \\sigma_Y^2.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two samples inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html#sec-compare-paired-samples",
    "href": "04-infer-two-samples.html#sec-compare-paired-samples",
    "title": "4  Two samples inferences",
    "section": "4.2 Comparing paired samples",
    "text": "4.2 Comparing paired samples\nThe preceding analysis for comparing population means was based on the assumption that a random sample X_1, \\dots, X_n is drawn from a distribution with mean \\mu_X and that a completely independent random sample Y_1, \\dots, Y_n is drawn from a distribution with mean \\mu_Y. Some situations, e.g., comparing observations before and after a treatment or exposure, necessitate the consideration of paired values.\nConsider a random sample of iid pairs, \n(X_1, Y_1), \\dots, (X_n, Y_n)\\,,\n with \\mathop{\\mathrm{\\mathbf{E}}}[X_i] = \\mu_X and \\mathop{\\mathrm{\\mathbf{E}}}[Y_i] = \\mu_Y. If we are interested in making inferences about the difference \\mu_X - \\mu_Y, then the paired differences \nD_i = X_i - Y_i \\,,\\quad  i=1, \\dots, n\\,,\n constitute a sample with mean \\mu_D = \\mu_X - \\mu_Y that can be treated using single-sample CIs and tests, e.g., see Section 3.1.3.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two samples inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html#sec-compare-proportions",
    "href": "04-infer-two-samples.html#sec-compare-proportions",
    "title": "4  Two samples inferences",
    "section": "4.3 Comparing proportions",
    "text": "4.3 Comparing proportions\nConsider a population containing a proportion p_X of individuals satisfying a given property. For a sample of size m from this population, we denote the sample proportion by \\widehat{p}_X. Likewise, we consider a population containing a proportion p_Y of individuals satisfying the same given property. For a sample of size n from this population, we denote the sample proportion by \\widehat{p}_Y. We assume the samples from the X and Y populations are independent. The natural estimator for the difference in population proportions p_X - p_Y is the difference in the sample proportions \\widehat{p}_X - \\widehat{p}_Y.\nProvided the samples are much smaller than the population sizes (i.e., the populations are about 20 times larger than the samples), \n\\mu_{(\\widehat{p}_X - \\widehat{p}_Y)} = \\mathop{\\mathrm{\\mathbf{E}}}[\\widehat{p}_X - \\widehat{p}_Y] = p_X - p_Y\\,,\n and \n\\sigma_{(\\widehat{p}_X - \\widehat{p}_Y)}^2 = \\mathop{\\mathrm{Var}}[\\widehat{p}_X - \\widehat{p}_Y]\n= \\frac{p_X(1-p_X)}{m} + \\frac{p_Y(1-p_Y)}{n}\\,,\n because the count of individuals satisfying the given property in each population will be independent draws from \\mathsf{Binom}(m, p_X) and \\mathsf{Binom}(n, p_Y), respectively. Further, if m and n are large (e.g., m \\geq 30 and n \\geq 30), then \\widehat{p}_X and \\widehat{p}_Y are (approximately) normally distributed. Standardizing \\widehat{p}_X - \\widehat{p}_Y, \nZ = \\frac{\\widehat{p}_X - \\widehat{p}_Y - (p_X - p_Y)}{\\sqrt{\\frac{p_X(1-p_X)}{m} + \\frac{p_Y(1-p_Y)}{n}}}\n\\quad \\sim \\mathsf{N}(0,1)\\,.\n A CI for \\widehat{p}_X - \\widehat{p}_Y then follows from the large-sample CI considered in Section 3.1.2.\n\nProposition 4.9 An approximate 100(1-\\alpha)\\% CI for p_X - p_Y is given by \n\\widehat{p}_X - \\widehat{p}_Y \\pm z_{\\alpha/2}\\sqrt{\\frac{\\widehat{p}_X (1 - \\widehat{p}_X)}{m} + \\frac{\\widehat{p}_Y (1 - \\widehat{p}_Y)}{n}}\\,,\n\\tag{4.6} and, as a rule of thumb, can be reliably used if m \\widehat{p}_X, m (1 - \\widehat{p}_X), n \\widehat{p}_Y, and n (1-\\widehat{p}_Y) are greater than or equal to 10.\n\nProposition 4.9 does not pool the estimators for the population proportions. However, if we are considering a hypothesis test concerning the equality of the population proportions with the null hypothesis \nH_0 : p_X - p_Y = 0 \\,,\n then we assume p_X = p_Y as our default position. Therefore, as a matter of consistency, we should replace the standard error in Equation 4.6 with a pooled estimator for the standard error of the population proportion, \n\\widehat{p} = \\frac{m}{m + n} \\widehat{p}_X + \\frac{n}{m + n} \\widehat{p}_Y \\,.\n\n\nProposition 4.10 Assume that m \\widehat{p}_X, m (1-\\widehat{p}_X), n\\widehat{p}_Y, n(1-\\widehat{p}_Y) are all greater than 10.\nConsider H_0 : p_X - p_Y = 0. The test statistic is \nZ = \\frac{\\widehat{p}_X - \\widehat{p}_Y}{\\sqrt{\\widehat{p} (1 - \\widehat{p}) \\left( \\frac{1}{m} + \\frac{1}{n} \\right)}} \\,.\n\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : p_X - p_Y &gt; 0, then P = 1 - \\Phi(z), i.e., upper-tail R = \\{z &gt; z_{\\alpha}\\}.\nIf H_a : p_X - p_Y &lt; 0, then P = \\Phi(z), i.e., lower-tail R = \\{z &lt; - z_{\\alpha}\\}.\nIf H_a : p_X - p_Y \\neq 0, then P = 2(1-\\Phi(|z|)), i.e., two-tailed R = \\{|z| &gt; z_{\\alpha/2}\\}.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two samples inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html#sec-compare-variances",
    "href": "04-infer-two-samples.html#sec-compare-variances",
    "title": "4  Two samples inferences",
    "section": "4.4 Comparing variances",
    "text": "4.4 Comparing variances\nFor a random sample \nX_1, \\dots, X_m \\sim \\mathsf{N}(\\mu_X, \\sigma_X^2)\n and an independent random sample \nY_1, \\dots, Y_n \\sim \\mathsf{N}(\\mu_Y, \\sigma_Y^2)\\,,\n the rv \nF = \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_Y^2} \\quad \\sim \\mathsf{F}(m-1, n-1)\\,,\n\\tag{4.7} that is, F has an \\mathsf{F} distribution with df \\nu_1 = m-1 and \\nu_2 = n-1. The statistic F in Equation 4.7 comprises the ratio of variances \\sigma_X^2 / \\sigma_Y^2 and not the difference; therefore, the plausibility of \\sigma_X^2 = \\sigma_Y^2 will be based on how much the ratio differs from 1.\n\nProposition 4.11 For the null hypothesis H_0 : \\sigma_X^2 = \\sigma_Y^2, the test statistic to consider is: \nf = \\frac{s_X^2}{s_Y^2}\n and the P-values are determined by the \\mathsf{F}(m-1, n-1) distribution where m and n are the respective sample sizes.\n\nA 100(1-\\alpha)\\% CI for the ratio \\sigma_X^2 / \\sigma_Y^2 is based on forming the probability, \nP(F_{1-\\alpha/2, \\nu_1, \\nu_2} &lt; F &lt; F_{\\alpha/2, \\nu_1, \\nu_2}) = 1 - \\alpha\\,,\n where F_{\\alpha/2, \\nu_1, \\nu_2} is the \\alpha/2 critical value from the \\mathsf{F}(\\nu_1 = m-1, \\nu_2 = n-1) distribution. Substituting Equation 4.7 with point estimates for F and manipulating the inequalities it is possible to isolate the ratio \\sigma_X^2 / \\sigma_Y^2, \nP \\left( \\frac{1}{F_{\\alpha/2, \\nu_1, \\nu_2}} \\frac{s_X^2}{s_Y^2} &lt; \\frac{\\sigma_X^2}{\\sigma_Y^2} &lt; \\frac{1}{F_{1-\\alpha/2, \\nu_1, \\nu_2}} \\frac{s_X^2}{s_Y^2} \\right)\n= 1 - \\alpha \\,.\n\n\nProposition 4.12 A 100(1-\\alpha)\\% CI for the ratio of population variances \\sigma_X^2 / \\sigma_Y^2 is given by \n\\left(F_{\\alpha/2, m-1, n-1}^{-1} s_X^2 / s_Y^2 \\,,  F_{1-\\alpha/2, m-1, n-1}^{-1} s_X^2 / s_Y^2 \\right)\\,.\n\n\n\nProposition 4.13 Assume the population distributions are normal and the random samples are independent of one another.\nConsider H_0 : \\sigma_X^2 = \\sigma_Y^2. The test statistic is \nF = S_X^2 / S_Y^2 \\,.\n\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\sigma_X^2 &gt; \\sigma_Y^2, then P-value is A_R = {} area under the \\mathsf{F}(m-1, n-1) curve to the right of f.\nIf H_a : \\sigma_X^2 &lt; \\sigma_Y^2, then P-value is A_L = {} area under the \\mathsf{F}(m-1, n-1) curve to the left of f.\nIf H_a : \\sigma_X^2 \\neq \\sigma_Y^2, then P-value is 2 \\cdot \\min(A_R, A_L).",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two samples inferences</span>"
    ]
  },
  {
    "objectID": "04-infer-two-samples.html#footnotes",
    "href": "04-infer-two-samples.html#footnotes",
    "title": "4  Inferences based on two samples",
    "section": "",
    "text": "If m \\neq n, then the estimator with more samples will contain more information about the parameter \\sigma^2. Thus, the simple average (S_X^2 + S_Y^2)/2 wouldn’t be fair, would it?↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferences based on two samples</span>"
    ]
  },
  {
    "objectID": "05-anova.html",
    "href": "05-anova.html",
    "title": "5  Analysis of variance",
    "section": "",
    "text": "5.1 Single factor ANOVA test\nSuppose that we have k normally distributed populations with different means \\mu_1, \\dots, \\mu_k and equal variances \\sigma^2. We denote the rv for the jth measurement taken from the ith population by X_{ij} and the corresponding sample observation by x_{ij}. For samples of size m_1, \\dots, m_k, we denote the sample means \n\\overline{X}_i = \\frac{1}{m_i} \\sum_{j=1}^{m_i} X_{ij}\\,,\n and sample variances \nS_i^2 = \\frac{1}{m_i - 1} \\sum_{j=1}^{m_i} (X_{ij} - \\overline{X}_{i})^2\\,,\n for each i = 1, \\dots, k; likewise, we denote the associated point estimates for the sample means \\overline{x}_1, \\dots, \\overline{x}_k and the sample variances s_1^2, \\dots, s_k^2. The average over all observations m = \\sum m_i, called the grand mean, is denoted by \n\\overline{X} = \\frac{1}{m} \\sum_{i=1}^k \\sum_{j=1}^{m_i} X_{ij}\\,.\n The sample variances s_i^2, and hence the sample standard deviations, will generally vary even when the k populations share the same variance; a rule of thumb is that the equality of variances is reasonable if the largest s_i is not much more than two times the smallest.\nWe wish to test the equality of the population means, given by the null hypothesis, \nH_0 : \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\,,\n versus the alternative hypothesis, \nH_a : \\text{at least two}\\; \\mu_i \\; \\text{differ}\\,.\n Note that if k=3 then H_0 is true only if all three means are the same, i.e., \\mu_1 = \\mu_1 = \\mu_3, but there are a number of ways which the alternative might hold: \\mu_1 \\neq \\mu_2 = \\mu_3 or \\mu_1 = \\mu_2 \\neq \\mu_3 or \\mu_1 = \\mu_3 \\neq \\mu_2 or \\mu_1 \\neq \\mu_2 \\neq \\mu_3.\nThe test procedure is based on comparing a measure of the difference in variation among the sample means, i.e., the variation between x_i’s, to a measure of variation within each sample.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "05-anova.html#anova-single-factor-test",
    "href": "05-anova.html#anova-single-factor-test",
    "title": "5  Analysis of variance (ANOVA)",
    "section": "",
    "text": "Table @ref(tab:anova-samples-stats) presents the Average Salary Data (in thousands of pounds) reported from 20 local councils classified by nation (England, N Ireland, Scotland, and Wales). The sample means and sample standard deviations are summarised in the table and presented using box plots in Figure @ref(fig:anova-samples-boxplots).",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance (ANOVA)</span>"
    ]
  },
  {
    "objectID": "05-anova.html#anova-ci",
    "href": "05-anova.html#anova-ci",
    "title": "5  Analysis of variance (ANOVA)",
    "section": "5.2 Confidence intervals",
    "text": "5.2 Confidence intervals\nIn Section @ref(compare-means), we gave a CI for comparing population means involving the difference \\mu_X - \\mu_Y. In some settings, we would like to give CIs for more complicated functions of population means \\mu_i. Let \\begin{equation*}\n\\theta = \\sum_{i=1}^k c_i \\mu_i\\,,\n\\end{equation*} for constants c_i. As we assume the X_ij are normally distributed with \\E[X_{ij}] = \\mu_i and \\Var[X_{ij}] = \\sigma^2, the estimator \\begin{equation*}\n\\widehat{\\theta} = \\sum_{i=1}^k c_i \\overline{X}_{i}\\,,\n\\end{equation*} is normally distributed with \\begin{equation*}\n\\Var[\\widehat{\\theta}] = \\sum_{i=1}^k c_i^2 \\Var[\\overline{X}_i] = \\sigma^2 \\sum_{i=1}^{k} \\frac{c_i^2}{m_i}\\,.\n\\end{equation*} We estimate \\sigma^2 by the \\mathsf{MSE} and standardise the estimator to arrive at a \\mathsf{t} variable \\begin{equation*}\n\\frac{\\widehat{\\theta} - \\theta}{\\widehat{\\sigma}_{\\widehat{\\theta}}}\\,,\n\\end{equation*} where \\widehat{\\sigma}_{\\widehat{\\theta}} is the estimated standard error of the estimator.\n\n\nCode\nA $100(1-\\alpha)\\%$ CI for $\\sum c_i \\mu_i$ is given by \n\\begin{equation*}\n \\sum_{i=1}^k c_i \\overline{x}_i \\pm t_{\\alpha/2, m-k} \\sqrt{\\mathsf{MSE} \\sum_{i=1}^k \\frac{c_i^2}{m_i}}\\,.\n\\end{equation*}\n\n\n\n\nCode\nDetermine a $90\\%$ CI for the difference in mean average salary for councils in Scotland and England, based on the data available in Table \\@ref(tab:anova-samples-stats)\n\n\nFor \\alpha = 0.10, the critical value t_{0.05, 16} = 1.7458837 is found by looking in a table of \\mathsf{t} critical values or by using r:\n\n\nCode\n# alt: qt(0.1/2, 16, lower.tail = FALSE)\nqt(1-0.1/2, df = 20 - 4) \n\n\n[1] 1.745884\n\n\nThen for the function \\overline{x}_2 - \\overline{x_1}, \\begin{equation*}\n\\begin{aligned}\n(\\overline{x}_{Eng} - \\overline{x}_{Sco}) \\pm& t_{0.05, 16} \\sqrt{\\mathsf{MSE}} \\sqrt{\\frac{1}{m_{Eng}} + \\frac{1}{m_{Sco}}} \\\\\n& = (14.5 - 13.0) \\pm 1.7458837 \\sqrt{5.14366} \\sqrt{\\frac{1}{6} + \\frac{1}{5}} \\\\\n& = 1.5 \\pm 2.3976575\\,.\n\\end{aligned}\n\\end{equation*} Thus a 90\\% confidence interval for \\mu_{Eng} - \\mu_{Sco} is (-0.8977\\,, 3.898). \\lozenge\n\nHow does the result in Example @ref(exm:anova-ci) compare to the \\mathsf{t} method in Section @ref(compare-means-normpops-vars-unknown)?",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance (ANOVA)</span>"
    ]
  },
  {
    "objectID": "05-anova.html#footnotes",
    "href": "05-anova.html#footnotes",
    "title": "5  Analysis of variance",
    "section": "",
    "text": "In the context of ANOVA, these k populations are often referred to as treatment distributions.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "05-anova.html#sec-anova-single-factor-test",
    "href": "05-anova.html#sec-anova-single-factor-test",
    "title": "5  Analysis of variance",
    "section": "",
    "text": "Alternative lingo\n\n\n\nIn the context of ANOVA, these k populations are often referred to as treatment distributions.\n\n\n\n\n\nDefinition 5.1 The mean square for treatments is \n\\mathsf{MSTr} = \\frac{1}{k-1} \\sum_{i=1}^k m_i (\\overline{X}_i - \\overline{X})^2\\,,\n and the mean square error is \n\\mathsf{MSE} = \\frac{1}{m-k} \\sum_{i=1}^k (m_i - 1) S_i^2 \\,.\n The \\mathsf{MSTr} and \\mathsf{MSE} are statistics that measure the variation among sample means and the variation within samples. We will also use \\mathsf{MSTr} and \\mathsf{MSE} to denote the calculated values of these statistics.\n\n\nProposition 5.1 The test statistic \nF = \\frac{\\mathsf{MSTr}}{\\mathsf{MSE}}\n is the appropriate test statistic for the single-factor ANOVA problem involving k populations (or treatments) with a random sample of size m_1, \\dots, m_k from each. When H_0 is true, \nF \\sim \\mathsf{F}(\\nu_1 = k-1, \\nu_2 = m - k)\\,.\n In the present context, a large test statistic value is more contradictory to H_0 than a smaller value. Therefore the test is upper-tailed, i.e., consider the area F_\\alpha to the right of the critical value F_{\\alpha, \\nu_1, \\nu_2}. We reject H_0 if the value of the test statistic F &gt; F_\\alpha.\n\n\n\n\n\n\n\nNote 5.1: Average Salary Data\n\n\n\n\n\nThe Average Salary Data comprises average salaries reported by 20 local councils across the four nations of the United Kingdom (England, N Ireland, Scotland and Wales). The sample means and sample standard deviations are summarised in Table 5.1.\n\n\n\n\nTable 5.1: Average Salary Data reported from 20 local councils.\n\n\n\n\n\n\n\nNation\nAverage salaries ('000 £)\nSample size\nSample mean\nSample sd\n\n\n\n\nEngland\n17, 12, 18, 13, 15, 12\n6\n14.5\n2.588\n\n\nN Ireland\n11, 7, 9, 13\n4\n10.0\n2.582\n\n\nScotland\n15, 10, 13, 14, 13\n5\n13.0\n1.871\n\n\nWales\n10, 12, 8, 7, 9\n5\n9.2\n1.924\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.1 Consider the Average Salary Data reported in Note 5.1. Is the expected average salary in each nation the same at the 5\\% level?\nWe begin by exploring the data through the generation and interpretation of some box plots. The box plots in Figure 5.1 indicate that there may be a difference in median average salary by nation.\n\n\n\n\n\n\n\n\nFigure 5.1: Box plots of the average mean salary data in Table Table 5.1 indicate five summary statistics: the median, two hinges (first and third quartiles) and two whiskers (extending from the hinge to the most extreme data point within 1.5 \\cdot \\mathsf{IQR}).\n\n\n\n\n\nFor \\alpha = 0.05, we compute the upper-tail area F_{0.05} i.e. to the right of the critical value F_{0.05, 3, 16} by consulting a statistical table or by using r to find F_{0.05} = 3.2388715.\n\n\nCode\n# alt: qf(.05, df1 = 3, df2 = 16, lower.tail = FALSE)\nqf(1-.05, df1 = 4-1, df2 = 20-4) \n\n\n[1] 3.238872\n\n\nThe grand mean is \n\\overline{x} = \\frac{17 + 12 + 18 + \\cdots + 8 + 7 + 9}{20} = 11.9\\,,\n and hence the variation among sample means is given by, \n\\begin{aligned}\n\\mathsf{MSTr} &= \\frac{1}{4-1} \\left(m_1(\\overline{x}_1 - \\overline{x})^2 + \\cdots + m_4 (\\overline{x}_4 - \\overline{x})^2\\right) \\\\\n&= \\left(6 (14.5-11.9)^2 + 4(10.0 - 11.9)^2 + 5(13.0-11.9)^2 + 5 ( 9.2 - 11.9)^2\\right) / 3 \\\\\n&= 32.5 \\,.\n\\end{aligned}\n The mean square error is \n\\begin{aligned}\n\\mathsf{MSE} & = \\frac{1}{20-4} \\left((m_1 - 1)s_1^2 + \\cdots (m_4-1)s_4^2\\right)\\\\\n  &= \\frac{5(2.588)^2 + 3(2.582)^2 + 4(1.871)^2 + 4(1.924)^2}{16} \\\\\n  &= 5.14366\n\\end{aligned}\n yielding the test statistic value \nF = \\frac{\\mathsf{MSTr}}{\\mathsf{MSE}} = \\frac{32.5}{5.14366}\n= 6.3184581 \\,.\n Since F &gt; F_\\alpha we reject H_0. The data do not support the hypothesis that the mean salaries in each nation are identical at the 5\\% level.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "05-anova.html#sec-anova-ci",
    "href": "05-anova.html#sec-anova-ci",
    "title": "5  Analysis of variance",
    "section": "5.2 Confidence intervals",
    "text": "5.2 Confidence intervals\nIn Section 4.1, we gave a CI for comparing population means involving the difference \\mu_X - \\mu_Y. In some settings, we would like to give CIs for more complicated functions of population means \\mu_i. Let \n\\theta = \\sum_{i=1}^k c_i \\mu_i\\,,\n for constants c_i. As we assume the X_ij are normally distributed with \\mathop{\\mathrm{\\mathbf{E}}}[X_{ij}] = \\mu_i and \\mathop{\\mathrm{Var}}[X_{ij}] = \\sigma^2, the estimator \n\\widehat{\\theta} = \\sum_{i=1}^k c_i \\overline{X}_{i}\\,,\n is normally distributed with \n\\mathop{\\mathrm{Var}}[\\widehat{\\theta}] = \\sum_{i=1}^k c_i^2 \\mathop{\\mathrm{Var}}[\\overline{X}_i] = \\sigma^2 \\sum_{i=1}^{k} \\frac{c_i^2}{m_i}\\,.\n We estimate \\sigma^2 by the \\mathsf{MSE} and standardise the estimator to arrive at a \\mathsf{t} variable \n\\frac{\\widehat{\\theta} - \\theta}{\\widehat{\\sigma}_{\\widehat{\\theta}}}\\,,\n where \\widehat{\\sigma}_{\\widehat{\\theta}} is the estimated standard error of the estimator.\n\nProposition 5.2 A 100(1-\\alpha)\\% CI for \\sum c_i \\mu_i is given by $$ _{i=1}^k c_i i t{/2, m-k} ,.\n\n\nExample 5.2 Determine a 90\\% CI for the difference in mean average salary for councils in Scotland and England, based on the data available in Table 5.1\nFor \\alpha = 0.10, the critical value t_{0.05, 16} = 1.7458837 is found by looking in a table of \\mathsf{t} critical values or by using r:\n\n\nCode\n# alt: qt(0.1/2, 16, lower.tail = FALSE)\nqt(1-0.1/2, df = 20 - 4) \n\n\n[1] 1.745884\n\n\nThen for the function \\overline{x}_2 - \\overline{x_1}, \n\\begin{aligned}\n(\\overline{x}_{Eng} - \\overline{x}_{Sco}) \\pm& t_{0.05, 16} \\sqrt{\\mathsf{MSE}} \\sqrt{\\frac{1}{m_{Eng}} + \\frac{1}{m_{Sco}}} \\\\\n& = (14.5 - 13.0) \\pm 1.7458837 \\sqrt{5.14366} \\sqrt{\\frac{1}{6} + \\frac{1}{5}} \\\\\n& = 1.5 \\pm 2.3976575\\,.\n\\end{aligned}\n Thus, a 90\\% confidence interval for \\mu_{Eng} - \\mu_{Sco} is (-0.8977\\,, 3.898).\n\n\n\n\n\n\n\nConsider the following\n\n\n\nHow does the result in Example 5.2 compare to the \\mathsf{t} method in Section 4.1.3?",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html",
    "href": "06-linear-models.html",
    "title": "6  Linear regression",
    "section": "",
    "text": "6.1 Simple linear regression models\nThe simplest regression is when X_i is one-dimensional and r(x) is linear as in Equation 6.1. A linear regression posits the expected value of Y_i is a linear function of the data X_i, but that Y deviates from its expected value by a random amount for fixed x_i.\nFrom the assumptions on \\epsilon_i, the linear model Equation 6.2 implies \n\\mathop{\\mathrm{\\mathbf{E}}}[Y_i \\mid X_i = x_i] = \\beta_0 + \\beta_1 x_i \\,.\n Thus, if \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are estimators of \\beta_0 and \\beta_1, then the fitted line is \n\\widehat{r}(x) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 x\n and the predicted or fitted value \\widehat{Y}_i = \\widehat{r}(X_i) is an estimator for \\mathop{\\mathrm{\\mathbf{E}}}[Y_i \\mid X_i = x_i]. The residuals are defined to be \n\\widehat{\\epsilon}_i = Y_i - \\widehat{Y}_i = Y_i - \\left( \\widehat{\\beta}_0 + \\widehat{\\beta}_1 X_i \\right) \\,.\n\\tag{6.3} The residual sums of squares, \n\\mathsf{RSS} = \\sum_{i=1}^m \\widehat{\\epsilon}_i^2\\,,\n\\tag{6.4} measures how well the regression line \\widehat{r} fits the data (Y_1, X_1), \\dots, (Y_m, X_m). The least squares estimates of \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are the values that minimize the \\mathsf{RSS} in Equation 6.4.\nEquation 6.4 is a function of \\widehat{\\beta}_0 and \\widehat{\\beta}_1 from the definition of the residuals Equation 6.3. Then Equation 6.5 and Equation 6.6 follow by equating the partial derivatives of Equation 6.4 to zero. The \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are the unique solution to this linear system.\nFigure 6.1: Linear regression (or least squares fit) of Volume to Diameter from the Cherry Tree Data. The vertical bars between the observed data point and the regression line indicate the error in the fit (the least squares residual). The residuals are squared and summed to yield the \\mathsf{RSS} (alt: \\mathsf{SSE}).\nFigure 6.2: The deviations about the sample mean \\overline{y}. The sum of the squared deviations or \\mathsf{SST} (total sum of squares) is a measure of the total variation in the observations.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#ls-estimate-var",
    "href": "06-linear-models.html#ls-estimate-var",
    "title": "6  Linear regression",
    "section": "6.2 Estimating \\sigma^2 for linear regressions",
    "text": "6.2 Estimating \\sigma^2 for linear regressions\nThe parameter \\sigma^2 (the variance of the random deviation) determines the variability in the regression model.\n\n\nCode\nAn unbiased estimate of $\\sigma^2$ is given by\n\\begin{equation}\n \\widehat{\\sigma}^2 = s^2 = \\frac{\\mathsf{RSS}}{m-2} = \\frac{1}{m-2} \\sum_{i=1}^m (y_i - \\widehat{y}_i)^2\\,.\n (\\#eq:least-squares-var-estimate)\n\\end{equation}\n\n\nIn Figure @ref(fig:linear-model-sigma-large-v-small), we present a least squares regression of timber volume on both tree diameter and height (for the Cherry Tree Data). As expected, the regressions indicate the volume increases with both covariates. Estimates for the variance of the random deviation @ref(eq:least-squares-var-estimate) in both regression models, \\sigma_{D}^2 and \\sigma_{H}^2, respectively, are computed to be s^2_{D} = 18.08 and s^2_{H} = 179.48. Thus, we see that small variances lead to observations of (x_i, y_i) that sit tightly around the regression line, in contrast to large variances that lead to a large cloud of points.\n\n\n\n\n\nFor the Cherry Tree Data, we estimate the variance to be s^2_{D} = 18.08 (for Diameter) and s^2_{H} = 179.48 (for Height); small variances lead to observations of (x_i, y_i) that sit tightly around the regression line, in contrast to large variances that lead to a large cloud of points.\n\n\n\n\n\nIn Theorem @ref(thm:least-squares-var-estimate), the number in the denominator is the df associated with the \\mathsf{RSS} and s^2. To calculate \\mathsf{RSS}, you must estimate two parameters \\beta_0 and \\beta_1, which results in the loss of two df. Hence the m-2.\n\nWe note to make inferences, the statistic \\begin{equation*}\nS^2 = \\frac{\\mathsf{RSS}}{m-2}\n\\end{equation*} is an unbiased estimator or \\sigma^2 and the random variable \\begin{equation*}\n\\frac{(m-2) S^2}{\\sigma^2} \\sim \\chi^2(m-2)\\,.\n\\end{equation*} Moreover, the statistic S^2 is independent of both \\widehat{\\beta}_0 and \\widehat{\\beta}_1.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#inference-ls",
    "href": "06-linear-models.html#inference-ls",
    "title": "6  Linear regression",
    "section": "6.3 Inferences for least-squares parameters",
    "text": "6.3 Inferences for least-squares parameters\nIf \\epsilon_i in @ref(eq:linear-model) is assumed to be normally distributed, then we can derive the sampling distributions of the estimators \\widehat{\\beta}_0 and \\widehat{\\beta}_1. Hence, we can use these sampling distributions to make inferences about the parameters \\beta_0 and \\beta_1.\nProvided iid \\epsilon_i \\mid X_i \\sim \\mathsf{N}(0, \\sigma^2), the least-squares estimators possess the following properties.\n\nBoth \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are normally distributed.\nBoth \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are unbiased, i.e., \\E[\\widehat{\\beta}_i] = \\beta_i for i = 0,1.\n\\Var[\\widehat{\\beta}_0] = c_{00} \\sigma^2 where c_{00} = \\sum_{i=1}^m x_i^2 / (m S_{xx}).\n\\Var[\\widehat{\\beta}_1] = c_{11} \\sigma^2 where c_{11} = 1/S_{xx}.\n\\Cov[\\widehat{\\beta}_0, \\widehat{\\beta}_1] = c_{01} \\sigma^2 where c_{01} = - \\overline{x} / S_{xx}.\n\nThese properties can be determined by working directly from @ref(eq:ls-slope) and @ref(eq:ls-intercept).\n\n\nCode\nConsider $H_0 : \\beta_i = \\beta_{i0}$. The test statistic is\n\\begin{equation*}\n T = \\frac{\\widehat{\\beta}_i - \\beta_{i0}}{S\\sqrt{c_{ii}}} \\,.\n (\\#eq:htest-ls-betas-statistic)\n\\end{equation*}\n\nFor a hypothesis test at level $\\alpha$, we use the following procedure:\n\nIf $H_a : \\beta_i &gt; \\beta_{i0}$, then $P$-value is the area under $\\mathsf{t}(m-2)$ to the right of $t$.\n\nIf $H_a : \\beta_i &lt; \\beta_{i0}$, tthen $P$-value is the area under $\\mathsf{t}(m-2)$ to the left of $t$.\n\nIf $H_a : \\beta_i \\neq \\beta_{i0}$, then $P$-value is twice the area under $\\mathsf{t}(m-2)$ to the right of $|t|$.\n\n\nA confidence interval for \\beta_i, based on the statistic @ref(eq:htest-ls-betas-statistic), can be given following the procedures in @ref(inference-single-sample).\n\n\nCode\nA $100(1-\\alpha)\\%$ CI for $\\beta_i$ is given by \n\\begin{equation*}\n \\widehat{\\beta}_i \\pm t_{\\alpha/2, m-2} S \\sqrt{c_{ii}} \\,.\n\\end{equation*}",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#correlation",
    "href": "06-linear-models.html#correlation",
    "title": "6  Linear regression",
    "section": "6.4 Correlation",
    "text": "6.4 Correlation\nLet (X_1, Y_1), \\dots, (X_m, Y_m) denote a random sample from a bivariate normal distribution with \\E[X_i] = \\mu_X, \\E[Y_i] = \\mu_Y, \\Var[X_i] = \\sigma_X^2, \\Var[Y_i] = \\sigma_Y^2, and correlation coefficient \\rho. The sample correlation coefficient is given by, \\begin{equation}\nr = \\frac{\\sum_{i=1}^m (X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sqrt{\\sum_{i=1}^m (X_i - \\overline{X})^2 \\sum_{i=1}^m (Y_i - \\overline{Y})^2}}\\,,\n(\\#eq:sample-correlation-statistic)\n\\end{equation} which can be rewritten in terms of S_{xx}, S_{xy}, and S_{yy}: \\begin{equation*}\nr = \\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}} = \\widehat{\\beta}_1 \\sqrt{\\frac{S_{xx}}{S_{yy}}}\\,,\n\\end{equation*} using @ref(eq:ls-slope) and we see that r and \\widehat{\\beta}_1 have the same sign. A |r| close to 1 means that the regression line is a good fit to the data, and, similarly, an |r| close to 0 means a poor fit to the data. Note that the correlation coefficient (and the least squares regression) are only suitable for describing linear relationships; a nonlinear relationship can also yield r near zero (see Figure @ref(fig:linear-model-correlation)).\n\n\n\n\n\nCorrelations range from -1 to 1 with |r|=1 indicating a strong linear relationship and r near zero indicating the absence of a linear relationship.\n\n\n\n\nOnce a model is fit, it can be used to predict a value of y for a given x. However, the model only gives the most likely value of y; a corresponding prediction interval is usually more appropriate.\n\n\nCode\nA $100(1-\\alpha)\\%$ **prediction interval** for an actual value of $Y$ when $x = x^*$ is given by \n\\begin{equation*}\n (\\widehat{\\beta}_0 + \\widehat{\\beta}_1 x^*) \\pm t_{\\alpha/2, m-2} S \\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}} \\,.\n\\end{equation*}\n\n\n\nThe prediction interval is different from the confidence interval for expected Y. Note that the length of the confidence interval for \\E[Y] when x=x^* is given by \\begin{equation*}\n2 \\cdot t_{\\alpha/2} S  \\sqrt{\\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}}\n\\end{equation*} whereas the length for the prediction interval of Y is \\begin{equation*}\n2 \\cdot t_{\\alpha/2} S  \\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}} \\,.\n\\end{equation*} Thus the prediction intervals for an actual value of Y are longer than the confidence intervals for \\E[Y] if both are determined for the same value x^*.\n\nThe linear model \\begin{equation*}\n\\E[ Y \\mid X = x ] = \\beta_0 + \\beta_1 x \\,,\n\\end{equation*} assumes that the conditional expectation of Y for a fixed value of X is a linear function of the x value. If we assume that (X,Y) has a bivariate normal distribution, then \\begin{equation*}\n\\beta_1 = \\frac{\\sigma_Y}{\\sigma_X} \\rho \\,,\n\\end{equation*} and thus, for the simple hypothesis tests we have considered (Table @ref(tab:htest-null-alt-forms)), statistical tests for \\beta and \\rho are equivalent.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#footnotes",
    "href": "06-linear-models.html#footnotes",
    "title": "6  Linear regression",
    "section": "",
    "text": "The \\mathsf{RSS} is sometimes referred to as the error sum of squares and abbreviated \\mathsf{SSE} (no, the order is not a typo).↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#sec-ls-estimate-var",
    "href": "06-linear-models.html#sec-ls-estimate-var",
    "title": "6  Linear regression",
    "section": "6.2 Estimating \\sigma^2 for linear regressions",
    "text": "6.2 Estimating \\sigma^2 for linear regressions\nThe parameter \\sigma^2 (the variance of the random deviation) determines the variability in the regression model.\n\nTheorem 6.2 An unbiased estimate of \\sigma^2 is given by \n\\widehat{\\sigma}^2 = s^2 = \\frac{\\mathsf{RSS}}{m-2} = \\frac{1}{m-2} \\sum_{i=1}^m (y_i - \\widehat{y}_i)^2\\,.\n\\tag{6.7}\n\nIn Figure 6.3, we present a least squares regression of timber volume on both tree diameter and height (for the Cherry Tree Data). As expected, the regressions indicate the volume increases with both covariates. Estimates for the variance of the random deviation Equation 6.7 in both regression models, \\sigma_{D}^2 and \\sigma_{H}^2, respectively, are computed to be s^2_{D} = 18.08 and s^2_{H} = 179.48. Thus, we see that small variances lead to observations of (x_i, y_i) that sit tightly around the regression line, in contrast to large variances that lead to a large cloud of points.\n\n\n\n\n\n\n\n\nFigure 6.3: For the Cherry Tree Data, we estimate the variance to be s^2_{D} = 18.08 (for Diameter) and s^2_{H} = 179.48 (for Height); small variances lead to observations of (x_i, y_i) that sit tightly around the regression line, in contrast to large variances that lead to a large cloud of points.\n\n\n\n\n\n\n\n\n\n\n\nWhy do we lose two degrees of freedom?\n\n\n\nIn Theorem 6.2, the number in the denominator is the df associated with the \\mathsf{RSS} and s^2. To calculate \\mathsf{RSS}, you must estimate two parameters \\beta_0 and \\beta_1, which results in the loss of two df. Hence the m-2.\n\n\nWe note to make inferences, the statistic \nS^2 = \\frac{\\mathsf{RSS}}{m-2}\n is an unbiased estimator or \\sigma^2 and the random variable \n\\frac{(m-2) S^2}{\\sigma^2} \\sim \\chi^2(m-2)\\,.\n Moreover, the statistic S^2 is independent of both \\widehat{\\beta}_0 and \\widehat{\\beta}_1.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#sec-inference-ls",
    "href": "06-linear-models.html#sec-inference-ls",
    "title": "6  Linear regression",
    "section": "6.3 Inferences for least-squares parameters",
    "text": "6.3 Inferences for least-squares parameters\nIf \\epsilon_i in Equation 6.2 is assumed to be normally distributed, then we can derive the sampling distributions of the estimators \\widehat{\\beta}_0 and \\widehat{\\beta}_1. Hence, we can use these sampling distributions to make inferences about the parameters \\beta_0 and \\beta_1.\nProvided iid \\epsilon_i \\mid X_i \\sim \\mathsf{N}(0, \\sigma^2), the least-squares estimators possess the following properties.\n\nBoth \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are normally distributed.\nBoth \\widehat{\\beta}_0 and \\widehat{\\beta}_1 are unbiased, i.e., \\mathop{\\mathrm{\\mathbf{E}}}[\\widehat{\\beta}_i] = \\beta_i for i = 0,1.\n\\mathop{\\mathrm{Var}}[\\widehat{\\beta}_0] = c_{00} \\sigma^2 where c_{00} = \\sum_{i=1}^m x_i^2 / (m S_{xx}).\n\\mathop{\\mathrm{Var}}[\\widehat{\\beta}_1] = c_{11} \\sigma^2 where c_{11} = 1/S_{xx}.\n\\mathop{\\mathrm{Cov}}[\\widehat{\\beta}_0, \\widehat{\\beta}_1] = c_{01} \\sigma^2 where c_{01} = - \\overline{x} / S_{xx}.\n\nThese properties can be determined by working directly from Equation 6.5 and Equation 6.6.\n\nProposition 6.1 Consider H_0 : \\beta_i = \\beta_{i0}. The test statistic is \nT = \\frac{\\widehat{\\beta}_i - \\beta_{i0}}{S\\sqrt{c_{ii}}} \\,.\n\\tag{6.8}\nFor a hypothesis test at level \\alpha, we use the following procedure:\nIf H_a : \\beta_i &gt; \\beta_{i0}, then P-value is the area under \\mathsf{t}(m-2) to the right of t.\nIf H_a : \\beta_i &lt; \\beta_{i0}, tthen P-value is the area under \\mathsf{t}(m-2) to the left of t.\nIf H_a : \\beta_i \\neq \\beta_{i0}, then P-value is twice the area under \\mathsf{t}(m-2) to the right of |t|.\n\nA confidence interval for \\beta_i, based on the statistic Equation 6.8, can be given following the procedures in Chapter 3.\n\nProposition 6.2 A 100(1-\\alpha)\\% CI for \\beta_i is given by \n\\widehat{\\beta}_i \\pm t_{\\alpha/2, m-2} S \\sqrt{c_{ii}} \\,.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#sec-correlation",
    "href": "06-linear-models.html#sec-correlation",
    "title": "6  Linear regression",
    "section": "6.4 Correlation",
    "text": "6.4 Correlation\nLet (X_1, Y_1), \\dots, (X_m, Y_m) denote a random sample from a bivariate normal distribution with \\mathop{\\mathrm{\\mathbf{E}}}[X_i] = \\mu_X, \\mathop{\\mathrm{\\mathbf{E}}}[Y_i] = \\mu_Y, \\mathop{\\mathrm{Var}}[X_i] = \\sigma_X^2, \\mathop{\\mathrm{Var}}[Y_i] = \\sigma_Y^2, and correlation coefficient \\rho. The sample correlation coefficient is given by, \nr = \\frac{\\sum_{i=1}^m (X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sqrt{\\sum_{i=1}^m (X_i - \\overline{X})^2 \\sum_{i=1}^m (Y_i - \\overline{Y})^2}}\\,,\n\\tag{6.9} which can be rewritten in terms of S_{xx}, S_{xy}, and S_{yy}: \nr = \\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}} = \\widehat{\\beta}_1 \\sqrt{\\frac{S_{xx}}{S_{yy}}}\\,,\n using Equation 6.5 and we see that r and \\widehat{\\beta}_1 have the same sign. A |r| close to 1 means that the regression line is a good fit to the data, and, similarly, an |r| close to 0 means a poor fit to the data. Note that the correlation coefficient (and the least squares regression) are only suitable for describing linear relationships; a nonlinear relationship can also yield r near zero (see Figure 6.4).\n\n\n\n\n\n\n\n\nFigure 6.4: Correlations range from -1 to 1 with |r|=1 indicating a strong linear relationship and r near zero indicating the absence of a linear relationship.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#sec-simple-linear-regression",
    "href": "06-linear-models.html#sec-simple-linear-regression",
    "title": "6  Linear regression",
    "section": "",
    "text": "Definition 6.1 The simple linear regression model relates a random response Y_i to a set of independent variables X_i, \nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i \\,,\n\\tag{6.2} where the intercept \\beta_0 and slope \\beta_1 are unknown parameters and the random deviation or random error \\epsilon_i is a rv assumed to satisfy:\n\n\\mathop{\\mathrm{\\mathbf{E}}}[\\epsilon_i \\mid X_i = x_i] = 0,\n\\mathop{\\mathrm{Var}}[\\epsilon_i \\mid X_i = x_i] = \\sigma^2 does not depend on x_i,\n\\epsilon_i and \\epsilon_j are independent for i, j = 1, \\dots, m.\n\n\n\n\nTheorem 6.1 The least squares estimates for \\widehat{\\beta}_1 and \\widehat{\\beta}_0 are given by, respectively, \n\\widehat{\\beta}_1 = \\frac{\\sum_{i=1}^m (X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sum_{i=1}^m (X_i - \\overline{X})^2} = \\frac{S_{xy}}{S_{xx}} \\,,\n\\tag{6.5} and \n\\widehat{\\beta}_0 = \\overline{Y} - \\widehat{\\beta}_1 \\overline{X}\\,.\n\\tag{6.6}\n\n\n\n\n\n\n\n\nAlternative lingo\n\n\n\nThe \\mathsf{RSS} is sometimes referred to as the error sum of squares and abbreviated \\mathsf{SSE} (no, the order is not a typo).\n\n\n\nExample 6.1 In Figure 6.1 and Figure 6.2, we consider the Cherry Tree Data (see Table 2.1) and discussion). We fit a least squares regression of timber volume (response variable) to the tree’s diameter (independent variable). As you would expect, the timber yield increases with diameter.\nThe r code below can be used to calculate the least squares regression and residuals.\n\n\nCode\ndata(trees)\ny &lt;- trees$Volume\nx &lt;- trees$Girth # NB: this is the diameter; data mislabeled!\nfit &lt;- lm(y ~ x)\ne &lt;- resid(fit)\nyhat &lt;- predict(fit)\n\n\nThe fit data frame contains the estimates for \\widehat{\\beta}_0 and \\widehat{\\beta}_1:\n\n\nCode\nfit$coefficients\n\n\n(Intercept)           x \n -36.943459    5.065856 \n\n\nBoth Figure 6.1 and Figure 6.2 are scatter plots of the observed values y. In Figure 6.1, the regression line \\widehat{y} is plotted along with the residuals \\widehat{\\epsilon}. In Figure 6.2, the sample mean \\overline{y} is plotted together with the deviations y - \\overline{y}.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "07-categorical-data.html",
    "href": "07-categorical-data.html",
    "title": "7  Categorical data",
    "section": "",
    "text": "7.1 Multinomial experiments\nSuppose we have a population divided into k &gt; 2 distinct categories. We consider an experiment where we select m individuals (or objects) from the population and categorise each. We denote the population proportion in the ith category by p_i. If the sample size m is much smaller than the population size M (so that the m trials are independent), this experiment will be approximately multinomial with success probability p_i for each category, i=1, \\dots, k.\nBefore the experiment is performed, we denote the number (or count) of the trials resulting in category i by the rv N_i. The expected number of trails that result in category i is given by \n\\mathop{\\mathrm{\\mathbf{E}}}[N_i] = m p_i\\,, \\quad i=1, \\dots, k\\,.\n\\tag{7.1} After the experiment is performed, we denote the corresponding observed value by n_i. Since the trials result in distinct categories, \n\\sum_{i=1}^k N_i = \\sum_{i=1}^{k} n_i = m \\,,\n which indicates that, for a given m, we only need to observe k-1 of the variables to be able to work out what the kth variable should be.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Categorical data</span>"
    ]
  },
  {
    "objectID": "07-categorical-data.html#goodness-of-fit-tests",
    "href": "07-categorical-data.html#goodness-of-fit-tests",
    "title": "7  Categorical data",
    "section": "7.2 Goodness-of-fit for a single factor",
    "text": "7.2 Goodness-of-fit for a single factor\nWe are interested in making inferences about the proportion parameters p_i. Specifically, we will consider the null hypothesis, \\begin{equation}\nH_0 : p_1 = p_{10}\\,, p_2 = p_{20}\\,, \\cdots\\,, p_k = p_{k0}\\,,\n(\\#eq:null-multinomial)\n\\end{equation} that completely specifies a value p_{i0} for each p_i.1 The alternative hypothesis H_a will state that H_0 is not true, i.e., that at least one p_i is different from the value p_{i0} claimed under the null H_0.\nProvided the null hypothesis in @ref(eq:null-multinomial) is true, the expected values @ref(eq:mean-count-multinomial) can be written in terms of the expected frequencies, \\begin{equation*}\n\\mathop{\\mathrm{\\mathbf{E}}}[N_i] = m p_{i0}\\,, \\quad i=1,\\dots,k\\,.\n\\end{equation*} Often the n_i, referred to as the observed cell counts, and the corresponding m p_{i0}, referred to as the expected cell counts, are tabulated, for example, as in Table @ref(tab:cell-counts).\n\n\n\n\nObserved and expected cell counts.\n\n\nCategory\n$i=1$\n$i=2$\n$\\cdots$\n$i=k$\nRow total\n\n\n\n\nObserved\n$n_1$\n$n_2$\n$\\cdots$\n$n_k$\n$m$\n\n\nExpected\n$mp_{10}$\n$mp_{20}$\n$\\cdots$\n$mp_{k0}$\n$m$\n\n\n\n\n\n\n\n\nThe test procedure assesses the discrepancy between the value of the observed and expected cell counts. This discrepancy, or goodness of fit, is measured by the squared deviations divided by the expected count.2\n\n\nCode\nFor $m p_i \\geq 5$ for $i = 1, \\dots, k$, the rv\n\\begin{equation*}\n V = \\sum_{i=1}^k \\frac{(N_i - m p_i)^2}{m p_i} \\quad \\sim \\chi^2(k-1)\\,,\n\\end{equation*}\nthat is, $V$ has approximately a $\\chi^2$ distribution with $\\nu = k-1$ df. \n\n\n\n\nCode\nConsider the null\n\\begin{equation*}\nH_0 : p_1 = p_{10}, p_2 = p_{20}, \\cdots, p_k = p_{k0}\\,,\n\\end{equation*}\nand the alternative \n\\begin{equation*}\nH_a : p_i \\neq p_{i0}\\; \\text{for at least one}\\; i\\,.\n\\end{equation*}\nThe test statistic is\n\\begin{equation*}\n V = \\sum_{i=1}^k \\frac{(N_i - m p_{i0})^2}{m p_{i0}}\\,.\n\\end{equation*}\nAs a rule of thumb, provided $m p_{i0} \\geq 5$ for all $i = 1, \\dots, k$, then the $P$-value is the area under $\\chi^2(k-1)$ to the right of $v$. \n\n\nIf m p_{i0} &lt; 5 for some i then it may be possible to combine the categories such that the new categorizations satisfy the assumptions of Proposition @ref(prp:htest-multinomial).\n\nThings are much more complicated if the category probabilities are not entirely specified.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Categorical data</span>"
    ]
  },
  {
    "objectID": "07-categorical-data.html#test-for-the-independence-of-factors",
    "href": "07-categorical-data.html#test-for-the-independence-of-factors",
    "title": "7  Categorical data",
    "section": "7.3 Test for the independence of factors",
    "text": "7.3 Test for the independence of factors\nIn Section 7.2, we considered categorising a population into a single factor. We now consider a single population where each individual is categorised into two factors with I distinct categories for the first factor and J distinct categories for the second factor. Each individual from the population belongs to exactly one of the I categories of the first factor and exactly one of the J categories of the second factor. We want to determine whether or not there is any dependency between the two factors.\nFor a sample of m individuals, we denote by n_{ij} the count of the m samples that fall both in category i of the first factor and category j of the second factor, for i = 1, \\dots, I and j = 1, \\dots, J. A contingency table with I rows and J columns (i.e., IJ cells) will be used to record the n_{ij} counts (in an obvious way). Let p_{ij} be the proportion of individuals in the population who belong in category i of factor 1 and category j of factor 2. Then, the probability that a randomly selected individual falls in category i of factor 1 is found by summing over all j: \np_{i} = \\sum_{j=1}^J p_{ij}\\,,\n and likewise, the probability that a randomly selected individual falls in category j of factor 2 is found by summing over all i: \np_{j} = \\sum_{i=1}^I p_{ij}\\,.\n The null hypothesis that we will be interested in adopting is \nH_0 : p_{ij} = p_{i} \\cdot p_{j} \\; \\forall (i,j)\\,,\n(\\#eq:null-two-factor)\n that is, an individual’s category in factor 1 is independent of the category in factor 2.\nFollowing the same program as for the single category goodness-of-fit test, we note that assuming the null hypothesis ?eq-null-two-factor is true, then the expected count in cell i,j is \n\\mathop{\\mathrm{\\mathbf{E}}}[N_{ij}] = m p_{ij} = m p_{i} p_{j}\\,;\n and we estimate p_i and p_j by the appropriate sample proportion: \n\\widehat{p}_i = \\frac{n_i}{m}\\,, \\qquad n_i = \\sum_{j} n_{ij} \\quad \\text{(row totals)}\\,,\n and \n\\widehat{p}_j = \\frac{n_j}{m}\\,, \\qquad n_j = \\sum_{i} n_{ij}\\quad \\text{(column totals)}\\,.\n Thus, the expected cell count is given by \n\\widehat{e}_{ij} = m \\widehat{p}_i \\widehat{p}_j = \\frac{n_i n_j}{m}\\,,\n and we assess the goodness of fit between the observed cell count n_ij and the expected cell count \\widehat{e}_ij.\n\nProposition 7.2 Assume the null hypothesis \nH_0 : p_{ij} = p_i p_j \\; \\text{for all } i=1, \\dots, I\\,, j=1, \\dots, J\\,,\n against the alternative hypothesis \nH_a : H_0 \\;\\text{is not true}\\,.\n The test statistic is \nV = \\sum_{i=1}^I \\sum_{j=1}^J \\frac{(N_{ij} - \\widehat{e}_{ij})^2}{\\widehat{e}_{ij}} \\,.\n As a rule of thumb, provided \\widehat{e}_{ij} \\geq 5 for all i,j and when H_0 is true, then the test statistic has approximately a \\chi^2(\\nu) distribution with \\nu = (I-1)(J-1) df. For a hypothesis test at level \\alpha, the procedure is upper-tailed, and the P-value is the area under \\chi^2(\\nu) to the right of v.\n\n\n\n\n\n\n\nAlternative lingo\n\n\n\nContingency is just another word for dependency in the context of goodness-of-fit tables.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Categorical data</span>"
    ]
  },
  {
    "objectID": "07-categorical-data.html#footnotes",
    "href": "07-categorical-data.html#footnotes",
    "title": "7  Categorical data",
    "section": "",
    "text": "Contingency is another word for dependency in this context.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Categorical data</span>"
    ]
  },
  {
    "objectID": "08-quality-control.html",
    "href": "08-quality-control.html",
    "title": "8  Quality control",
    "section": "",
    "text": "8.1 Control charts\nThe essential elements of control charting involve specifying a control region and then analysing time-series data. We will specify a baseline value along with an upper and lower control limit and assume that a process is under control unless a test statistic suggests otherwise. To construct a control chart, one collects data about a process at fixed points of time and calculates the running value of a quality statistic. Suppose the quality statistic exceeds the upper or lower control limits. In that case, the process is deemed out of control, and the product quality is assumed to be negatively impacted.\nThe process of creating a control chart is best illustrated through an extended example, like Example 8.1 provided below.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "08-quality-control.html#footnotes",
    "href": "08-quality-control.html#footnotes",
    "title": "8  Quality control",
    "section": "",
    "text": "The default position here will be reminiscent of hypothesis testing.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "07-categorical-data.html#sec-goodness-of-fit-tests",
    "href": "07-categorical-data.html#sec-goodness-of-fit-tests",
    "title": "7  Categorical data",
    "section": "7.2 Goodness-of-fit for a single factor",
    "text": "7.2 Goodness-of-fit for a single factor\nWe are interested in making inferences about the proportion parameters p_i. Specifically, we will consider the null hypothesis, \nH_0 : p_1 = p_{10}\\,, p_2 = p_{20}\\,, \\cdots\\,, p_k = p_{k0}\\,,\n\\tag{7.2} that completely specifies a value p_{i0} for each p_i. The alternative hypothesis H_a will state that H_0 is not true, i.e., that at least one p_i is different from the value p_{i0} claimed under the null H_0.\n\n\n\n\n\n\nNotation\n\n\n\nHere for i=1, \\dots, k we use the notation p_{i0} to denote the value of p_i claimed under the null hypothesis.\n\n\nProvided the null hypothesis in Equation 7.2 is true, the expected values Equation 7.1 can be written in terms of the expected frequencies, \n\\mathop{\\mathrm{\\mathbf{E}}}[N_i] = m p_{i0}\\,, \\quad i=1,\\dots,k\\,.\n Often the n_i, referred to as the observed cell counts, and the corresponding m p_{i0}, referred to as the expected cell counts, are tabulated, for example, as in Table 7.1.\n\n\n\nTable 7.1: Observed and expected cell counts.\n\n\n\n\n\nCategory\ni=1\ni=2\n\\cdots\ni=k\nRow total\n\n\n\n\nObserved\nn_1\nn_2\n\\cdots\nn_k\nm\n\n\nExpected\nmp_{10}\nmp_{20}\n\\cdots\nmp_{k0}\nm\n\n\n\n\n\n\nThe test procedure assesses the discrepancy between the value of the observed and expected cell counts. This discrepancy, or goodness of fit, is measured by the squared deviations divided by the expected count.\n\n\n\n\n\n\nWhy divide by expected cell counts?\n\n\n\nThe division by the expected cell counts accounts for possible differences in the relative magnitude of the observed/expected counts.\n\n\n\nTheorem 7.1 For m p_i \\geq 5 for i = 1, \\dots, k, the rv \nV = \\sum_{i=1}^k \\frac{(N_i - m p_i)^2}{m p_i} \\quad \\sim \\chi^2(k-1)\\,,\n that is, V has approximately a \\chi^2 distribution with \\nu = k-1 df.\n\n\nProposition 7.1 Consider the null \nH_0 : p_1 = p_{10}, p_2 = p_{20}, \\cdots, p_k = p_{k0}\\,,\n and the alternative \nH_a : p_i \\neq p_{i0}\\; \\text{for at least one}\\; i\\,.\n The test statistic is \nV = \\sum_{i=1}^k \\frac{(N_i - m p_{i0})^2}{m p_{i0}}\\,.\n As a rule of thumb, provided m p_{i0} \\geq 5 for all i = 1, \\dots, k, then the P-value is the area under \\chi^2(k-1) to the right of v.\n\nIf m p_{i0} &lt; 5 for some i then it may be possible to combine the categories such that the new categorizations satisfy the assumptions of Proposition 7.1.\n\n\n\n\n\n\nWhat about partial information?\n\n\n\nThings are much more complicated if the category probabilities are not entirely specified.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Categorical data</span>"
    ]
  },
  {
    "objectID": "08-quality-control.html#sec-control-charts",
    "href": "08-quality-control.html#sec-control-charts",
    "title": "8  Quality control",
    "section": "",
    "text": "Default position\n\n\n\nThe default position adopted for quality control will be reminiscent of hypothesis testing: “assume that a process is under control unless a test statistic suggests otherwise.”\n\n\n\n\nExample 8.1 Here we consider the typical 3 \\sigma control charting for a process mean \\overline{X} based on estimated parameters. That is, we assume the generating process X is normally distributed with unknown parameters \\mu and \\sigma^2. We seek to estimate the mean \\overline{X}. Our control region is specified to be three standard deviations; the process is in control if it remains within three standard deviations of a baseline value.\n\n\n\n\n\n\nNote 8.1: Beer Production Data\n\n\n\n\n\nThe Beer Production Data contains measurements of the features OG, ABV, pH, and IBU for 50 batches of each of three types of product (Premium Lager, IPA, and Light Lager).\n\n\nCode\nbeer |&gt; glimpse()\n\n\nRows: 150\nColumns: 6\n$ Batch_Id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, …\n$ OG       &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5…\n$ ABV      &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4…\n$ pH       &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1…\n$ IBU      &lt;dbl&gt; 9.0, 10.0, 7.0, 9.0, 8.0, 7.7, 7.4, 7.1, 6.8, 6.5, 6.2, 5.9, 5.6, 5.3, …\n$ Beer     &lt;chr&gt; \"Premium Lager\", \"Premium Lager\", \"Premium Lager\", \"Premium Lager\", \"Pr…\n\n\n\n\n\nLet’s consider the Beer Production Data in Note 8.1. We are interested in the IPA’s pH value, which influences saccharification. We assume that three batches of IPA are produced per day, and we prepare the data as follows.\n\n\nCode\nipa &lt;- beer |&gt; \n select(Batch_Id, pH, Beer) |&gt; \n filter(Beer == \"IPA\") |&gt; \n rename(Day = Batch_Id)\n\nm &lt;- 3    # three batches per day\nk &lt;- 16   # number of days\nipa$Day[1:(m*k)] &lt;- rep(1:k, each = m)\nipa &lt;- ipa[1:(m*k),]\n\n\nThe prepared data, ipa, is summarized in the Table 8.1.\n\n\nCode\nipa_stat &lt;- ipa |&gt; \n group_by(Day) |&gt; \n summarise(obs = list(pH), mean = signif(mean(pH), digits = 4), \n           sd = signif(sd(pH), digits = 4), range = max(pH) - min(pH)) \nipa_stat |&gt; \n kbl(align = \"rcccc\", booktabs = T, escape = F) |&gt;\n kable_styling(latex_options = c(\"striped\", \"hold_position\"))\n\n\n\n\nTable 8.1: Observations and summary statistics for the Beer Production Data.\n\n\n\n\n\n\n\nDay\nobs\nmean\nsd\nrange\n\n\n\n\n1\n4.7, 4.5, 4.9\n4.700\n0.20000\n0.4\n\n\n2\n4.0, 4.6, 4.5\n4.367\n0.32150\n0.6\n\n\n3\n4.7, 3.3, 4.6\n4.200\n0.78100\n1.4\n\n\n4\n3.9, 3.5, 4.2\n3.867\n0.35120\n0.7\n\n\n5\n4.0, 4.7, 3.6\n4.100\n0.55680\n1.1\n\n\n6\n4.4, 4.5, 4.1\n4.333\n0.20820\n0.4\n\n\n7\n4.5, 3.9, 4.8\n4.400\n0.45830\n0.9\n\n\n8\n4.0, 4.9, 4.7\n4.533\n0.47260\n0.9\n\n\n9\n4.3, 4.4, 4.8\n4.500\n0.26460\n0.5\n\n\n10\n5.0, 4.5, 3.5\n4.333\n0.76380\n1.5\n\n\n11\n3.8, 3.7, 3.9\n3.800\n0.10000\n0.2\n\n\n12\n5.1, 4.5, 4.5\n4.700\n0.34640\n0.6\n\n\n13\n4.7, 4.4, 4.1\n4.400\n0.30000\n0.6\n\n\n14\n4.0, 4.4, 4.6\n4.333\n0.30550\n0.6\n\n\n15\n4.0, 3.3, 4.2\n3.833\n0.47260\n0.9\n\n\n16\n4.2, 4.2, 4.3\n4.233\n0.05774\n0.1\n\n\n\n\n\n\n\n\n\n\n\nWe first observe that the pH measurements are (at least approximately) normal, as seen in the quantile-quantile plot in Figure 8.1.\n\n\nCode\nipa |&gt; ggplot(aes(sample = pH)) + stat_qq() + stat_qq_line()\n\n\n\n\n\n\n\n\nFigure 8.1: Normal quantile-quantile plot of observed pH measurements of the IPA batches.\n\n\n\n\n\nWe consider the data for pH readings from three batches of IPA taken over sixteen days (k = 16) presented in Table 8.1. The Table includes the sample mean per day, \\overline{x}, the sample standard deviation, s, and the range of values per day, \\max{x_i} - \\min{x_i} (each based on m=3 batches).\nWe estimate the mean\n\n\\widehat{\\mu} = \\frac{1}{k} \\sum_{i=1}^k \\overline{x}_i \\,,\n by averaging the means found for the k days and, similarly, estimating the mean of the sample standard deviation, \n\\overline{s} = \\frac{1}{k} \\sum_{i=1}^k s_i\\,,\n by averaging the sample standard deviations for the k days. It can be shown that \n\\widehat{\\sigma} = \\frac{\\overline{S}}{a_m}\n is an unbiased estimator of \\sigma where \na_m = \\frac{\\sqrt{2} \\Gamma(m/2)}{\\sqrt{m-1}\\Gamma\\left((n-1)/2\\right)}\\,.\n Thus, we compute the 3\\sigma upper and lower control limits, respectively, \n\\mathsf{UCL} = \\widehat{\\mu} + 3 \\frac{\\overline{s}}{a_m \\sqrt{m}}\n and \n\\mathsf{LCL} = \\widehat{\\mu} - 3 \\frac{\\overline{s}}{a_m \\sqrt{m}} \\,.\n The computations in r follow, along with the resulting control chart in Figure 8.2.\n\n\nCode\na &lt;- function(m){ sqrt(2) * gamma(m/2) / (sqrt(m-1) * gamma((m-1)/2)) }\nmuhat = sum(ipa_stat$mean) / k\nsbar = sum(ipa_stat$sd) / k\nlcl = muhat - 3*sbar / (a(m) * sqrt(m))\nucl = muhat + 3*sbar / (a(m) * sqrt(m))\n\nggplot(ipa_stat, aes(x = Day)) + geom_point(aes(y = mean)) + \n geom_hline(aes(yintercept = muhat, color = \"Mean\"), linewidth = lsz) + \n geom_hline(aes(yintercept = lcl, color = \"LCL\"), linewidth = lsz*1.5) + \n geom_hline(aes(yintercept = ucl, color = \"UCL\"), linewidth = lsz*1.5) + ylab(\"pH\") + \n   theme(legend.justification = c(1,1), legend.position = c(1,1),\n         legend.title = element_blank(), \n         legend.box.margin = margin(c(4, 4, 4, 4), unit = \"pt\"))\n\n\n\n\n\n\n\n\nFigure 8.2: The 3\\sigma control chart illustrates that with respect to pH the brewing process is in-control over the selected timeframe as the observations fall within the (\\mathsf{LCL}, \\mathsf{UCL}) control interval.\n\n\n\n\n\nFrom Figure 8.2, we observe for each day the process is in-control as the observed mean pH values fall within the control limits (\\mathsf{LCL}, \\mathsf{UCL}). If this were not the case, our initial assumption that the process is in control would be violated. The violation of the assumption would require that we seek to identify an assignable cause for the variation. If a cause could be identified, we would need to recompute our control limits with the observations that were out of control removed.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#prediction-using-linear-models",
    "href": "06-linear-models.html#prediction-using-linear-models",
    "title": "6  Linear regression",
    "section": "6.5 Prediction using linear models",
    "text": "6.5 Prediction using linear models\nOnce a model is fit, it can be used to predict a value of y for a given x. However, the model only gives the most likely value of y; a corresponding prediction interval is usually more appropriate.\n\nProposition 6.3 A 100(1-\\alpha)\\% prediction interval for an actual value of Y when x = x^* is given by \n(\\widehat{\\beta}_0 + \\widehat{\\beta}_1 x^*) \\pm t_{\\alpha/2, m-2} S \\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}} \\,.\n\n\n\n\n\n\n\n\nPrediction versus confidence intervals\n\n\n\nThe prediction interval is different from the confidence interval for expected Y. Note that the length of the confidence interval for \\mathop{\\mathrm{\\mathbf{E}}}[Y] when x=x^* is given by \n2 \\cdot t_{\\alpha/2} S  \\sqrt{\\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}}\n whereas the length for the prediction interval of Y is \n2 \\cdot t_{\\alpha/2} S  \\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\overline{x})^2}{S_{xx}}} \\,.\n Thus the prediction intervals for an actual value of Y are longer than the confidence intervals for \\mathop{\\mathrm{\\mathbf{E}}}[Y] if both are determined for the same value x^*.\n\n\nThe linear model \n\\mathop{\\mathrm{\\mathbf{E}}}[ Y \\mid X = x ] = \\beta_0 + \\beta_1 x \\,,\n assumes that the conditional expectation of Y for a fixed value of X is a linear function of the x value. If we assume that (X,Y) has a bivariate normal distribution, then \n\\beta_1 = \\frac{\\sigma_Y}{\\sigma_X} \\rho \\,,\n and thus, for the simple hypothesis tests we have considered (Table 2.2), statistical tests for \\beta_1 and \\rho are equivalent.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  }
]